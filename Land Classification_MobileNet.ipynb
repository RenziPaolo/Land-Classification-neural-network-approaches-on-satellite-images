{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b761683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 18:30:30.658256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.662829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.663129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.664024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-19 18:30:30.665145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.665487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.665820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.982864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.983184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.983324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 18:30:30.983436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5644 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices('GPU')\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10631242",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test, ds_validation), ds_info = tfds.load(\n",
    "    'eurosat/all',\n",
    "    split=['train[:80%]','train[80%:90%]','train[90%:100%]'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9f9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_training_history(training_history):\n",
    "    loss = training_history.history['loss']\n",
    "    val_loss = training_history.history['val_loss']\n",
    "\n",
    "    accuracy = training_history.history['sparse_categorical_accuracy']\n",
    "    val_accuracy = training_history.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss, label='Training set')\n",
    "    plt.plot(val_loss, label='Test set', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(accuracy, label='Training set')\n",
    "    plt.plot(val_accuracy, label='Test set', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "    plt.savefig(fname=\"MobileNet/MobileNet history\"+current_time,dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067f1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return image[:,:,1:4]/28002., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_validation = ds_validation.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_validation = ds_validation.batch(128)\n",
    "ds_validation = ds_validation.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71457f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.0471752  0.04903221 0.05521034]\n",
      "   [0.0471752  0.04903221 0.05521034]\n",
      "   [0.04799657 0.05003214 0.05642454]\n",
      "   ...\n",
      "   [0.04346118 0.04553246 0.04781801]\n",
      "   [0.04271124 0.04496107 0.04928219]\n",
      "   [0.04171131 0.04360403 0.04599671]]\n",
      "\n",
      "  [[0.0471752  0.04903221 0.05521034]\n",
      "   [0.0471752  0.04903221 0.05521034]\n",
      "   [0.04799657 0.05003214 0.05642454]\n",
      "   ...\n",
      "   [0.04346118 0.04553246 0.04781801]\n",
      "   [0.04271124 0.04496107 0.04928219]\n",
      "   [0.04171131 0.04360403 0.04599671]]\n",
      "\n",
      "  [[0.04703236 0.04953218 0.05378187]\n",
      "   [0.04703236 0.04953218 0.05378187]\n",
      "   [0.0471752  0.05046068 0.05510321]\n",
      "   ...\n",
      "   [0.04206842 0.04246125 0.04471109]\n",
      "   [0.04056853 0.04203271 0.04396114]\n",
      "   [0.04049711 0.04124705 0.04249696]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0395686  0.04099707 0.04253267]\n",
      "   [0.0395686  0.04099707 0.04253267]\n",
      "   [0.03964002 0.04110421 0.04367545]\n",
      "   ...\n",
      "   [0.0398543  0.03781873 0.04196129]\n",
      "   [0.0392472  0.03696164 0.04056853]\n",
      "   [0.03817584 0.03603314 0.03989001]]\n",
      "\n",
      "  [[0.03749732 0.03931862 0.03799729]\n",
      "   [0.03749732 0.03931862 0.03799729]\n",
      "   [0.03914006 0.04056853 0.0407828 ]\n",
      "   ...\n",
      "   [0.0398543  0.03785444 0.04331833]\n",
      "   [0.0389615  0.03696164 0.04096136]\n",
      "   [0.03814013 0.03596172 0.04013999]]\n",
      "\n",
      "  [[0.03389044 0.03585458 0.02489108]\n",
      "   [0.03389044 0.03585458 0.02489108]\n",
      "   [0.03539033 0.03699736 0.02835512]\n",
      "   ...\n",
      "   [0.04092565 0.03817584 0.04324691]\n",
      "   [0.04024712 0.03728305 0.041997  ]\n",
      "   [0.03946147 0.03685451 0.0413899 ]]]\n",
      "\n",
      "\n",
      " [[[0.02596243 0.02874795 0.01489179]\n",
      "   [0.02596243 0.02874795 0.01489179]\n",
      "   [0.02571245 0.0273909  0.01417756]\n",
      "   ...\n",
      "   [0.02610528 0.02874795 0.01396329]\n",
      "   [0.02674809 0.0325691  0.01532033]\n",
      "   [0.02706949 0.02914078 0.01574888]]\n",
      "\n",
      "  [[0.02596243 0.02874795 0.01489179]\n",
      "   [0.02596243 0.02874795 0.01489179]\n",
      "   [0.02571245 0.0273909  0.01417756]\n",
      "   ...\n",
      "   [0.02610528 0.02874795 0.01396329]\n",
      "   [0.02674809 0.0325691  0.01532033]\n",
      "   [0.02706949 0.02914078 0.01574888]]\n",
      "\n",
      "  [[0.02621241 0.0298193  0.01478466]\n",
      "   [0.02621241 0.0298193  0.01478466]\n",
      "   [0.02714092 0.03292622 0.01499893]\n",
      "   ...\n",
      "   [0.0267838  0.03189058 0.01589172]\n",
      "   [0.02753375 0.03353332 0.01621313]\n",
      "   [0.02724805 0.03174773 0.01532033]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03349761 0.02996214 0.03539033]\n",
      "   [0.03349761 0.02996214 0.03539033]\n",
      "   [0.03121206 0.02914078 0.03156918]\n",
      "   ...\n",
      "   [0.02699807 0.03199771 0.01746304]\n",
      "   [0.02714092 0.02928362 0.01757017]\n",
      "   [0.0252482  0.03046211 0.01417756]]\n",
      "\n",
      "  [[0.03110492 0.02899793 0.03046211]\n",
      "   [0.03110492 0.02899793 0.03046211]\n",
      "   [0.02967645 0.02828369 0.0267838 ]\n",
      "   ...\n",
      "   [0.02742661 0.03396186 0.01649882]\n",
      "   [0.02706949 0.03310478 0.01617742]\n",
      "   [0.02596243 0.03221199 0.01417756]]\n",
      "\n",
      "  [[0.02964074 0.02764088 0.02506964]\n",
      "   [0.02964074 0.02764088 0.02506964]\n",
      "   [0.02903364 0.02835512 0.02339119]\n",
      "   ...\n",
      "   [0.02703378 0.03342618 0.01592743]\n",
      "   [0.02706949 0.03524748 0.01639169]\n",
      "   [0.02599814 0.03431898 0.01564174]]]\n",
      "\n",
      "\n",
      " [[[0.04213985 0.03964002 0.03942576]\n",
      "   [0.04213985 0.03964002 0.03942576]\n",
      "   [0.04028284 0.038033   0.03603314]\n",
      "   ...\n",
      "   [0.05181773 0.05306764 0.05896007]\n",
      "   [0.05371045 0.0532462  0.06217413]\n",
      "   [0.05824584 0.05760303 0.06628098]]\n",
      "\n",
      "  [[0.04213985 0.03964002 0.03942576]\n",
      "   [0.04213985 0.03964002 0.03942576]\n",
      "   [0.04028284 0.038033   0.03603314]\n",
      "   ...\n",
      "   [0.05181773 0.05306764 0.05896007]\n",
      "   [0.05371045 0.0532462  0.06217413]\n",
      "   [0.05824584 0.05760303 0.06628098]]\n",
      "\n",
      "  [[0.03996143 0.03767588 0.03556889]\n",
      "   [0.03996143 0.03767588 0.03556889]\n",
      "   [0.03892579 0.03699736 0.03360474]\n",
      "   ...\n",
      "   [0.05942433 0.06049568 0.06778087]\n",
      "   [0.05467467 0.05224627 0.0590315 ]\n",
      "   [0.05549604 0.0553889  0.06353118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05042497 0.05017499 0.05571031]\n",
      "   [0.05042497 0.05017499 0.05571031]\n",
      "   [0.05192486 0.05267481 0.05688879]\n",
      "   ...\n",
      "   [0.05135347 0.04774659 0.05246054]\n",
      "   [0.04953218 0.05013927 0.05481751]\n",
      "   [0.04660381 0.04449682 0.04531819]]\n",
      "\n",
      "  [[0.04917506 0.04903221 0.05431755]\n",
      "   [0.04917506 0.04903221 0.05431755]\n",
      "   [0.04992501 0.05138919 0.05338904]\n",
      "   ...\n",
      "   [0.05267481 0.04978216 0.05813871]\n",
      "   [0.04935362 0.05192486 0.05392472]\n",
      "   [0.04906792 0.04731805 0.05010356]]\n",
      "\n",
      "  [[0.04378259 0.04221127 0.04085422]\n",
      "   [0.04378259 0.04221127 0.04085422]\n",
      "   [0.04103278 0.03889008 0.03964002]\n",
      "   ...\n",
      "   [0.05121063 0.04956789 0.05738876]\n",
      "   [0.04956789 0.04981787 0.05103207]\n",
      "   [0.05256767 0.05078209 0.05656739]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.02831941 0.02414113 0.01389186]\n",
      "   [0.02831941 0.02414113 0.01389186]\n",
      "   [0.02939076 0.0249625  0.01485608]\n",
      "   ...\n",
      "   [0.0322477  0.02885508 0.02546247]\n",
      "   [0.03492608 0.03406899 0.02939076]\n",
      "   [0.03203342 0.03124777 0.02560531]]\n",
      "\n",
      "  [[0.02831941 0.02414113 0.01389186]\n",
      "   [0.02831941 0.02414113 0.01389186]\n",
      "   [0.02939076 0.0249625  0.01485608]\n",
      "   ...\n",
      "   [0.0322477  0.02885508 0.02546247]\n",
      "   [0.03492608 0.03406899 0.02939076]\n",
      "   [0.03203342 0.03124777 0.02560531]]\n",
      "\n",
      "  [[0.0273909  0.02278409 0.01335619]\n",
      "   [0.0273909  0.02278409 0.01335619]\n",
      "   [0.02735519 0.02328405 0.01328477]\n",
      "   ...\n",
      "   [0.03192629 0.02839083 0.02285551]\n",
      "   [0.03842583 0.03717592 0.03342618]\n",
      "   [0.0395686  0.03806871 0.0337833 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03267624 0.02664095 0.02528391]\n",
      "   [0.03267624 0.02664095 0.02528391]\n",
      "   [0.04024712 0.04153275 0.03442611]\n",
      "   ...\n",
      "   [0.03146204 0.02746232 0.01960574]\n",
      "   [0.03124777 0.0304264  0.01928434]\n",
      "   [0.03685451 0.03446182 0.02660524]]\n",
      "\n",
      "  [[0.03564031 0.03249768 0.03210485]\n",
      "   [0.03564031 0.03249768 0.03210485]\n",
      "   [0.04913935 0.04756803 0.04060424]\n",
      "   ...\n",
      "   [0.0313549  0.02806942 0.01996286]\n",
      "   [0.03131919 0.02874795 0.01910578]\n",
      "   [0.03617599 0.03260481 0.02842654]]\n",
      "\n",
      "  [[0.03592601 0.0322477  0.03028355]\n",
      "   [0.03592601 0.0322477  0.03028355]\n",
      "   [0.041997   0.04067567 0.03339047]\n",
      "   ...\n",
      "   [0.03414042 0.02949789 0.02489108]\n",
      "   [0.03531891 0.03292622 0.02546247]\n",
      "   [0.03906864 0.03585458 0.03446182]]]\n",
      "\n",
      "\n",
      " [[[0.0426041  0.04471109 0.04092565]\n",
      "   [0.0426041  0.04471109 0.04092565]\n",
      "   [0.04010428 0.04156846 0.03696164]\n",
      "   ...\n",
      "   [0.02924791 0.03531891 0.01746304]\n",
      "   [0.02971216 0.03567602 0.0176416 ]\n",
      "   [0.0286051  0.03267624 0.01649882]]\n",
      "\n",
      "  [[0.0426041  0.04471109 0.04092565]\n",
      "   [0.0426041  0.04471109 0.04092565]\n",
      "   [0.04010428 0.04156846 0.03696164]\n",
      "   ...\n",
      "   [0.02924791 0.03531891 0.01746304]\n",
      "   [0.02971216 0.03567602 0.0176416 ]\n",
      "   [0.0286051  0.03267624 0.01649882]]\n",
      "\n",
      "  [[0.04621099 0.04585387 0.04617527]\n",
      "   [0.04621099 0.04585387 0.04617527]\n",
      "   [0.04253267 0.04196129 0.0377473 ]\n",
      "   ...\n",
      "   [0.0295336  0.03585458 0.01971288]\n",
      "   [0.02931933 0.0331762  0.01778444]\n",
      "   [0.0292122  0.03149775 0.01660596]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02656953 0.02417685 0.01524891]\n",
      "   [0.02656953 0.02417685 0.01524891]\n",
      "   [0.02635526 0.02153418 0.01346332]\n",
      "   ...\n",
      "   [0.03299764 0.03464038 0.02964074]\n",
      "   [0.03314049 0.03521177 0.02914078]\n",
      "   [0.03324762 0.03456896 0.02985501]]\n",
      "\n",
      "  [[0.03214056 0.03067638 0.0231412 ]\n",
      "   [0.03214056 0.03067638 0.0231412 ]\n",
      "   [0.02685522 0.02396257 0.01507035]\n",
      "   ...\n",
      "   [0.03328334 0.03414042 0.02946218]\n",
      "   [0.0328548  0.03510464 0.02889079]\n",
      "   [0.03346189 0.03435469 0.02978359]]\n",
      "\n",
      "  [[0.0395686  0.03796157 0.03167631]\n",
      "   [0.0395686  0.03796157 0.03167631]\n",
      "   [0.03067638 0.03081923 0.02199843]\n",
      "   ...\n",
      "   [0.03328334 0.03449754 0.03035497]\n",
      "   [0.03310478 0.03531891 0.0298193 ]\n",
      "   [0.03274766 0.03396186 0.02978359]]]\n",
      "\n",
      "\n",
      " [[[0.04871081 0.05096065 0.07220913]\n",
      "   [0.04871081 0.05096065 0.07220913]\n",
      "   [0.04917506 0.05171059 0.07295907]\n",
      "   ...\n",
      "   [0.05817442 0.06810228 0.09956431]\n",
      "   [0.05703164 0.06592386 0.09845725]\n",
      "   [0.05613885 0.06385258 0.09467181]]\n",
      "\n",
      "  [[0.04871081 0.05096065 0.07220913]\n",
      "   [0.04871081 0.05096065 0.07220913]\n",
      "   [0.04917506 0.05171059 0.07295907]\n",
      "   ...\n",
      "   [0.05817442 0.06810228 0.09956431]\n",
      "   [0.05703164 0.06592386 0.09845725]\n",
      "   [0.05613885 0.06385258 0.09467181]]\n",
      "\n",
      "  [[0.04974645 0.05228198 0.07295907]\n",
      "   [0.04974645 0.05228198 0.07295907]\n",
      "   [0.04967503 0.05221056 0.07288765]\n",
      "   ...\n",
      "   [0.05674595 0.06649525 0.09770731]\n",
      "   [0.05699593 0.06642383 0.09788586]\n",
      "   [0.05696022 0.06553103 0.09506464]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04417542 0.0438183  0.05638883]\n",
      "   [0.04417542 0.0438183  0.05638883]\n",
      "   [0.04353261 0.04374687 0.05678166]\n",
      "   ...\n",
      "   [0.04046139 0.04010428 0.04392543]\n",
      "   [0.04046139 0.03992572 0.0438183 ]\n",
      "   [0.04096136 0.04067567 0.04592529]]\n",
      "\n",
      "  [[0.04392543 0.04392543 0.05592458]\n",
      "   [0.04392543 0.04392543 0.05592458]\n",
      "   [0.04356832 0.04399686 0.05653168]\n",
      "   ...\n",
      "   [0.04010428 0.03860439 0.04246125]\n",
      "   [0.04006857 0.03910435 0.04313977]\n",
      "   [0.04074709 0.04038997 0.04638954]]\n",
      "\n",
      "  [[0.04263981 0.04313977 0.05546032]\n",
      "   [0.04263981 0.04313977 0.05546032]\n",
      "   [0.04374687 0.04378259 0.05574602]\n",
      "   ...\n",
      "   [0.03960431 0.0377473  0.04210414]\n",
      "   [0.03989001 0.0383544  0.04378259]\n",
      "   [0.04013999 0.03914006 0.0444254 ]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.04956789 0.05156774 0.06945933]\n",
      "   [0.04956789 0.05156774 0.06945933]\n",
      "   [0.0496036  0.05167488 0.06956646]\n",
      "   ...\n",
      "   [0.05103207 0.05199629 0.06849511]\n",
      "   [0.05067495 0.05092493 0.06799515]\n",
      "   [0.05060353 0.05199629 0.06760231]]\n",
      "\n",
      "  [[0.04956789 0.05156774 0.06945933]\n",
      "   [0.04956789 0.05156774 0.06945933]\n",
      "   [0.0496036  0.05167488 0.06956646]\n",
      "   ...\n",
      "   [0.05103207 0.05199629 0.06849511]\n",
      "   [0.05067495 0.05092493 0.06799515]\n",
      "   [0.05060353 0.05199629 0.06760231]]\n",
      "\n",
      "  [[0.04935362 0.05149632 0.06981644]\n",
      "   [0.04935362 0.05149632 0.06981644]\n",
      "   [0.04981787 0.05181773 0.07006642]\n",
      "   ...\n",
      "   [0.05096065 0.05178202 0.06874509]\n",
      "   [0.0508178  0.05185344 0.06799515]\n",
      "   [0.05099636 0.05156774 0.0681737 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04742518 0.04681809 0.06110278]\n",
      "   [0.04742518 0.04681809 0.06110278]\n",
      "   [0.04681809 0.045961   0.06113849]\n",
      "   ...\n",
      "   [0.05185344 0.05342476 0.07103064]\n",
      "   [0.05106778 0.05371045 0.07138776]\n",
      "   [0.05167488 0.05360331 0.07253053]]\n",
      "\n",
      "  [[0.04663952 0.0468538  0.06113849]\n",
      "   [0.04663952 0.0468538  0.06113849]\n",
      "   [0.04681809 0.04692522 0.06138847]\n",
      "   ...\n",
      "   [0.05181773 0.05310335 0.07085208]\n",
      "   [0.05174631 0.05349618 0.07078066]\n",
      "   [0.05167488 0.05310335 0.0715306 ]]\n",
      "\n",
      "  [[0.04642526 0.04696093 0.06138847]\n",
      "   [0.04642526 0.04696093 0.06138847]\n",
      "   [0.04713949 0.04781801 0.06188844]\n",
      "   ...\n",
      "   [0.05138919 0.05303193 0.0708878 ]\n",
      "   [0.05178202 0.05338904 0.07024498]\n",
      "   [0.05174631 0.05281766 0.0708878 ]]]\n",
      "\n",
      "\n",
      " [[[0.04281837 0.04242554 0.03964002]\n",
      "   [0.04281837 0.04242554 0.03964002]\n",
      "   [0.04253267 0.04246125 0.03867581]\n",
      "   ...\n",
      "   [0.05456753 0.05435326 0.05810299]\n",
      "   [0.05313906 0.05467467 0.05724591]\n",
      "   [0.05435326 0.05442468 0.0578173 ]]\n",
      "\n",
      "  [[0.04281837 0.04242554 0.03964002]\n",
      "   [0.04281837 0.04242554 0.03964002]\n",
      "   [0.04253267 0.04246125 0.03867581]\n",
      "   ...\n",
      "   [0.05456753 0.05435326 0.05810299]\n",
      "   [0.05313906 0.05467467 0.05724591]\n",
      "   [0.05435326 0.05442468 0.0578173 ]]\n",
      "\n",
      "  [[0.04374687 0.04278266 0.04135419]\n",
      "   [0.04374687 0.04278266 0.04135419]\n",
      "   [0.04356832 0.04331833 0.03960431]\n",
      "   ...\n",
      "   [0.05378187 0.05524606 0.05713877]\n",
      "   [0.05431755 0.05531748 0.05774587]\n",
      "   [0.0547818  0.05542461 0.05788872]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04113992 0.04071138 0.03692593]\n",
      "   [0.04113992 0.04071138 0.03692593]\n",
      "   [0.03996143 0.03910435 0.03449754]\n",
      "   ...\n",
      "   [0.0398543  0.03767588 0.03231912]\n",
      "   [0.04013999 0.03846154 0.03271195]\n",
      "   [0.04071138 0.03899721 0.03492608]]\n",
      "\n",
      "  [[0.0413899  0.04074709 0.03781873]\n",
      "   [0.0413899  0.04074709 0.03781873]\n",
      "   [0.03953289 0.03885437 0.03431898]\n",
      "   ...\n",
      "   [0.03960431 0.0377473  0.03267624]\n",
      "   [0.03967574 0.03806871 0.03299764]\n",
      "   [0.04081851 0.03928291 0.03524748]]\n",
      "\n",
      "  [[0.04035426 0.0398543  0.03492608]\n",
      "   [0.04035426 0.0398543  0.03492608]\n",
      "   [0.04003286 0.03953289 0.03403328]\n",
      "   ...\n",
      "   [0.03906864 0.03785444 0.0322477 ]\n",
      "   [0.03935433 0.03814013 0.03314049]\n",
      "   [0.04006857 0.03960431 0.03535462]]]\n",
      "\n",
      "\n",
      " [[[0.02639097 0.02035569 0.01103493]\n",
      "   [0.02639097 0.02035569 0.01103493]\n",
      "   [0.02621241 0.02042711 0.01121349]\n",
      "   ...\n",
      "   [0.02667667 0.02206985 0.01178487]\n",
      "   [0.02692665 0.02453396 0.01314192]\n",
      "   [0.02696236 0.02153418 0.0124634 ]]\n",
      "\n",
      "  [[0.02639097 0.02035569 0.01103493]\n",
      "   [0.02639097 0.02035569 0.01103493]\n",
      "   [0.02621241 0.02042711 0.01121349]\n",
      "   ...\n",
      "   [0.02667667 0.02206985 0.01178487]\n",
      "   [0.02692665 0.02453396 0.01314192]\n",
      "   [0.02696236 0.02153418 0.0124634 ]]\n",
      "\n",
      "  [[0.02621241 0.02071281 0.01099921]\n",
      "   [0.02621241 0.02071281 0.01099921]\n",
      "   [0.02589101 0.02085565 0.01057067]\n",
      "   ...\n",
      "   [0.02656953 0.0237483  0.01296336]\n",
      "   [0.02714092 0.02417685 0.01317763]\n",
      "   [0.02653382 0.02146275 0.01285622]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0273909  0.0228198  0.01267767]\n",
      "   [0.0273909  0.0228198  0.01267767]\n",
      "   [0.0261767  0.02189129 0.01228484]\n",
      "   ...\n",
      "   [0.02771231 0.02489108 0.0133919 ]\n",
      "   [0.02660524 0.02289122 0.01496322]\n",
      "   [0.02742661 0.02471252 0.01528462]]\n",
      "\n",
      "  [[0.0273909  0.02256982 0.01267767]\n",
      "   [0.0273909  0.02256982 0.01267767]\n",
      "   [0.02692665 0.02217699 0.0127848 ]\n",
      "   ...\n",
      "   [0.02735519 0.02535533 0.01432041]\n",
      "   [0.02746232 0.02481966 0.01524891]\n",
      "   [0.02764088 0.0252482  0.01503464]]\n",
      "\n",
      "  [[0.02742661 0.02306978 0.01271338]\n",
      "   [0.02742661 0.02306978 0.01271338]\n",
      "   [0.02717663 0.02249839 0.01267767]\n",
      "   ...\n",
      "   [0.02831941 0.02696236 0.01546318]\n",
      "   [0.02821227 0.02564103 0.0155346 ]\n",
      "   [0.02821227 0.02653382 0.01617742]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.02974788 0.03006928 0.03046211]\n",
      "   [0.02974788 0.03006928 0.03046211]\n",
      "   [0.02881937 0.03028355 0.03071209]\n",
      "   ...\n",
      "   [0.02789086 0.0304264  0.01464181]\n",
      "   [0.02792658 0.03078352 0.01392758]\n",
      "   [0.02760517 0.02896222 0.01417756]]\n",
      "\n",
      "  [[0.02974788 0.03006928 0.03046211]\n",
      "   [0.02974788 0.03006928 0.03046211]\n",
      "   [0.02881937 0.03028355 0.03071209]\n",
      "   ...\n",
      "   [0.02789086 0.0304264  0.01464181]\n",
      "   [0.02792658 0.03078352 0.01392758]\n",
      "   [0.02760517 0.02896222 0.01417756]]\n",
      "\n",
      "  [[0.02974788 0.03056924 0.0310335 ]\n",
      "   [0.02974788 0.03056924 0.0310335 ]\n",
      "   [0.02960503 0.03060496 0.03167631]\n",
      "   ...\n",
      "   [0.02760517 0.03053353 0.01432041]\n",
      "   [0.02778373 0.03056924 0.01424898]\n",
      "   [0.02778373 0.02949789 0.01428469]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0325691  0.03281908 0.04560389]\n",
      "   [0.0325691  0.03281908 0.04560389]\n",
      "   [0.03303336 0.03342618 0.04813942]\n",
      "   ...\n",
      "   [0.03574745 0.0389615  0.05728162]\n",
      "   [0.03585458 0.03792586 0.05471038]\n",
      "   [0.03406899 0.03549746 0.0483894 ]]\n",
      "\n",
      "  [[0.03521177 0.03703307 0.05453182]\n",
      "   [0.03521177 0.03703307 0.05453182]\n",
      "   [0.03503321 0.03764017 0.05388901]\n",
      "   ...\n",
      "   [0.03585458 0.0395686  0.05742447]\n",
      "   [0.0349975  0.0377473  0.05553175]\n",
      "   [0.03396186 0.03610456 0.05110349]]\n",
      "\n",
      "  [[0.03585458 0.0377473  0.05513892]\n",
      "   [0.03585458 0.0377473  0.05513892]\n",
      "   [0.03496179 0.03764017 0.0547818 ]\n",
      "   ...\n",
      "   [0.03646168 0.03981858 0.05785301]\n",
      "   [0.03453325 0.03760446 0.05546032]\n",
      "   [0.03446182 0.0368188  0.05174631]]]\n",
      "\n",
      "\n",
      " [[[0.03092636 0.02681951 0.01921291]\n",
      "   [0.03092636 0.02681951 0.01921291]\n",
      "   [0.0307478  0.02671238 0.01939147]\n",
      "   ...\n",
      "   [0.03085494 0.02685522 0.01864153]\n",
      "   [0.03099779 0.02710521 0.01882008]\n",
      "   [0.03092636 0.02706949 0.01924863]]\n",
      "\n",
      "  [[0.03092636 0.02681951 0.01921291]\n",
      "   [0.03092636 0.02681951 0.01921291]\n",
      "   [0.0307478  0.02671238 0.01939147]\n",
      "   ...\n",
      "   [0.03085494 0.02685522 0.01864153]\n",
      "   [0.03099779 0.02710521 0.01882008]\n",
      "   [0.03092636 0.02706949 0.01924863]]\n",
      "\n",
      "  [[0.03124777 0.02674809 0.0191772 ]\n",
      "   [0.03124777 0.02674809 0.0191772 ]\n",
      "   [0.0310335  0.02653382 0.01967717]\n",
      "   ...\n",
      "   [0.03117635 0.02696236 0.01910578]\n",
      "   [0.03099779 0.02703378 0.01853439]\n",
      "   [0.03096207 0.02717663 0.01896293]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03114063 0.02760517 0.01953432]\n",
      "   [0.03114063 0.02760517 0.01953432]\n",
      "   [0.03153346 0.02689094 0.01971288]\n",
      "   ...\n",
      "   [0.03178344 0.02717663 0.01967717]\n",
      "   [0.03146204 0.02742661 0.0197843 ]\n",
      "   [0.0313549  0.02760517 0.02049854]]\n",
      "\n",
      "  [[0.0310335  0.02760517 0.02017713]\n",
      "   [0.0310335  0.02760517 0.02017713]\n",
      "   [0.0316406  0.02781944 0.02010571]\n",
      "   ...\n",
      "   [0.03181916 0.02731948 0.02035569]\n",
      "   [0.03156918 0.02753375 0.01999857]\n",
      "   [0.03106921 0.02753375 0.02049854]]\n",
      "\n",
      "  [[0.03114063 0.02753375 0.02014142]\n",
      "   [0.03114063 0.02753375 0.02014142]\n",
      "   [0.03139061 0.02764088 0.02017713]\n",
      "   ...\n",
      "   [0.03124777 0.02746232 0.02007   ]\n",
      "   [0.03096207 0.0267838  0.01974859]\n",
      "   [0.03121206 0.02703378 0.0197843 ]]]\n",
      "\n",
      "\n",
      " [[[0.03081923 0.02610528 0.01617742]\n",
      "   [0.03081923 0.02610528 0.01617742]\n",
      "   [0.03081923 0.02553389 0.01578459]\n",
      "   ...\n",
      "   [0.03464038 0.02960503 0.02456967]\n",
      "   [0.03481894 0.03289051 0.02360546]\n",
      "   [0.03524748 0.03335476 0.02317692]]\n",
      "\n",
      "  [[0.03081923 0.02610528 0.01617742]\n",
      "   [0.03081923 0.02610528 0.01617742]\n",
      "   [0.03081923 0.02553389 0.01578459]\n",
      "   ...\n",
      "   [0.03464038 0.02960503 0.02456967]\n",
      "   [0.03481894 0.03289051 0.02360546]\n",
      "   [0.03524748 0.03335476 0.02317692]]\n",
      "\n",
      "  [[0.03078352 0.02531962 0.01574888]\n",
      "   [0.03078352 0.02531962 0.01574888]\n",
      "   [0.03028355 0.02553389 0.01574888]\n",
      "   ...\n",
      "   [0.03646168 0.03267624 0.02792658]\n",
      "   [0.03710449 0.03603314 0.02810514]\n",
      "   [0.03685451 0.03692593 0.02849796]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03099779 0.02660524 0.01546318]\n",
      "   [0.03099779 0.02660524 0.01546318]\n",
      "   [0.03056924 0.02692665 0.01653453]\n",
      "   ...\n",
      "   [0.03156918 0.02603385 0.01557032]\n",
      "   [0.03124777 0.02639097 0.01546318]\n",
      "   [0.03078352 0.02564103 0.01589172]]\n",
      "\n",
      "  [[0.03064067 0.02656953 0.01571316]\n",
      "   [0.03064067 0.02656953 0.01571316]\n",
      "   [0.03121206 0.02710521 0.01607028]\n",
      "   ...\n",
      "   [0.03064067 0.02628384 0.01564174]\n",
      "   [0.03067638 0.02631955 0.0155346 ]\n",
      "   [0.0310335  0.02510535 0.01610599]]\n",
      "\n",
      "  [[0.03056924 0.02696236 0.01564174]\n",
      "   [0.03056924 0.02696236 0.01564174]\n",
      "   [0.03078352 0.02674809 0.01503464]\n",
      "   ...\n",
      "   [0.03142633 0.02646239 0.01592743]\n",
      "   [0.0316406  0.02649811 0.01646311]\n",
      "   [0.03146204 0.02599814 0.01678452]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.0313549  0.03217627 0.01596314]\n",
      "   [0.0313549  0.03217627 0.01596314]\n",
      "   [0.03099779 0.03174773 0.01482037]\n",
      "   ...\n",
      "   [0.03049782 0.03206914 0.01671309]\n",
      "   [0.03078352 0.03231912 0.01639169]\n",
      "   [0.03060496 0.03156918 0.01596314]]\n",
      "\n",
      "  [[0.0313549  0.03217627 0.01596314]\n",
      "   [0.0313549  0.03217627 0.01596314]\n",
      "   [0.03099779 0.03174773 0.01482037]\n",
      "   ...\n",
      "   [0.03049782 0.03206914 0.01671309]\n",
      "   [0.03078352 0.03231912 0.01639169]\n",
      "   [0.03060496 0.03156918 0.01596314]]\n",
      "\n",
      "  [[0.03006928 0.03067638 0.01410613]\n",
      "   [0.03006928 0.03067638 0.01410613]\n",
      "   [0.0298193  0.0304264  0.01403471]\n",
      "   ...\n",
      "   [0.03085494 0.03235483 0.01682023]\n",
      "   [0.0310335  0.03217627 0.01635597]\n",
      "   [0.03117635 0.03146204 0.01635597]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0313549  0.02967645 0.01974859]\n",
      "   [0.0313549  0.02967645 0.01974859]\n",
      "   [0.03178344 0.03006928 0.02131991]\n",
      "   ...\n",
      "   [0.03178344 0.03414042 0.01649882]\n",
      "   [0.03174773 0.03414042 0.01624884]\n",
      "   [0.03124777 0.03442611 0.01621313]]\n",
      "\n",
      "  [[0.03131919 0.02939076 0.02017713]\n",
      "   [0.03131919 0.02939076 0.02017713]\n",
      "   [0.0310335  0.02906935 0.01939147]\n",
      "   ...\n",
      "   [0.03185487 0.03453325 0.01653453]\n",
      "   [0.03178344 0.03467609 0.01653453]\n",
      "   [0.03142633 0.03431898 0.01689165]]\n",
      "\n",
      "  [[0.03067638 0.02878366 0.01860581]\n",
      "   [0.03067638 0.02878366 0.01860581]\n",
      "   [0.03089065 0.02899793 0.01867724]\n",
      "   ...\n",
      "   [0.03142633 0.03381901 0.0164274 ]\n",
      "   [0.0316406  0.03517606 0.0161417 ]\n",
      "   [0.0313549  0.03517606 0.01649882]]]\n",
      "\n",
      "\n",
      " [[[0.03546175 0.03081923 0.03142633]\n",
      "   [0.03546175 0.03081923 0.03142633]\n",
      "   [0.03514035 0.03260481 0.03260481]\n",
      "   ...\n",
      "   [0.03656882 0.03331905 0.03628312]\n",
      "   [0.03535462 0.0322477  0.03153346]\n",
      "   [0.03524748 0.03289051 0.03406899]]\n",
      "\n",
      "  [[0.03546175 0.03081923 0.03142633]\n",
      "   [0.03546175 0.03081923 0.03142633]\n",
      "   [0.03514035 0.03260481 0.03260481]\n",
      "   ...\n",
      "   [0.03656882 0.03331905 0.03628312]\n",
      "   [0.03535462 0.0322477  0.03153346]\n",
      "   [0.03524748 0.03289051 0.03406899]]\n",
      "\n",
      "  [[0.03531891 0.03303336 0.03342618]\n",
      "   [0.03531891 0.03303336 0.03342618]\n",
      "   [0.03660453 0.03339047 0.03571174]\n",
      "   ...\n",
      "   [0.03564031 0.03199771 0.03503321]\n",
      "   [0.03471181 0.03128348 0.03281908]\n",
      "   [0.03567602 0.03339047 0.03421184]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03599743 0.03242626 0.03353332]\n",
      "   [0.03599743 0.03242626 0.03353332]\n",
      "   [0.03739019 0.03535462 0.0362117 ]\n",
      "   ...\n",
      "   [0.0368188  0.03496179 0.03642597]\n",
      "   [0.03785444 0.03639026 0.0407828 ]\n",
      "   [0.0392472  0.03824727 0.04178273]]\n",
      "\n",
      "  [[0.03599743 0.03239054 0.03389044]\n",
      "   [0.03599743 0.03239054 0.03389044]\n",
      "   [0.03699736 0.03353332 0.03506893]\n",
      "   ...\n",
      "   [0.03356903 0.03181916 0.02789086]\n",
      "   [0.03374759 0.03056924 0.02699807]\n",
      "   [0.03403328 0.03099779 0.02817656]]\n",
      "\n",
      "  [[0.03603314 0.03364046 0.03231912]\n",
      "   [0.03603314 0.03364046 0.03231912]\n",
      "   [0.03564031 0.03228341 0.03099779]\n",
      "   ...\n",
      "   [0.03414042 0.03010499 0.02749804]\n",
      "   [0.03271195 0.02935505 0.0237483 ]\n",
      "   [0.031962   0.02992643 0.02210556]]]\n",
      "\n",
      "\n",
      " [[[0.03581887 0.02649811 0.02103421]\n",
      "   [0.03581887 0.02649811 0.02103421]\n",
      "   [0.03485465 0.02764088 0.0206771 ]\n",
      "   ...\n",
      "   [0.04585387 0.03981858 0.03660453]\n",
      "   [0.04642526 0.0383544  0.03549746]\n",
      "   [0.04392543 0.03664024 0.0331762 ]]\n",
      "\n",
      "  [[0.03581887 0.02649811 0.02103421]\n",
      "   [0.03581887 0.02649811 0.02103421]\n",
      "   [0.03485465 0.02764088 0.0206771 ]\n",
      "   ...\n",
      "   [0.04585387 0.03981858 0.03660453]\n",
      "   [0.04642526 0.0383544  0.03549746]\n",
      "   [0.04392543 0.03664024 0.0331762 ]]\n",
      "\n",
      "  [[0.03603314 0.03060496 0.0261767 ]\n",
      "   [0.03603314 0.03060496 0.0261767 ]\n",
      "   [0.03631883 0.02910506 0.02592672]\n",
      "   ...\n",
      "   [0.04349689 0.03599743 0.03249768]\n",
      "   [0.04042568 0.03353332 0.03056924]\n",
      "   [0.03903292 0.03117635 0.02960503]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03456896 0.02971216 0.02078423]\n",
      "   [0.03456896 0.02971216 0.02078423]\n",
      "   [0.03467609 0.03081923 0.02181987]\n",
      "   ...\n",
      "   [0.03642597 0.02896222 0.02578387]\n",
      "   [0.03689022 0.02874795 0.02467681]\n",
      "   [0.04049711 0.03235483 0.02928362]]\n",
      "\n",
      "  [[0.03481894 0.02967645 0.02074852]\n",
      "   [0.03481894 0.02967645 0.02074852]\n",
      "   [0.03481894 0.02996214 0.02071281]\n",
      "   ...\n",
      "   [0.03374759 0.02485537 0.01949861]\n",
      "   [0.03396186 0.0234269  0.0188558 ]\n",
      "   [0.03517606 0.02785515 0.02399829]]\n",
      "\n",
      "  [[0.03481894 0.03071209 0.02074852]\n",
      "   [0.03481894 0.03071209 0.02074852]\n",
      "   [0.03514035 0.03024784 0.02081994]\n",
      "   ...\n",
      "   [0.03364046 0.02392686 0.01842725]\n",
      "   [0.03535462 0.02421256 0.01974859]\n",
      "   [0.03556889 0.02567674 0.02117706]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03021213 0.02517677 0.01578459]\n",
      "   [0.03021213 0.02517677 0.01578459]\n",
      "   [0.03131919 0.0258553  0.01546318]\n",
      "   ...\n",
      "   [0.03153346 0.02603385 0.0173559 ]\n",
      "   [0.03171202 0.02628384 0.01814156]\n",
      "   [0.03174773 0.0261767  0.01874866]]\n",
      "\n",
      "  [[0.03021213 0.02517677 0.01578459]\n",
      "   [0.03021213 0.02517677 0.01578459]\n",
      "   [0.03131919 0.0258553  0.01546318]\n",
      "   ...\n",
      "   [0.03153346 0.02603385 0.0173559 ]\n",
      "   [0.03171202 0.02628384 0.01814156]\n",
      "   [0.03174773 0.0261767  0.01874866]]\n",
      "\n",
      "  [[0.03092636 0.02549818 0.01603457]\n",
      "   [0.03092636 0.02549818 0.01603457]\n",
      "   [0.03078352 0.02574816 0.01657025]\n",
      "   ...\n",
      "   [0.03081923 0.02599814 0.01592743]\n",
      "   [0.03114063 0.02614099 0.01714163]\n",
      "   [0.03185487 0.02571245 0.01846297]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03060496 0.02399829 0.0155346 ]\n",
      "   [0.03060496 0.02399829 0.0155346 ]\n",
      "   [0.02974788 0.02349832 0.01464181]\n",
      "   ...\n",
      "   [0.03110492 0.02499821 0.01649882]\n",
      "   [0.03053353 0.02514106 0.01653453]\n",
      "   [0.03064067 0.02442683 0.01589172]]\n",
      "\n",
      "  [[0.0301407  0.02392686 0.01574888]\n",
      "   [0.0301407  0.02392686 0.01574888]\n",
      "   [0.02978359 0.02371259 0.01517749]\n",
      "   ...\n",
      "   [0.03142633 0.02656953 0.01753446]\n",
      "   [0.03081923 0.02578387 0.01653453]\n",
      "   [0.03046211 0.02424827 0.01564174]]\n",
      "\n",
      "  [[0.02985501 0.02303407 0.01514178]\n",
      "   [0.02985501 0.02303407 0.01514178]\n",
      "   [0.03028355 0.02349832 0.01507035]\n",
      "   ...\n",
      "   [0.03160489 0.02642668 0.017963  ]\n",
      "   [0.03071209 0.0255696  0.01685594]\n",
      "   [0.03078352 0.02485537 0.01539176]]]\n",
      "\n",
      "\n",
      " [[[0.02560531 0.0170345  0.00917792]\n",
      "   [0.02560531 0.0170345  0.00917792]\n",
      "   [0.02581958 0.01739161 0.00917792]\n",
      "   ...\n",
      "   [0.02621241 0.0173559  0.00957074]\n",
      "   [0.02624813 0.01710592 0.00935647]\n",
      "   [0.02574816 0.0173559  0.00932076]]\n",
      "\n",
      "  [[0.02560531 0.0170345  0.00917792]\n",
      "   [0.02560531 0.0170345  0.00917792]\n",
      "   [0.02581958 0.01739161 0.00917792]\n",
      "   ...\n",
      "   [0.02621241 0.0173559  0.00957074]\n",
      "   [0.02624813 0.01710592 0.00935647]\n",
      "   [0.02574816 0.0173559  0.00932076]]\n",
      "\n",
      "  [[0.02574816 0.01724877 0.00932076]\n",
      "   [0.02574816 0.01724877 0.00932076]\n",
      "   [0.02581958 0.01724877 0.00935647]\n",
      "   ...\n",
      "   [0.02621241 0.01717735 0.00946361]\n",
      "   [0.02621241 0.01742733 0.00935647]\n",
      "   [0.02624813 0.01707021 0.00935647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02574816 0.01710592 0.0091422 ]\n",
      "   [0.02574816 0.01710592 0.0091422 ]\n",
      "   [0.02578387 0.01728448 0.0091422 ]\n",
      "   ...\n",
      "   [0.02603385 0.01714163 0.00932076]\n",
      "   [0.02571245 0.01724877 0.00910649]\n",
      "   [0.02553389 0.01742733 0.00907078]]\n",
      "\n",
      "  [[0.02599814 0.01717735 0.0091422 ]\n",
      "   [0.02599814 0.01717735 0.0091422 ]\n",
      "   [0.02574816 0.0173559  0.00924934]\n",
      "   ...\n",
      "   [0.02589101 0.01728448 0.00935647]\n",
      "   [0.02567674 0.01714163 0.00935647]\n",
      "   [0.02560531 0.01717735 0.00928505]]\n",
      "\n",
      "  [[0.02614099 0.01753446 0.00917792]\n",
      "   [0.02614099 0.01753446 0.00917792]\n",
      "   [0.0258553  0.01728448 0.0091422 ]\n",
      "   ...\n",
      "   [0.02571245 0.01707021 0.00935647]\n",
      "   [0.02606957 0.01728448 0.00921363]\n",
      "   [0.02574816 0.01692736 0.00932076]]]\n",
      "\n",
      "\n",
      " [[[0.04796086 0.04931791 0.05553175]\n",
      "   [0.04796086 0.04931791 0.05553175]\n",
      "   [0.04956789 0.05231769 0.0593529 ]\n",
      "   ...\n",
      "   [0.03789015 0.03806871 0.03778302]\n",
      "   [0.03881866 0.03953289 0.03960431]\n",
      "   [0.04021141 0.04053282 0.04103278]]\n",
      "\n",
      "  [[0.04796086 0.04931791 0.05553175]\n",
      "   [0.04796086 0.04931791 0.05553175]\n",
      "   [0.04956789 0.05231769 0.0593529 ]\n",
      "   ...\n",
      "   [0.03789015 0.03806871 0.03778302]\n",
      "   [0.03881866 0.03953289 0.03960431]\n",
      "   [0.04021141 0.04053282 0.04103278]]\n",
      "\n",
      "  [[0.04571102 0.04753232 0.05206771]\n",
      "   [0.04571102 0.04753232 0.05206771]\n",
      "   [0.04853225 0.05135347 0.05796015]\n",
      "   ...\n",
      "   [0.03964002 0.03889008 0.0398543 ]\n",
      "   [0.0395686  0.03914006 0.04099707]\n",
      "   [0.03889008 0.03981858 0.04042568]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03756874 0.03717592 0.03731876]\n",
      "   [0.03756874 0.03717592 0.03731876]\n",
      "   [0.03767588 0.03785444 0.03714021]\n",
      "   ...\n",
      "   [0.04371116 0.04467538 0.04821084]\n",
      "   [0.04253267 0.04349689 0.04638954]\n",
      "   [0.04221127 0.04310406 0.04599671]]\n",
      "\n",
      "  [[0.03667595 0.03664024 0.03553317]\n",
      "   [0.03667595 0.03664024 0.03553317]\n",
      "   [0.03710449 0.03699736 0.03592601]\n",
      "   ...\n",
      "   [0.04424684 0.04574673 0.05042497]\n",
      "   [0.04388972 0.04499679 0.04874652]\n",
      "   [0.04435397 0.04435397 0.04885365]]\n",
      "\n",
      "  [[0.03656882 0.03642597 0.03478323]\n",
      "   [0.03656882 0.03642597 0.03478323]\n",
      "   [0.03678309 0.03578316 0.03471181]\n",
      "   ...\n",
      "   [0.04421113 0.04524677 0.04956789]\n",
      "   [0.04399686 0.04531819 0.04878223]\n",
      "   [0.04388972 0.04485394 0.04849654]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.03821156 0.03124777 0.02542675]\n",
      "   [0.03821156 0.03124777 0.02542675]\n",
      "   [0.04338976 0.03631883 0.03531891]\n",
      "   ...\n",
      "   [0.06081709 0.05663881 0.06324548]\n",
      "   [0.05778159 0.05996    0.06670952]\n",
      "   [0.04463967 0.04399686 0.03696164]]\n",
      "\n",
      "  [[0.03821156 0.03124777 0.02542675]\n",
      "   [0.03821156 0.03124777 0.02542675]\n",
      "   [0.04338976 0.03631883 0.03531891]\n",
      "   ...\n",
      "   [0.06081709 0.05663881 0.06324548]\n",
      "   [0.05778159 0.05996    0.06670952]\n",
      "   [0.04463967 0.04399686 0.03696164]]\n",
      "\n",
      "  [[0.03799729 0.03081923 0.02467681]\n",
      "   [0.03799729 0.03081923 0.02467681]\n",
      "   [0.04063996 0.0331762  0.03089065]\n",
      "   ...\n",
      "   [0.06385258 0.06124562 0.07163774]\n",
      "   [0.0666381  0.0681737  0.07628027]\n",
      "   [0.05163917 0.05046068 0.05188915]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04453253 0.041997   0.03817584]\n",
      "   [0.04453253 0.041997   0.03817584]\n",
      "   [0.0374259  0.03617599 0.03139061]\n",
      "   ...\n",
      "   [0.03974716 0.03185487 0.02821227]\n",
      "   [0.03971145 0.03199771 0.02978359]\n",
      "   [0.03989001 0.03549746 0.03131919]]\n",
      "\n",
      "  [[0.04135419 0.03989001 0.0383544 ]\n",
      "   [0.04135419 0.03989001 0.0383544 ]\n",
      "   [0.03842583 0.03674737 0.0325691 ]\n",
      "   ...\n",
      "   [0.03206914 0.027998   0.02378402]\n",
      "   [0.03367617 0.02914078 0.021927  ]\n",
      "   [0.04242554 0.03360474 0.02942647]]\n",
      "\n",
      "  [[0.0407828  0.03971145 0.03796157]\n",
      "   [0.0407828  0.03971145 0.03796157]\n",
      "   [0.03749732 0.03599743 0.03239054]\n",
      "   ...\n",
      "   [0.03503321 0.03056924 0.02424827]\n",
      "   [0.03642597 0.03349761 0.02599814]\n",
      "   [0.04631812 0.041997   0.04096136]]]\n",
      "\n",
      "\n",
      " [[[0.03617599 0.03149775 0.02139133]\n",
      "   [0.03617599 0.03149775 0.02139133]\n",
      "   [0.03664024 0.03142633 0.0216056 ]\n",
      "   ...\n",
      "   [0.03699736 0.03674737 0.02389115]\n",
      "   [0.03946147 0.03849725 0.02806942]\n",
      "   [0.04081851 0.03842583 0.03049782]]\n",
      "\n",
      "  [[0.03617599 0.03149775 0.02139133]\n",
      "   [0.03617599 0.03149775 0.02139133]\n",
      "   [0.03664024 0.03142633 0.0216056 ]\n",
      "   ...\n",
      "   [0.03699736 0.03674737 0.02389115]\n",
      "   [0.03946147 0.03849725 0.02806942]\n",
      "   [0.04081851 0.03842583 0.03049782]]\n",
      "\n",
      "  [[0.03610456 0.03178344 0.02174845]\n",
      "   [0.03610456 0.03178344 0.02174845]\n",
      "   [0.03674737 0.03146204 0.02203414]\n",
      "   ...\n",
      "   [0.03610456 0.03589029 0.02206985]\n",
      "   [0.03589029 0.03667595 0.02156989]\n",
      "   [0.03735447 0.03771159 0.02474823]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03206914 0.02592672 0.01646311]\n",
      "   [0.03206914 0.02592672 0.01646311]\n",
      "   [0.03206914 0.02631955 0.01664167]\n",
      "   ...\n",
      "   [0.06095993 0.06374545 0.07449468]\n",
      "   [0.06103136 0.06324548 0.07317334]\n",
      "   [0.0566031  0.05688879 0.06499536]]\n",
      "\n",
      "  [[0.03242626 0.02671238 0.01664167]\n",
      "   [0.03242626 0.02671238 0.01664167]\n",
      "   [0.03221199 0.02681951 0.01657025]\n",
      "   ...\n",
      "   [0.06074566 0.06367403 0.07328048]\n",
      "   [0.06256696 0.06538819 0.07542318]\n",
      "   [0.06224556 0.06538819 0.07510178]]\n",
      "\n",
      "  [[0.03331905 0.02885508 0.01889151]\n",
      "   [0.03331905 0.02885508 0.01889151]\n",
      "   [0.03264052 0.02864081 0.0182487 ]\n",
      "   ...\n",
      "   [0.05874581 0.0623884  0.0708878 ]\n",
      "   [0.06188844 0.06428112 0.07549461]\n",
      "   [0.06356689 0.06688808 0.07770874]]]\n",
      "\n",
      "\n",
      " [[[0.03642597 0.03471181 0.02503393]\n",
      "   [0.03642597 0.03471181 0.02503393]\n",
      "   [0.04128277 0.03589029 0.03281908]\n",
      "   ...\n",
      "   [0.0322477  0.0322477  0.01835583]\n",
      "   [0.03235483 0.03346189 0.01907007]\n",
      "   [0.03292622 0.03381901 0.01971288]]\n",
      "\n",
      "  [[0.03642597 0.03471181 0.02503393]\n",
      "   [0.03642597 0.03471181 0.02503393]\n",
      "   [0.04128277 0.03589029 0.03281908]\n",
      "   ...\n",
      "   [0.0322477  0.0322477  0.01835583]\n",
      "   [0.03235483 0.03346189 0.01907007]\n",
      "   [0.03292622 0.03381901 0.01971288]]\n",
      "\n",
      "  [[0.03731876 0.03792586 0.02528391]\n",
      "   [0.03731876 0.03792586 0.02528391]\n",
      "   [0.03785444 0.0377473  0.0276766 ]\n",
      "   ...\n",
      "   [0.03181916 0.03278337 0.017963  ]\n",
      "   [0.0325691  0.03353332 0.01839154]\n",
      "   [0.03260481 0.03406899 0.01935576]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04417542 0.03999714 0.03578316]\n",
      "   [0.04417542 0.03999714 0.03578316]\n",
      "   [0.03699736 0.03253339 0.02946218]\n",
      "   ...\n",
      "   [0.03410471 0.02999786 0.02267695]\n",
      "   [0.03410471 0.03049782 0.02239126]\n",
      "   [0.03385472 0.03217627 0.02153418]]\n",
      "\n",
      "  [[0.04306835 0.0392472  0.03749732]\n",
      "   [0.04306835 0.0392472  0.03749732]\n",
      "   [0.04413971 0.04010428 0.03874723]\n",
      "   ...\n",
      "   [0.03392615 0.02985501 0.0228198 ]\n",
      "   [0.03410471 0.02985501 0.02264124]\n",
      "   [0.03381901 0.03099779 0.02156989]]\n",
      "\n",
      "  [[0.04103278 0.03624741 0.03221199]\n",
      "   [0.04103278 0.03624741 0.03221199]\n",
      "   [0.04488965 0.04242554 0.03917577]\n",
      "   ...\n",
      "   [0.03417613 0.02996214 0.02271266]\n",
      "   [0.03374759 0.02964074 0.02271266]\n",
      "   [0.03392615 0.02974788 0.02214128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.0377473  0.03603314 0.03806871]\n",
      "   [0.0377473  0.03603314 0.03806871]\n",
      "   [0.0374259  0.03578316 0.03781873]\n",
      "   ...\n",
      "   [0.03746161 0.03556889 0.03674737]\n",
      "   [0.04049711 0.03781873 0.04481823]\n",
      "   [0.04028284 0.03981858 0.04803228]]\n",
      "\n",
      "  [[0.0377473  0.03603314 0.03806871]\n",
      "   [0.0377473  0.03603314 0.03806871]\n",
      "   [0.0374259  0.03578316 0.03781873]\n",
      "   ...\n",
      "   [0.03746161 0.03556889 0.03674737]\n",
      "   [0.04049711 0.03781873 0.04481823]\n",
      "   [0.04028284 0.03981858 0.04803228]]\n",
      "\n",
      "  [[0.03856868 0.03642597 0.03967574]\n",
      "   [0.03856868 0.03642597 0.03967574]\n",
      "   [0.0374259  0.03442611 0.03685451]\n",
      "   ...\n",
      "   [0.03664024 0.03399757 0.03381901]\n",
      "   [0.03974716 0.03821156 0.04467538]\n",
      "   [0.03874723 0.03796157 0.04463967]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04188986 0.04167559 0.0468538 ]\n",
      "   [0.04188986 0.04167559 0.0468538 ]\n",
      "   [0.04142561 0.04049711 0.04571102]\n",
      "   ...\n",
      "   [0.03592601 0.03314049 0.03292622]\n",
      "   [0.03717592 0.03506893 0.03674737]\n",
      "   [0.03692593 0.03503321 0.03606885]]\n",
      "\n",
      "  [[0.0413899  0.03967574 0.04438969]\n",
      "   [0.0413899  0.03967574 0.04438969]\n",
      "   [0.03949718 0.03914006 0.04271124]\n",
      "   ...\n",
      "   [0.03464038 0.03081923 0.02764088]\n",
      "   [0.03571174 0.03314049 0.03289051]\n",
      "   [0.03696164 0.03489036 0.03739019]]\n",
      "\n",
      "  [[0.03892579 0.03617599 0.03789015]\n",
      "   [0.03892579 0.03617599 0.03789015]\n",
      "   [0.03735447 0.03485465 0.03492608]\n",
      "   ...\n",
      "   [0.03417613 0.03003357 0.02546247]\n",
      "   [0.03510464 0.03156918 0.02806942]\n",
      "   [0.03578316 0.03199771 0.03239054]]]\n",
      "\n",
      "\n",
      " [[[0.04581816 0.03303336 0.02114135]\n",
      "   [0.04581816 0.03303336 0.02114135]\n",
      "   [0.04710378 0.03603314 0.02474823]\n",
      "   ...\n",
      "   [0.05267481 0.04338976 0.03664024]\n",
      "   [0.05231769 0.04235412 0.03510464]\n",
      "   [0.05221056 0.04331833 0.03464038]]\n",
      "\n",
      "  [[0.04581816 0.03303336 0.02114135]\n",
      "   [0.04581816 0.03303336 0.02114135]\n",
      "   [0.04710378 0.03603314 0.02474823]\n",
      "   ...\n",
      "   [0.05267481 0.04338976 0.03664024]\n",
      "   [0.05231769 0.04235412 0.03510464]\n",
      "   [0.05221056 0.04331833 0.03464038]]\n",
      "\n",
      "  [[0.04653239 0.03142633 0.02089136]\n",
      "   [0.04653239 0.03142633 0.02089136]\n",
      "   [0.04688951 0.03281908 0.02171274]\n",
      "   ...\n",
      "   [0.05285337 0.04428255 0.03664024]\n",
      "   [0.05246054 0.04378259 0.03674737]\n",
      "   [0.05238912 0.04388972 0.03599743]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05410328 0.04803228 0.03428327]\n",
      "   [0.05410328 0.04803228 0.03428327]\n",
      "   [0.05253196 0.04603243 0.03310478]\n",
      "   ...\n",
      "   [0.05031784 0.03735447 0.02849796]\n",
      "   [0.04874652 0.03606885 0.02842654]\n",
      "   [0.04760374 0.03335476 0.02410542]]\n",
      "\n",
      "  [[0.05360331 0.04628241 0.03221199]\n",
      "   [0.05360331 0.04628241 0.03221199]\n",
      "   [0.05092493 0.04392543 0.02985501]\n",
      "   ...\n",
      "   [0.04760374 0.03431898 0.02424827]\n",
      "   [0.04881794 0.03374759 0.02664095]\n",
      "   [0.04796086 0.03199771 0.02274838]]\n",
      "\n",
      "  [[0.0526391  0.04488965 0.02971216]\n",
      "   [0.0526391  0.04488965 0.02971216]\n",
      "   [0.052032   0.04281837 0.02828369]\n",
      "   ...\n",
      "   [0.04856796 0.03506893 0.02667667]\n",
      "   [0.04835369 0.03417613 0.02521249]\n",
      "   [0.04796086 0.03189058 0.02310549]]]\n",
      "\n",
      "\n",
      " [[[0.02789086 0.02353403 0.01471324]\n",
      "   [0.02789086 0.02353403 0.01471324]\n",
      "   [0.02885508 0.02299836 0.01578459]\n",
      "   ...\n",
      "   [0.03360474 0.03556889 0.02796229]\n",
      "   [0.03939004 0.03964002 0.04046139]\n",
      "   [0.03817584 0.0395686  0.04028284]]\n",
      "\n",
      "  [[0.02789086 0.02353403 0.01471324]\n",
      "   [0.02789086 0.02353403 0.01471324]\n",
      "   [0.02885508 0.02299836 0.01578459]\n",
      "   ...\n",
      "   [0.03360474 0.03556889 0.02796229]\n",
      "   [0.03939004 0.03964002 0.04046139]\n",
      "   [0.03817584 0.0395686  0.04028284]]\n",
      "\n",
      "  [[0.02806942 0.02214128 0.01528462]\n",
      "   [0.02806942 0.02214128 0.01528462]\n",
      "   [0.02867652 0.02260553 0.01517749]\n",
      "   ...\n",
      "   [0.02924791 0.02914078 0.01846297]\n",
      "   [0.03360474 0.03292622 0.03031926]\n",
      "   [0.03039069 0.03206914 0.02310549]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04446111 0.04092565 0.0389615 ]\n",
      "   [0.04446111 0.04092565 0.0389615 ]\n",
      "   [0.05163917 0.05099636 0.0535676 ]\n",
      "   ...\n",
      "   [0.02756946 0.02553389 0.01346332]\n",
      "   [0.02785515 0.02642668 0.01378473]\n",
      "   [0.02885508 0.02806942 0.01503464]]\n",
      "\n",
      "  [[0.03917577 0.03649739 0.03821156]\n",
      "   [0.03917577 0.03649739 0.03821156]\n",
      "   [0.05392472 0.05567459 0.05453182]\n",
      "   ...\n",
      "   [0.0273909  0.02546247 0.01328477]\n",
      "   [0.027998   0.02685522 0.01389186]\n",
      "   [0.02856939 0.02689094 0.01414185]]\n",
      "\n",
      "  [[0.04421113 0.04121134 0.04346118]\n",
      "   [0.04421113 0.04121134 0.04346118]\n",
      "   [0.06374545 0.06653097 0.06735233]\n",
      "   ...\n",
      "   [0.02810514 0.02824798 0.01446325]\n",
      "   [0.02806942 0.02628384 0.01407042]\n",
      "   [0.02789086 0.02592672 0.01378473]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.04117563 0.03789015 0.03546175]\n",
      "   [0.04117563 0.03789015 0.03546175]\n",
      "   [0.03917577 0.03731876 0.03542604]\n",
      "   ...\n",
      "   [0.04767517 0.04392543 0.04781801]\n",
      "   [0.0456396  0.04117563 0.03946147]\n",
      "   [0.04738947 0.03978287 0.04299693]]\n",
      "\n",
      "  [[0.04117563 0.03789015 0.03546175]\n",
      "   [0.04117563 0.03789015 0.03546175]\n",
      "   [0.03917577 0.03731876 0.03542604]\n",
      "   ...\n",
      "   [0.04767517 0.04392543 0.04781801]\n",
      "   [0.0456396  0.04117563 0.03946147]\n",
      "   [0.04738947 0.03978287 0.04299693]]\n",
      "\n",
      "  [[0.05078209 0.04996072 0.05010356]\n",
      "   [0.05078209 0.04996072 0.05010356]\n",
      "   [0.052032   0.05217484 0.05371045]\n",
      "   ...\n",
      "   [0.04763946 0.04413971 0.04842511]\n",
      "   [0.04813942 0.04238983 0.04581816]\n",
      "   [0.04667524 0.04153275 0.04463967]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03728305 0.03606885 0.03249768]\n",
      "   [0.03728305 0.03606885 0.03249768]\n",
      "   [0.03649739 0.0325691  0.02914078]\n",
      "   ...\n",
      "   [0.05381759 0.04803228 0.04921077]\n",
      "   [0.05117492 0.04692522 0.04842511]\n",
      "   [0.04999643 0.04678237 0.04706807]]\n",
      "\n",
      "  [[0.03624741 0.03503321 0.02885508]\n",
      "   [0.03624741 0.03503321 0.02885508]\n",
      "   [0.03556889 0.03217627 0.02685522]\n",
      "   ...\n",
      "   [0.05485322 0.04903221 0.04903221]\n",
      "   [0.05271052 0.05056782 0.05163917]\n",
      "   [0.05228198 0.04671095 0.04978216]]\n",
      "\n",
      "  [[0.03242626 0.0286051  0.02146275]\n",
      "   [0.03242626 0.0286051  0.02146275]\n",
      "   [0.03331905 0.027998   0.02174845]\n",
      "   ...\n",
      "   [0.04803228 0.04188986 0.04203271]\n",
      "   [0.05563888 0.0514249  0.05303193]\n",
      "   [0.05863867 0.05281766 0.05471038]]]\n",
      "\n",
      "\n",
      " [[[0.03092636 0.03003357 0.02428398]\n",
      "   [0.03092636 0.03003357 0.02428398]\n",
      "   [0.03067638 0.02939076 0.02589101]\n",
      "   ...\n",
      "   [0.02896222 0.02596243 0.01782016]\n",
      "   [0.02856939 0.02631955 0.01892722]\n",
      "   [0.02889079 0.02635526 0.01767731]]\n",
      "\n",
      "  [[0.03092636 0.03003357 0.02428398]\n",
      "   [0.03092636 0.03003357 0.02428398]\n",
      "   [0.03067638 0.02939076 0.02589101]\n",
      "   ...\n",
      "   [0.02896222 0.02596243 0.01782016]\n",
      "   [0.02856939 0.02631955 0.01892722]\n",
      "   [0.02889079 0.02635526 0.01767731]]\n",
      "\n",
      "  [[0.03371188 0.02999786 0.02660524]\n",
      "   [0.03371188 0.02999786 0.02660524]\n",
      "   [0.03349761 0.03324762 0.03303336]\n",
      "   ...\n",
      "   [0.02903364 0.02653382 0.01803443]\n",
      "   [0.02889079 0.02621241 0.01821299]\n",
      "   [0.0292122  0.02628384 0.01760589]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02742661 0.02371259 0.01546318]\n",
      "   [0.02742661 0.02371259 0.01546318]\n",
      "   [0.02785515 0.02474823 0.0158203 ]\n",
      "   ...\n",
      "   [0.02735519 0.0237483  0.01564174]\n",
      "   [0.0289265  0.02471252 0.01753446]\n",
      "   [0.0286051  0.02489108 0.0164274 ]]\n",
      "\n",
      "  [[0.02692665 0.02289122 0.01403471]\n",
      "   [0.02692665 0.02289122 0.01403471]\n",
      "   [0.02756946 0.02414113 0.01371331]\n",
      "   ...\n",
      "   [0.02839083 0.02517677 0.01842725]\n",
      "   [0.02949789 0.0267838  0.01849868]\n",
      "   [0.02871224 0.02521249 0.01646311]]\n",
      "\n",
      "  [[0.02696236 0.02353403 0.01464181]\n",
      "   [0.02696236 0.02353403 0.01464181]\n",
      "   [0.02728377 0.02303407 0.01446325]\n",
      "   ...\n",
      "   [0.02853368 0.02564103 0.01742733]\n",
      "   [0.02942647 0.02753375 0.01821299]\n",
      "   [0.02956932 0.02553389 0.01799871]]]\n",
      "\n",
      "\n",
      " [[[0.04142561 0.0407828  0.04921077]\n",
      "   [0.04142561 0.0407828  0.04921077]\n",
      "   [0.04231841 0.04271124 0.0529605 ]\n",
      "   ...\n",
      "   [0.04192558 0.041997   0.05288908]\n",
      "   [0.04056853 0.0413899  0.04735376]\n",
      "   [0.04056853 0.0401757  0.04342547]]\n",
      "\n",
      "  [[0.04142561 0.0407828  0.04921077]\n",
      "   [0.04142561 0.0407828  0.04921077]\n",
      "   [0.04231841 0.04271124 0.0529605 ]\n",
      "   ...\n",
      "   [0.04192558 0.041997   0.05288908]\n",
      "   [0.04056853 0.0413899  0.04735376]\n",
      "   [0.04056853 0.0401757  0.04342547]]\n",
      "\n",
      "  [[0.04049711 0.04006857 0.04835369]\n",
      "   [0.04049711 0.04006857 0.04835369]\n",
      "   [0.04171131 0.04217556 0.05088922]\n",
      "   ...\n",
      "   [0.03664024 0.03553317 0.03721163]\n",
      "   [0.04042568 0.04053282 0.04478252]\n",
      "   [0.04631812 0.04731805 0.06092422]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04228269 0.04313977 0.05413899]\n",
      "   [0.04228269 0.04313977 0.05413899]\n",
      "   [0.04206842 0.04256839 0.05581744]\n",
      "   ...\n",
      "   [0.03485465 0.0325691  0.03178344]\n",
      "   [0.03424755 0.03199771 0.0292122 ]\n",
      "   [0.03435469 0.03171202 0.02896222]]\n",
      "\n",
      "  [[0.04296122 0.04331833 0.05481751]\n",
      "   [0.04296122 0.04331833 0.05481751]\n",
      "   [0.04271124 0.04288979 0.05617456]\n",
      "   ...\n",
      "   [0.03685451 0.03531891 0.03892579]\n",
      "   [0.03456896 0.03203342 0.03114063]\n",
      "   [0.03449754 0.03142633 0.0289265 ]]\n",
      "\n",
      "  [[0.04338976 0.04328262 0.05499607]\n",
      "   [0.04338976 0.04328262 0.05499607]\n",
      "   [0.04288979 0.04310406 0.05724591]\n",
      "   ...\n",
      "   [0.03949718 0.03917577 0.04806799]\n",
      "   [0.03692593 0.0349975  0.03714021]\n",
      "   [0.03496179 0.03189058 0.02914078]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.05063924 0.04981787 0.05360331]\n",
      "   [0.05063924 0.04981787 0.05360331]\n",
      "   [0.04788944 0.04617527 0.04621099]\n",
      "   ...\n",
      "   [0.03703307 0.0374259  0.02571245]\n",
      "   [0.04103278 0.04246125 0.03410471]\n",
      "   [0.03703307 0.03828298 0.0286051 ]]\n",
      "\n",
      "  [[0.05063924 0.04981787 0.05360331]\n",
      "   [0.05063924 0.04981787 0.05360331]\n",
      "   [0.04788944 0.04617527 0.04621099]\n",
      "   ...\n",
      "   [0.03703307 0.0374259  0.02571245]\n",
      "   [0.04103278 0.04246125 0.03410471]\n",
      "   [0.03703307 0.03828298 0.0286051 ]]\n",
      "\n",
      "  [[0.04703236 0.04560389 0.04860367]\n",
      "   [0.04703236 0.04560389 0.04860367]\n",
      "   [0.05096065 0.04374687 0.05160346]\n",
      "   ...\n",
      "   [0.03796157 0.03724734 0.02631955]\n",
      "   [0.03981858 0.04010428 0.0301407 ]\n",
      "   [0.03646168 0.03660453 0.02478394]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04578244 0.04317549 0.04531819]\n",
      "   [0.04578244 0.04317549 0.04531819]\n",
      "   [0.05003214 0.04606814 0.04878223]\n",
      "   ...\n",
      "   [0.03299764 0.03381901 0.01949861]\n",
      "   [0.03296193 0.03510464 0.02010571]\n",
      "   [0.03342618 0.03506893 0.02089136]]\n",
      "\n",
      "  [[0.05228198 0.04953218 0.04949646]\n",
      "   [0.05228198 0.04953218 0.04949646]\n",
      "   [0.05017499 0.04706807 0.04810371]\n",
      "   ...\n",
      "   [0.0343904  0.03485465 0.02431969]\n",
      "   [0.03349761 0.03396186 0.02081994]\n",
      "   [0.03389044 0.03324762 0.02239126]]\n",
      "\n",
      "  [[0.04699664 0.04181844 0.04396114]\n",
      "   [0.04699664 0.04181844 0.04396114]\n",
      "   [0.04617527 0.04181844 0.04324691]\n",
      "   ...\n",
      "   [0.03917577 0.03874723 0.0377473 ]\n",
      "   [0.03571174 0.03546175 0.02999786]\n",
      "   [0.03349761 0.03385472 0.02428398]]]\n",
      "\n",
      "\n",
      " [[[0.03771159 0.03628312 0.03003357]\n",
      "   [0.03771159 0.03628312 0.03003357]\n",
      "   [0.03846154 0.03639026 0.03071209]\n",
      "   ...\n",
      "   [0.03856868 0.04085422 0.02699807]\n",
      "   [0.03853296 0.04142561 0.0276766 ]\n",
      "   [0.03889008 0.04185415 0.02774802]]\n",
      "\n",
      "  [[0.03771159 0.03628312 0.03003357]\n",
      "   [0.03771159 0.03628312 0.03003357]\n",
      "   [0.03846154 0.03639026 0.03071209]\n",
      "   ...\n",
      "   [0.03856868 0.04085422 0.02699807]\n",
      "   [0.03853296 0.04142561 0.0276766 ]\n",
      "   [0.03889008 0.04185415 0.02774802]]\n",
      "\n",
      "  [[0.03671166 0.03567602 0.02792658]\n",
      "   [0.03671166 0.03567602 0.02792658]\n",
      "   [0.03689022 0.03524748 0.0273909 ]\n",
      "   ...\n",
      "   [0.03839011 0.04103278 0.02699807]\n",
      "   [0.03846154 0.04106849 0.02785515]\n",
      "   [0.03860439 0.04124705 0.02778373]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03474752 0.03081923 0.02128419]\n",
      "   [0.03474752 0.03081923 0.02128419]\n",
      "   [0.03503321 0.03085494 0.02128419]\n",
      "   ...\n",
      "   [0.03656882 0.03539033 0.02381973]\n",
      "   [0.03599743 0.0356046  0.02399829]\n",
      "   [0.03649739 0.03824727 0.02521249]]\n",
      "\n",
      "  [[0.03460467 0.0310335  0.02121277]\n",
      "   [0.03460467 0.0310335  0.02121277]\n",
      "   [0.03478323 0.03078352 0.02149846]\n",
      "   ...\n",
      "   [0.03703307 0.03635455 0.02574816]\n",
      "   [0.0374259  0.0368188  0.02546247]\n",
      "   [0.03721163 0.03799729 0.02714092]]\n",
      "\n",
      "  [[0.03464038 0.03071209 0.02071281]\n",
      "   [0.03464038 0.03071209 0.02071281]\n",
      "   [0.03424755 0.03039069 0.02114135]\n",
      "   ...\n",
      "   [0.03628312 0.0349975  0.02610528]\n",
      "   [0.03656882 0.03464038 0.02581958]\n",
      "   [0.03624741 0.03449754 0.02396257]]]\n",
      "\n",
      "\n",
      " [[[0.03417613 0.04099707 0.03189058]\n",
      "   [0.03417613 0.04099707 0.03189058]\n",
      "   [0.03428327 0.04356832 0.03514035]\n",
      "   ...\n",
      "   [0.03381901 0.03396186 0.02889079]\n",
      "   [0.02910506 0.02503393 0.01707021]\n",
      "   [0.02871224 0.02489108 0.01646311]]\n",
      "\n",
      "  [[0.03417613 0.04099707 0.03189058]\n",
      "   [0.03417613 0.04099707 0.03189058]\n",
      "   [0.03428327 0.04356832 0.03514035]\n",
      "   ...\n",
      "   [0.03381901 0.03396186 0.02889079]\n",
      "   [0.02910506 0.02503393 0.01707021]\n",
      "   [0.02871224 0.02489108 0.01646311]]\n",
      "\n",
      "  [[0.03414042 0.04263981 0.0328548 ]\n",
      "   [0.03414042 0.04263981 0.0328548 ]\n",
      "   [0.03364046 0.04263981 0.03281908]\n",
      "   ...\n",
      "   [0.0349975  0.04135419 0.03710449]\n",
      "   [0.03446182 0.03299764 0.02864081]\n",
      "   [0.0286051  0.02478394 0.01646311]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03171202 0.0331762  0.02035569]\n",
      "   [0.03171202 0.0331762  0.02035569]\n",
      "   [0.03181916 0.03296193 0.0203914 ]\n",
      "   ...\n",
      "   [0.02756946 0.02264124 0.01303478]\n",
      "   [0.0276766  0.02292693 0.01314192]\n",
      "   [0.02806942 0.0228198  0.01324905]]\n",
      "\n",
      "  [[0.03121206 0.03360474 0.02074852]\n",
      "   [0.03121206 0.03360474 0.02074852]\n",
      "   [0.03210485 0.03328334 0.01992715]\n",
      "   ...\n",
      "   [0.02803371 0.0228198  0.01303478]\n",
      "   [0.02764088 0.02306978 0.01335619]\n",
      "   [0.02764088 0.02331976 0.01349904]]\n",
      "\n",
      "  [[0.03178344 0.03331905 0.02010571]\n",
      "   [0.03178344 0.03331905 0.02010571]\n",
      "   [0.03121206 0.03371188 0.01996286]\n",
      "   ...\n",
      "   [0.02796229 0.02310549 0.01324905]\n",
      "   [0.02789086 0.02317692 0.01328477]\n",
      "   [0.0276766  0.02303407 0.01342761]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.04010428 0.03289051 0.02603385]\n",
      "   [0.04010428 0.03289051 0.02603385]\n",
      "   [0.03860439 0.02828369 0.02028427]\n",
      "   ...\n",
      "   [0.03467609 0.03146204 0.01882008]\n",
      "   [0.03464038 0.0316406  0.01932005]\n",
      "   [0.03556889 0.03231912 0.01985572]]\n",
      "\n",
      "  [[0.04010428 0.03289051 0.02603385]\n",
      "   [0.04010428 0.03289051 0.02603385]\n",
      "   [0.03860439 0.02828369 0.02028427]\n",
      "   ...\n",
      "   [0.03467609 0.03146204 0.01882008]\n",
      "   [0.03464038 0.0316406  0.01932005]\n",
      "   [0.03556889 0.03231912 0.01985572]]\n",
      "\n",
      "  [[0.03510464 0.02656953 0.01846297]\n",
      "   [0.03510464 0.02656953 0.01846297]\n",
      "   [0.03553317 0.02817656 0.01935576]\n",
      "   ...\n",
      "   [0.03485465 0.0310335  0.01957003]\n",
      "   [0.03467609 0.03078352 0.01942718]\n",
      "   [0.03481894 0.031962   0.02031998]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03564031 0.03389044 0.02471252]\n",
      "   [0.03564031 0.03389044 0.02471252]\n",
      "   [0.03581887 0.03392615 0.02431969]\n",
      "   ...\n",
      "   [0.03814013 0.03549746 0.02885508]\n",
      "   [0.03646168 0.03281908 0.02324834]\n",
      "   [0.03606885 0.03328334 0.02456967]]\n",
      "\n",
      "  [[0.03664024 0.03492608 0.0276766 ]\n",
      "   [0.03664024 0.03492608 0.0276766 ]\n",
      "   [0.03710449 0.03471181 0.02796229]\n",
      "   ...\n",
      "   [0.03271195 0.02760517 0.01867724]\n",
      "   [0.03324762 0.02628384 0.01753446]\n",
      "   [0.03303336 0.02846225 0.01907007]]\n",
      "\n",
      "  [[0.04042568 0.03724734 0.03274766]\n",
      "   [0.04042568 0.03724734 0.03274766]\n",
      "   [0.03939004 0.03660453 0.03114063]\n",
      "   ...\n",
      "   [0.03146204 0.02603385 0.01585601]\n",
      "   [0.03167631 0.02535533 0.01599886]\n",
      "   [0.03246197 0.02689094 0.01721306]]]\n",
      "\n",
      "\n",
      " [[[0.05274623 0.04528248 0.03921149]\n",
      "   [0.05274623 0.04528248 0.03921149]\n",
      "   [0.05256767 0.04449682 0.03760446]\n",
      "   ...\n",
      "   [0.04924648 0.04285408 0.02817656]\n",
      "   [0.05060353 0.04210414 0.02960503]\n",
      "   [0.04992501 0.0407828  0.02917649]]\n",
      "\n",
      "  [[0.05274623 0.04528248 0.03921149]\n",
      "   [0.05274623 0.04528248 0.03921149]\n",
      "   [0.05256767 0.04449682 0.03760446]\n",
      "   ...\n",
      "   [0.04924648 0.04285408 0.02817656]\n",
      "   [0.05060353 0.04210414 0.02960503]\n",
      "   [0.04992501 0.0407828  0.02917649]]\n",
      "\n",
      "  [[0.05246054 0.04246125 0.03510464]\n",
      "   [0.05246054 0.04246125 0.03510464]\n",
      "   [0.05135347 0.04106849 0.03199771]\n",
      "   ...\n",
      "   [0.04971074 0.04221127 0.0289265 ]\n",
      "   [0.05053211 0.04163988 0.02924791]\n",
      "   [0.04978216 0.04067567 0.02714092]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04871081 0.03885437 0.02728377]\n",
      "   [0.04871081 0.03885437 0.02728377]\n",
      "   [0.04885365 0.03914006 0.02471252]\n",
      "   ...\n",
      "   [0.04924648 0.04153275 0.02785515]\n",
      "   [0.04910364 0.04110421 0.02764088]\n",
      "   [0.04860367 0.03914006 0.02606957]]\n",
      "\n",
      "  [[0.04835369 0.03860439 0.02510535]\n",
      "   [0.04835369 0.03860439 0.02510535]\n",
      "   [0.0483894  0.04056853 0.02506964]\n",
      "   ...\n",
      "   [0.04906792 0.04121134 0.02667667]\n",
      "   [0.04828227 0.04053282 0.02681951]\n",
      "   [0.04763946 0.03667595 0.02346261]]\n",
      "\n",
      "  [[0.04835369 0.04053282 0.02499821]\n",
      "   [0.04835369 0.04053282 0.02499821]\n",
      "   [0.04963931 0.04124705 0.02624813]\n",
      "   ...\n",
      "   [0.04849654 0.03817584 0.02303407]\n",
      "   [0.04678237 0.03492608 0.02242697]\n",
      "   [0.04792515 0.03428327 0.02228412]]]\n",
      "\n",
      "\n",
      " [[[0.04813942 0.04435397 0.03967574]\n",
      "   [0.04813942 0.04435397 0.03967574]\n",
      "   [0.05728162 0.05178202 0.05335333]\n",
      "   ...\n",
      "   [0.03510464 0.02989072 0.02106992]\n",
      "   [0.03967574 0.03514035 0.03028355]\n",
      "   [0.04449682 0.04206842 0.04181844]]\n",
      "\n",
      "  [[0.04813942 0.04435397 0.03967574]\n",
      "   [0.04813942 0.04435397 0.03967574]\n",
      "   [0.05728162 0.05178202 0.05335333]\n",
      "   ...\n",
      "   [0.03510464 0.02989072 0.02106992]\n",
      "   [0.03967574 0.03514035 0.03028355]\n",
      "   [0.04449682 0.04206842 0.04181844]]\n",
      "\n",
      "  [[0.04588958 0.04306835 0.03899721]\n",
      "   [0.04588958 0.04306835 0.03899721]\n",
      "   [0.05806728 0.05428184 0.05413899]\n",
      "   ...\n",
      "   [0.03614027 0.03089065 0.02214128]\n",
      "   [0.04085422 0.03789015 0.03249768]\n",
      "   [0.04506821 0.04292551 0.04463967]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04985358 0.04667524 0.04435397]\n",
      "   [0.04985358 0.04667524 0.04435397]\n",
      "   [0.03996143 0.03885437 0.03192629]\n",
      "   ...\n",
      "   [0.04181844 0.03874723 0.03328334]\n",
      "   [0.04424684 0.03767588 0.03521177]\n",
      "   [0.0447468  0.0398543  0.03531891]]\n",
      "\n",
      "  [[0.05513892 0.05042497 0.04956789]\n",
      "   [0.05513892 0.05042497 0.04956789]\n",
      "   [0.04956789 0.04506821 0.04056853]\n",
      "   ...\n",
      "   [0.03542604 0.03342618 0.02324834]\n",
      "   [0.03885437 0.03374759 0.03099779]\n",
      "   [0.04113992 0.03599743 0.03267624]]\n",
      "\n",
      "  [[0.04992501 0.04846082 0.04499679]\n",
      "   [0.04992501 0.04846082 0.04499679]\n",
      "   [0.04328262 0.04074709 0.03492608]\n",
      "   ...\n",
      "   [0.03696164 0.03553317 0.02460539]\n",
      "   [0.04206842 0.03706878 0.03060496]\n",
      "   [0.04060424 0.03617599 0.02939076]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.04888937 0.05349618 0.06935219]\n",
      "   [0.04888937 0.05349618 0.06935219]\n",
      "   [0.04903221 0.05346047 0.06906649]\n",
      "   ...\n",
      "   [0.04588958 0.04967503 0.0648168 ]\n",
      "   [0.04521106 0.04774659 0.06445968]\n",
      "   [0.04628241 0.04831798 0.06617384]]\n",
      "\n",
      "  [[0.04888937 0.05349618 0.06935219]\n",
      "   [0.04888937 0.05349618 0.06935219]\n",
      "   [0.04903221 0.05346047 0.06906649]\n",
      "   ...\n",
      "   [0.04588958 0.04967503 0.0648168 ]\n",
      "   [0.04521106 0.04774659 0.06445968]\n",
      "   [0.04628241 0.04831798 0.06617384]]\n",
      "\n",
      "  [[0.04906792 0.0538533  0.0696736 ]\n",
      "   [0.04906792 0.0538533  0.0696736 ]\n",
      "   [0.04881794 0.05392472 0.06913792]\n",
      "   ...\n",
      "   [0.0483894  0.05156774 0.06660239]\n",
      "   [0.04546104 0.04938933 0.06456681]\n",
      "   [0.04578244 0.04856796 0.06545961]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04346118 0.04703236 0.06006714]\n",
      "   [0.04346118 0.04703236 0.06006714]\n",
      "   [0.04292551 0.0462467  0.0593529 ]\n",
      "   ...\n",
      "   [0.04317549 0.04863938 0.0636026 ]\n",
      "   [0.04392543 0.04856796 0.06403114]\n",
      "   [0.04413971 0.0489965  0.06356689]]\n",
      "\n",
      "  [[0.04356832 0.04674666 0.05978144]\n",
      "   [0.04356832 0.04674666 0.05978144]\n",
      "   [0.04331833 0.04635383 0.05846011]\n",
      "   ...\n",
      "   [0.04331833 0.04871081 0.06335261]\n",
      "   [0.0432112  0.04856796 0.0629955 ]\n",
      "   [0.04371116 0.04878223 0.06356689]]\n",
      "\n",
      "  [[0.04385401 0.04749661 0.05924577]\n",
      "   [0.04385401 0.04749661 0.05924577]\n",
      "   [0.04285408 0.04649668 0.05867438]\n",
      "   ...\n",
      "   [0.04367545 0.04788944 0.06278123]\n",
      "   [0.04278266 0.04817513 0.0629955 ]\n",
      "   [0.0432112  0.04831798 0.06285265]]]\n",
      "\n",
      "\n",
      " [[[0.0273909  0.02546247 0.01574888]\n",
      "   [0.0273909  0.02546247 0.01574888]\n",
      "   [0.02717663 0.02542675 0.01578459]\n",
      "   ...\n",
      "   [0.02885508 0.02642668 0.01889151]\n",
      "   [0.02917649 0.02667667 0.01882008]\n",
      "   [0.02917649 0.0267838  0.01864153]]\n",
      "\n",
      "  [[0.0273909  0.02546247 0.01574888]\n",
      "   [0.0273909  0.02546247 0.01574888]\n",
      "   [0.02717663 0.02542675 0.01578459]\n",
      "   ...\n",
      "   [0.02885508 0.02642668 0.01889151]\n",
      "   [0.02917649 0.02667667 0.01882008]\n",
      "   [0.02917649 0.0267838  0.01864153]]\n",
      "\n",
      "  [[0.02728377 0.02535533 0.01574888]\n",
      "   [0.02728377 0.02535533 0.01574888]\n",
      "   [0.02674809 0.02521249 0.01571316]\n",
      "   ...\n",
      "   [0.02849796 0.02639097 0.01803443]\n",
      "   [0.02878366 0.02692665 0.01821299]\n",
      "   [0.0286051  0.02724805 0.01846297]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02803371 0.02596243 0.01617742]\n",
      "   [0.02803371 0.02596243 0.01617742]\n",
      "   [0.0276766  0.02531962 0.01592743]\n",
      "   ...\n",
      "   [0.0298193  0.02874795 0.01742733]\n",
      "   [0.02881937 0.02864081 0.01664167]\n",
      "   [0.02814085 0.02731948 0.01585601]]\n",
      "\n",
      "  [[0.02796229 0.0273909  0.01624884]\n",
      "   [0.02796229 0.0273909  0.01624884]\n",
      "   [0.0276766  0.02660524 0.01610599]\n",
      "   ...\n",
      "   [0.02928362 0.02856939 0.01807014]\n",
      "   [0.02889079 0.02760517 0.01685594]\n",
      "   [0.02889079 0.02635526 0.01596314]]\n",
      "\n",
      "  [[0.02785515 0.0276766  0.0164274 ]\n",
      "   [0.02785515 0.0276766  0.0164274 ]\n",
      "   [0.02789086 0.02696236 0.01628455]\n",
      "   ...\n",
      "   [0.02931933 0.02856939 0.0185701 ]\n",
      "   [0.02903364 0.02867652 0.01803443]\n",
      "   [0.02931933 0.02867652 0.01724877]]]\n",
      "\n",
      "\n",
      " [[[0.03206914 0.03278337 0.01878437]\n",
      "   [0.03206914 0.03278337 0.01878437]\n",
      "   [0.02881937 0.02746232 0.01596314]\n",
      "   ...\n",
      "   [0.03053353 0.03253339 0.01542747]\n",
      "   [0.03053353 0.03299764 0.01567745]\n",
      "   [0.0307478  0.03324762 0.0155346 ]]\n",
      "\n",
      "  [[0.03206914 0.03278337 0.01878437]\n",
      "   [0.03206914 0.03278337 0.01878437]\n",
      "   [0.02881937 0.02746232 0.01596314]\n",
      "   ...\n",
      "   [0.03053353 0.03253339 0.01542747]\n",
      "   [0.03053353 0.03299764 0.01567745]\n",
      "   [0.0307478  0.03324762 0.0155346 ]]\n",
      "\n",
      "  [[0.03310478 0.03624741 0.02196272]\n",
      "   [0.03310478 0.03624741 0.02196272]\n",
      "   [0.03114063 0.03178344 0.0188558 ]\n",
      "   ...\n",
      "   [0.03031926 0.03321191 0.01546318]\n",
      "   [0.03078352 0.03414042 0.01524891]\n",
      "   [0.03106921 0.03442611 0.01549889]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03274766 0.03467609 0.02299836]\n",
      "   [0.03274766 0.03467609 0.02299836]\n",
      "   [0.03346189 0.03556889 0.02346261]\n",
      "   ...\n",
      "   [0.03939004 0.04010428 0.04403257]\n",
      "   [0.03989001 0.04056853 0.04421113]\n",
      "   [0.04021141 0.04035426 0.04410399]]\n",
      "\n",
      "  [[0.03306907 0.03521177 0.02285551]\n",
      "   [0.03306907 0.03521177 0.02285551]\n",
      "   [0.03360474 0.03589029 0.02335547]\n",
      "   ...\n",
      "   [0.03946147 0.04028284 0.04499679]\n",
      "   [0.03964002 0.03974716 0.04410399]\n",
      "   [0.03981858 0.0398543  0.04385401]]\n",
      "\n",
      "  [[0.03267624 0.03478323 0.02256982]\n",
      "   [0.03267624 0.03478323 0.02256982]\n",
      "   [0.03253339 0.03510464 0.02242697]\n",
      "   ...\n",
      "   [0.04092565 0.04049711 0.04585387]\n",
      "   [0.04049711 0.03971145 0.04431826]\n",
      "   [0.03939004 0.03849725 0.04271124]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.06170988 0.06363831 0.07917292]\n",
      "   [0.06170988 0.06363831 0.07917292]\n",
      "   [0.06099564 0.06253125 0.0773159 ]\n",
      "   ...\n",
      "   [0.04031855 0.03885437 0.03081923]\n",
      "   [0.04031855 0.03667595 0.03121206]\n",
      "   [0.04113992 0.03764017 0.02992643]]\n",
      "\n",
      "  [[0.06170988 0.06363831 0.07917292]\n",
      "   [0.06170988 0.06363831 0.07917292]\n",
      "   [0.06099564 0.06253125 0.0773159 ]\n",
      "   ...\n",
      "   [0.04031855 0.03885437 0.03081923]\n",
      "   [0.04031855 0.03667595 0.03121206]\n",
      "   [0.04113992 0.03764017 0.02992643]]\n",
      "\n",
      "  [[0.06042426 0.06317406 0.07856581]\n",
      "   [0.06042426 0.06317406 0.07856581]\n",
      "   [0.06045997 0.06203128 0.0773159 ]\n",
      "   ...\n",
      "   [0.04113992 0.04046139 0.02967645]\n",
      "   [0.0407828  0.03696164 0.03064067]\n",
      "   [0.04092565 0.03764017 0.03078352]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06195986 0.06535248 0.08077995]\n",
      "   [0.06195986 0.06535248 0.08077995]\n",
      "   [0.06185272 0.0645311  0.08131562]\n",
      "   ...\n",
      "   [0.04424684 0.04296122 0.03824727]\n",
      "   [0.04210414 0.04021141 0.03260481]\n",
      "   [0.04085422 0.0395686  0.03010499]]\n",
      "\n",
      "  [[0.06449539 0.06760231 0.08310121]\n",
      "   [0.06449539 0.06760231 0.08310121]\n",
      "   [0.06374545 0.06770945 0.08438683]\n",
      "   ...\n",
      "   [0.04106849 0.0386401  0.02971216]\n",
      "   [0.04035426 0.03906864 0.02956932]\n",
      "   [0.0398543  0.03849725 0.02871224]]\n",
      "\n",
      "  [[0.0648168  0.06828084 0.08502964]\n",
      "   [0.0648168  0.06828084 0.08502964]\n",
      "   [0.06392401 0.06728091 0.08320834]\n",
      "   ...\n",
      "   [0.04067567 0.0383544  0.02746232]\n",
      "   [0.04003286 0.03814013 0.02803371]\n",
      "   [0.03992572 0.03853296 0.02724805]]]\n",
      "\n",
      "\n",
      " [[[0.04649668 0.0453539  0.04799657]\n",
      "   [0.04649668 0.0453539  0.04799657]\n",
      "   [0.04753232 0.04688951 0.04188986]\n",
      "   ...\n",
      "   [0.03385472 0.02885508 0.02035569]\n",
      "   [0.03435469 0.0304264  0.02074852]\n",
      "   [0.03517606 0.03146204 0.02242697]]\n",
      "\n",
      "  [[0.04649668 0.0453539  0.04799657]\n",
      "   [0.04649668 0.0453539  0.04799657]\n",
      "   [0.04753232 0.04688951 0.04188986]\n",
      "   ...\n",
      "   [0.03385472 0.02885508 0.02035569]\n",
      "   [0.03435469 0.0304264  0.02074852]\n",
      "   [0.03517606 0.03146204 0.02242697]]\n",
      "\n",
      "  [[0.03767588 0.03771159 0.03024784]\n",
      "   [0.03767588 0.03771159 0.03024784]\n",
      "   [0.04185415 0.04310406 0.03589029]\n",
      "   ...\n",
      "   [0.03549746 0.03199771 0.02267695]\n",
      "   [0.03664024 0.03310478 0.02346261]\n",
      "   [0.03724734 0.03531891 0.02431969]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03335476 0.03153346 0.01785587]\n",
      "   [0.03335476 0.03153346 0.01785587]\n",
      "   [0.0328548  0.02956932 0.01774873]\n",
      "   ...\n",
      "   [0.04413971 0.03953289 0.03699736]\n",
      "   [0.04585387 0.03867581 0.03724734]\n",
      "   [0.04128277 0.03514035 0.03139061]]\n",
      "\n",
      "  [[0.03374759 0.03249768 0.01924863]\n",
      "   [0.03374759 0.03249768 0.01924863]\n",
      "   [0.03346189 0.03064067 0.0191772 ]\n",
      "   ...\n",
      "   [0.04417542 0.0377473  0.03517606]\n",
      "   [0.04435397 0.03796157 0.03828298]\n",
      "   [0.03999714 0.03517606 0.02992643]]\n",
      "\n",
      "  [[0.03278337 0.0304264  0.01903435]\n",
      "   [0.03278337 0.0304264  0.01903435]\n",
      "   [0.03339047 0.03089065 0.01932005]\n",
      "   ...\n",
      "   [0.04378259 0.03817584 0.03592601]\n",
      "   [0.04178273 0.03574745 0.03467609]\n",
      "   [0.03842583 0.0325691  0.02603385]]]\n",
      "\n",
      "\n",
      " [[[0.04063996 0.04792515 0.05871009]\n",
      "   [0.04063996 0.04792515 0.05871009]\n",
      "   [0.03928291 0.04688951 0.05856724]\n",
      "   ...\n",
      "   [0.02871224 0.02517677 0.01789158]\n",
      "   [0.02971216 0.02553389 0.01924863]\n",
      "   [0.02928362 0.02539104 0.01803443]]\n",
      "\n",
      "  [[0.04063996 0.04792515 0.05871009]\n",
      "   [0.04063996 0.04792515 0.05871009]\n",
      "   [0.03928291 0.04688951 0.05856724]\n",
      "   ...\n",
      "   [0.02871224 0.02517677 0.01789158]\n",
      "   [0.02971216 0.02553389 0.01924863]\n",
      "   [0.02928362 0.02539104 0.01803443]]\n",
      "\n",
      "  [[0.03935433 0.04399686 0.05499607]\n",
      "   [0.03935433 0.04399686 0.05499607]\n",
      "   [0.03910435 0.04542533 0.05831726]\n",
      "   ...\n",
      "   [0.02885508 0.0243554  0.01714163]\n",
      "   [0.02996214 0.02542675 0.0185701 ]\n",
      "   [0.02956932 0.02521249 0.01760589]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03131919 0.02899793 0.02781944]\n",
      "   [0.03131919 0.02899793 0.02781944]\n",
      "   [0.03128348 0.02814085 0.02571245]\n",
      "   ...\n",
      "   [0.0304264  0.0273909  0.02456967]\n",
      "   [0.03306907 0.02689094 0.0206771 ]\n",
      "   [0.04238983 0.04192558 0.04910364]]\n",
      "\n",
      "  [[0.0325691  0.0307478  0.03099779]\n",
      "   [0.0325691  0.0307478  0.03099779]\n",
      "   [0.03167631 0.02881937 0.02649811]\n",
      "   ...\n",
      "   [0.03028355 0.0252482  0.02167702]\n",
      "   [0.03260481 0.02889079 0.02210556]\n",
      "   [0.04046139 0.04253267 0.04574673]]\n",
      "\n",
      "  [[0.03406899 0.0331762  0.03417613]\n",
      "   [0.03406899 0.0331762  0.03417613]\n",
      "   [0.03246197 0.03081923 0.02928362]\n",
      "   ...\n",
      "   [0.02949789 0.02421256 0.01882008]\n",
      "   [0.03249768 0.02710521 0.0197843 ]\n",
      "   [0.03892579 0.03635455 0.03964002]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03678309 0.03171202 0.02574816]\n",
      "   [0.03678309 0.03171202 0.02574816]\n",
      "   [0.04010428 0.03160489 0.02771231]\n",
      "   ...\n",
      "   [0.04246125 0.03703307 0.03596172]\n",
      "   [0.04346118 0.03689022 0.0386401 ]\n",
      "   [0.04010428 0.03839011 0.03521177]]\n",
      "\n",
      "  [[0.03678309 0.03171202 0.02574816]\n",
      "   [0.03678309 0.03171202 0.02574816]\n",
      "   [0.04010428 0.03160489 0.02771231]\n",
      "   ...\n",
      "   [0.04246125 0.03703307 0.03596172]\n",
      "   [0.04346118 0.03689022 0.0386401 ]\n",
      "   [0.04010428 0.03839011 0.03521177]]\n",
      "\n",
      "  [[0.04035426 0.031962   0.02796229]\n",
      "   [0.04035426 0.031962   0.02796229]\n",
      "   [0.04781801 0.03821156 0.03549746]\n",
      "   ...\n",
      "   [0.04035426 0.03714021 0.04024712]\n",
      "   [0.04203271 0.03510464 0.03564031]\n",
      "   [0.04249696 0.03385472 0.0307478 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04392543 0.03949718 0.03546175]\n",
      "   [0.04392543 0.03949718 0.03546175]\n",
      "   [0.04785372 0.04638954 0.04117563]\n",
      "   ...\n",
      "   [0.04249696 0.04221127 0.04324691]\n",
      "   [0.04235412 0.04203271 0.04238983]\n",
      "   [0.04096136 0.04081851 0.04035426]]\n",
      "\n",
      "  [[0.04221127 0.04010428 0.03596172]\n",
      "   [0.04221127 0.04010428 0.03596172]\n",
      "   [0.04128277 0.04060424 0.031962  ]\n",
      "   ...\n",
      "   [0.04338976 0.041997   0.04231841]\n",
      "   [0.0432112  0.04171131 0.04235412]\n",
      "   [0.04274695 0.04178273 0.04181844]]\n",
      "\n",
      "  [[0.03535462 0.02789086 0.02081994]\n",
      "   [0.03535462 0.02789086 0.02081994]\n",
      "   [0.03639026 0.02810514 0.02007   ]\n",
      "   ...\n",
      "   [0.04085422 0.04185415 0.04296122]\n",
      "   [0.04224698 0.041997   0.04306835]\n",
      "   [0.04267552 0.04228269 0.04335405]]]\n",
      "\n",
      "\n",
      " [[[0.03631883 0.03214056 0.02564103]\n",
      "   [0.03631883 0.03214056 0.02564103]\n",
      "   [0.0362117  0.03278337 0.02378402]\n",
      "   ...\n",
      "   [0.03492608 0.03178344 0.02746232]\n",
      "   [0.05049639 0.04753232 0.0395686 ]\n",
      "   [0.03846154 0.03403328 0.03189058]]\n",
      "\n",
      "  [[0.03631883 0.03214056 0.02564103]\n",
      "   [0.03631883 0.03214056 0.02564103]\n",
      "   [0.0362117  0.03278337 0.02378402]\n",
      "   ...\n",
      "   [0.03492608 0.03178344 0.02746232]\n",
      "   [0.05049639 0.04753232 0.0395686 ]\n",
      "   [0.03846154 0.03403328 0.03189058]]\n",
      "\n",
      "  [[0.03331905 0.03142633 0.02356975]\n",
      "   [0.03331905 0.03142633 0.02356975]\n",
      "   [0.0331762  0.03356903 0.02421256]\n",
      "   ...\n",
      "   [0.03442611 0.03053353 0.0255696 ]\n",
      "   [0.03842583 0.03678309 0.03053353]\n",
      "   [0.03599743 0.03349761 0.027998  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0471752  0.05113921 0.05246054]\n",
      "   [0.0471752  0.05113921 0.05246054]\n",
      "   [0.03856868 0.03746161 0.03406899]\n",
      "   ...\n",
      "   [0.04374687 0.04249696 0.04496107]\n",
      "   [0.04124705 0.04142561 0.04024712]\n",
      "   [0.03999714 0.03321191 0.03328334]]\n",
      "\n",
      "  [[0.04771088 0.05206771 0.05278194]\n",
      "   [0.04771088 0.05206771 0.05278194]\n",
      "   [0.038033   0.0322477  0.03085494]\n",
      "   ...\n",
      "   [0.04531819 0.04146132 0.04860367]\n",
      "   [0.04438969 0.04453253 0.04749661]\n",
      "   [0.04878223 0.04728234 0.0401757 ]]\n",
      "\n",
      "  [[0.04288979 0.04074709 0.04092565]\n",
      "   [0.04288979 0.04074709 0.04092565]\n",
      "   [0.03778302 0.03517606 0.0295336 ]\n",
      "   ...\n",
      "   [0.04842511 0.04699664 0.05246054]\n",
      "   [0.04513963 0.04338976 0.03753303]\n",
      "   [0.05321049 0.04853225 0.04360403]]]\n",
      "\n",
      "\n",
      " [[[0.04303264 0.04060424 0.03299764]\n",
      "   [0.04303264 0.04060424 0.03299764]\n",
      "   [0.04667524 0.04660381 0.04088994]\n",
      "   ...\n",
      "   [0.05213913 0.0444254  0.04356832]\n",
      "   [0.04935362 0.04524677 0.04267552]\n",
      "   [0.04403257 0.04217556 0.03578316]]\n",
      "\n",
      "  [[0.04303264 0.04060424 0.03299764]\n",
      "   [0.04303264 0.04060424 0.03299764]\n",
      "   [0.04667524 0.04660381 0.04088994]\n",
      "   ...\n",
      "   [0.05213913 0.0444254  0.04356832]\n",
      "   [0.04935362 0.04524677 0.04267552]\n",
      "   [0.04403257 0.04217556 0.03578316]]\n",
      "\n",
      "  [[0.04428255 0.04399686 0.03931862]\n",
      "   [0.04428255 0.04399686 0.03931862]\n",
      "   [0.04638954 0.04453253 0.04103278]\n",
      "   ...\n",
      "   [0.04585387 0.03960431 0.03710449]\n",
      "   [0.04878223 0.04463967 0.03960431]\n",
      "   [0.04467538 0.04242554 0.03664024]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05028212 0.04753232 0.04346118]\n",
      "   [0.05028212 0.04753232 0.04346118]\n",
      "   [0.04438969 0.04331833 0.03706878]\n",
      "   ...\n",
      "   [0.03714021 0.03789015 0.02531962]\n",
      "   [0.03667595 0.03789015 0.02606957]\n",
      "   [0.03721163 0.03746161 0.02671238]]\n",
      "\n",
      "  [[0.04767517 0.04721091 0.04346118]\n",
      "   [0.04767517 0.04721091 0.04346118]\n",
      "   [0.04453253 0.04292551 0.03964002]\n",
      "   ...\n",
      "   [0.03649739 0.03714021 0.0249625 ]\n",
      "   [0.03599743 0.03735447 0.02274838]\n",
      "   [0.03635455 0.03724734 0.02456967]]\n",
      "\n",
      "  [[0.04942504 0.04513963 0.04346118]\n",
      "   [0.04942504 0.04513963 0.04346118]\n",
      "   [0.04581816 0.04203271 0.03678309]\n",
      "   ...\n",
      "   [0.03692593 0.03814013 0.02771231]\n",
      "   [0.03614027 0.03778302 0.02406971]\n",
      "   [0.03671166 0.03753303 0.02478394]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.03099779 0.02310549 0.01199914]\n",
      "   [0.03099779 0.02310549 0.01199914]\n",
      "   [0.03064067 0.02346261 0.01174916]\n",
      "   ...\n",
      "   [0.03417613 0.03124777 0.01774873]\n",
      "   [0.03481894 0.03139061 0.01753446]\n",
      "   [0.03446182 0.03146204 0.01749875]]\n",
      "\n",
      "  [[0.03099779 0.02310549 0.01199914]\n",
      "   [0.03099779 0.02310549 0.01199914]\n",
      "   [0.03064067 0.02346261 0.01174916]\n",
      "   ...\n",
      "   [0.03417613 0.03124777 0.01774873]\n",
      "   [0.03481894 0.03139061 0.01753446]\n",
      "   [0.03446182 0.03146204 0.01749875]]\n",
      "\n",
      "  [[0.03096207 0.02335547 0.01210628]\n",
      "   [0.03096207 0.02335547 0.01210628]\n",
      "   [0.0307478  0.02331976 0.01189201]\n",
      "   ...\n",
      "   [0.03471181 0.03121206 0.01792729]\n",
      "   [0.03464038 0.03131919 0.01807014]\n",
      "   [0.03460467 0.03149775 0.01839154]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02978359 0.02028427 0.01092779]\n",
      "   [0.02978359 0.02028427 0.01092779]\n",
      "   [0.0301407  0.02053425 0.0109635 ]\n",
      "   ...\n",
      "   [0.03203342 0.02503393 0.01267767]\n",
      "   [0.03156918 0.0249625  0.01228484]\n",
      "   [0.03142633 0.02492679 0.01235626]]\n",
      "\n",
      "  [[0.02971216 0.02064138 0.01085637]\n",
      "   [0.02971216 0.02064138 0.01085637]\n",
      "   [0.02978359 0.02064138 0.01089208]\n",
      "   ...\n",
      "   [0.03199771 0.02492679 0.01249911]\n",
      "   [0.03149775 0.02503393 0.01264195]\n",
      "   [0.03156918 0.02528391 0.01249911]]\n",
      "\n",
      "  [[0.02992643 0.02007    0.01074923]\n",
      "   [0.02992643 0.02007    0.01074923]\n",
      "   [0.0295336  0.02021284 0.01110635]\n",
      "   ...\n",
      "   [0.03167631 0.02478394 0.0127848 ]\n",
      "   [0.03199771 0.02485537 0.01249911]\n",
      "   [0.03146204 0.02485537 0.0124634 ]]]\n",
      "\n",
      "\n",
      " [[[0.04949646 0.04453253 0.0456396 ]\n",
      "   [0.04949646 0.04453253 0.0456396 ]\n",
      "   [0.03610456 0.03106921 0.02774802]\n",
      "   ...\n",
      "   [0.03942576 0.03617599 0.03746161]\n",
      "   [0.03828298 0.03478323 0.03431898]\n",
      "   [0.0368188  0.03310478 0.03085494]]\n",
      "\n",
      "  [[0.04949646 0.04453253 0.0456396 ]\n",
      "   [0.04949646 0.04453253 0.0456396 ]\n",
      "   [0.03610456 0.03106921 0.02774802]\n",
      "   ...\n",
      "   [0.03942576 0.03617599 0.03746161]\n",
      "   [0.03828298 0.03478323 0.03431898]\n",
      "   [0.0368188  0.03310478 0.03085494]]\n",
      "\n",
      "  [[0.04978216 0.04517534 0.04774659]\n",
      "   [0.04978216 0.04517534 0.04774659]\n",
      "   [0.0413899  0.03631883 0.03385472]\n",
      "   ...\n",
      "   [0.03724734 0.03364046 0.03314049]\n",
      "   [0.03721163 0.03306907 0.03139061]\n",
      "   [0.03710449 0.03299764 0.03117635]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03478323 0.03124777 0.02549818]\n",
      "   [0.03478323 0.03124777 0.02549818]\n",
      "   [0.03474752 0.03114063 0.02492679]\n",
      "   ...\n",
      "   [0.0426041  0.0392472  0.04424684]\n",
      "   [0.04246125 0.03935433 0.041997  ]\n",
      "   [0.03685451 0.0313549  0.02939076]]\n",
      "\n",
      "  [[0.03435469 0.03064067 0.0243554 ]\n",
      "   [0.03435469 0.03064067 0.0243554 ]\n",
      "   [0.03424755 0.03035497 0.02439111]\n",
      "   ...\n",
      "   [0.0377473  0.03303336 0.03481894]\n",
      "   [0.03642597 0.0316406  0.03010499]\n",
      "   [0.03349761 0.02681951 0.02328405]]\n",
      "\n",
      "  [[0.03421184 0.03096207 0.02399829]\n",
      "   [0.03421184 0.03096207 0.02399829]\n",
      "   [0.03446182 0.0310335  0.02499821]\n",
      "   ...\n",
      "   [0.03689022 0.03185487 0.03210485]\n",
      "   [0.03253339 0.02742661 0.02206985]\n",
      "   [0.0331762  0.02764088 0.02378402]]]\n",
      "\n",
      "\n",
      " [[[0.03353332 0.03121206 0.02321263]\n",
      "   [0.03353332 0.03121206 0.02321263]\n",
      "   [0.03314049 0.03160489 0.02353403]\n",
      "   ...\n",
      "   [0.03392615 0.03049782 0.02724805]\n",
      "   [0.03281908 0.02917649 0.02392686]\n",
      "   [0.03239054 0.02971216 0.02139133]]\n",
      "\n",
      "  [[0.03353332 0.03121206 0.02321263]\n",
      "   [0.03353332 0.03121206 0.02321263]\n",
      "   [0.03314049 0.03160489 0.02353403]\n",
      "   ...\n",
      "   [0.03392615 0.03049782 0.02724805]\n",
      "   [0.03281908 0.02917649 0.02392686]\n",
      "   [0.03239054 0.02971216 0.02139133]]\n",
      "\n",
      "  [[0.03389044 0.03106921 0.0249625 ]\n",
      "   [0.03389044 0.03106921 0.0249625 ]\n",
      "   [0.03299764 0.03046211 0.02292693]\n",
      "   ...\n",
      "   [0.03392615 0.02964074 0.02610528]\n",
      "   [0.03278337 0.02939076 0.02271266]\n",
      "   [0.03235483 0.02996214 0.02085565]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0310335  0.02996214 0.01603457]\n",
      "   [0.0310335  0.02996214 0.01603457]\n",
      "   [0.03096207 0.02928362 0.01607028]\n",
      "   ...\n",
      "   [0.04388972 0.03467609 0.03039069]\n",
      "   [0.04313977 0.03567602 0.03335476]\n",
      "   [0.04653239 0.04242554 0.04335405]]\n",
      "\n",
      "  [[0.03139061 0.02978359 0.01621313]\n",
      "   [0.03139061 0.02978359 0.01621313]\n",
      "   [0.03114063 0.02964074 0.01624884]\n",
      "   ...\n",
      "   [0.04981787 0.04431826 0.04171131]\n",
      "   [0.05063924 0.04599671 0.04696093]\n",
      "   [0.05603171 0.05285337 0.05431755]]\n",
      "\n",
      "  [[0.0313549  0.02978359 0.01696307]\n",
      "   [0.0313549  0.02978359 0.01696307]\n",
      "   [0.03121206 0.0301407  0.01653453]\n",
      "   ...\n",
      "   [0.0401757  0.03331905 0.03006928]\n",
      "   [0.04728234 0.04392543 0.04085422]\n",
      "   [0.0483894  0.04835369 0.04181844]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03128348 0.0307478  0.01860581]\n",
      "   [0.03128348 0.0307478  0.01860581]\n",
      "   [0.03099779 0.02989072 0.01778444]\n",
      "   ...\n",
      "   [0.03021213 0.03110492 0.01499893]\n",
      "   [0.0304264  0.03160489 0.01514178]\n",
      "   [0.03056924 0.03181916 0.01539176]]\n",
      "\n",
      "  [[0.03128348 0.0307478  0.01860581]\n",
      "   [0.03128348 0.0307478  0.01860581]\n",
      "   [0.03099779 0.02989072 0.01778444]\n",
      "   ...\n",
      "   [0.03021213 0.03110492 0.01499893]\n",
      "   [0.0304264  0.03160489 0.01514178]\n",
      "   [0.03056924 0.03181916 0.01539176]]\n",
      "\n",
      "  [[0.03149775 0.02864081 0.01832012]\n",
      "   [0.03149775 0.02864081 0.01832012]\n",
      "   [0.03060496 0.02842654 0.01624884]\n",
      "   ...\n",
      "   [0.0304264  0.03221199 0.01539176]\n",
      "   [0.0304264  0.03278337 0.01578459]\n",
      "   [0.03085494 0.031962   0.01589172]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03099779 0.02885508 0.02060567]\n",
      "   [0.03099779 0.02885508 0.02060567]\n",
      "   [0.03146204 0.02996214 0.02239126]\n",
      "   ...\n",
      "   [0.0343904  0.03556889 0.02724805]\n",
      "   [0.03631883 0.03442611 0.02942647]\n",
      "   [0.03181916 0.02614099 0.01789158]]\n",
      "\n",
      "  [[0.0337833  0.03046211 0.02417685]\n",
      "   [0.0337833  0.03046211 0.02417685]\n",
      "   [0.03414042 0.03142633 0.02503393]\n",
      "   ...\n",
      "   [0.04142561 0.03939004 0.03274766]\n",
      "   [0.04281837 0.04099707 0.03671166]\n",
      "   [0.03446182 0.0316406  0.02553389]]\n",
      "\n",
      "  [[0.03642597 0.03278337 0.027998  ]\n",
      "   [0.03642597 0.03278337 0.027998  ]\n",
      "   [0.0368188  0.03231912 0.02699807]\n",
      "   ...\n",
      "   [0.03703307 0.03428327 0.02846225]\n",
      "   [0.04113992 0.03531891 0.03139061]\n",
      "   [0.03821156 0.03535462 0.03171202]]]\n",
      "\n",
      "\n",
      " [[[0.02756946 0.01849868 0.01010642]\n",
      "   [0.02756946 0.01849868 0.01010642]\n",
      "   [0.02703378 0.01864153 0.01021356]\n",
      "   ...\n",
      "   [0.02810514 0.02139133 0.01235626]\n",
      "   [0.02796229 0.02210556 0.01267767]\n",
      "   [0.02796229 0.02189129 0.01328477]]\n",
      "\n",
      "  [[0.02756946 0.01849868 0.01010642]\n",
      "   [0.02756946 0.01849868 0.01010642]\n",
      "   [0.02703378 0.01864153 0.01021356]\n",
      "   ...\n",
      "   [0.02810514 0.02139133 0.01235626]\n",
      "   [0.02796229 0.02210556 0.01267767]\n",
      "   [0.02796229 0.02189129 0.01328477]]\n",
      "\n",
      "  [[0.02764088 0.01867724 0.01024927]\n",
      "   [0.02764088 0.01867724 0.01024927]\n",
      "   [0.02753375 0.01864153 0.01017784]\n",
      "   ...\n",
      "   [0.02789086 0.02031998 0.01182058]\n",
      "   [0.02746232 0.0209985  0.01210628]\n",
      "   [0.02796229 0.02135562 0.01235626]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02731948 0.01874866 0.01021356]\n",
      "   [0.02731948 0.01874866 0.01021356]\n",
      "   [0.02756946 0.01871295 0.01028498]\n",
      "   ...\n",
      "   [0.02689094 0.01846297 0.01014213]\n",
      "   [0.02724805 0.01849868 0.00999929]\n",
      "   [0.02731948 0.0182487  0.01042783]]\n",
      "\n",
      "  [[0.02749804 0.01910578 0.01028498]\n",
      "   [0.02749804 0.01910578 0.01028498]\n",
      "   [0.02760517 0.01860581 0.01021356]\n",
      "   ...\n",
      "   [0.02735519 0.01821299 0.01024927]\n",
      "   [0.02731948 0.01828441 0.00971359]\n",
      "   [0.02714092 0.01817727 0.01039211]]\n",
      "\n",
      "  [[0.02753375 0.01860581 0.01017784]\n",
      "   [0.02753375 0.01860581 0.01017784]\n",
      "   [0.02731948 0.01903435 0.01039211]\n",
      "   ...\n",
      "   [0.02706949 0.01810585 0.0103564 ]\n",
      "   [0.02681951 0.01799871 0.01014213]\n",
      "   [0.02685522 0.01789158 0.01046354]]]\n",
      "\n",
      "\n",
      " [[[0.04735376 0.05017499 0.06060281]\n",
      "   [0.04735376 0.05017499 0.06060281]\n",
      "   [0.04878223 0.0514249  0.0648168 ]\n",
      "   ...\n",
      "   [0.03935433 0.0368188  0.03846154]\n",
      "   [0.0407828  0.03878294 0.04485394]\n",
      "   [0.04174702 0.03989001 0.04696093]]\n",
      "\n",
      "  [[0.04735376 0.05017499 0.06060281]\n",
      "   [0.04735376 0.05017499 0.06060281]\n",
      "   [0.04878223 0.0514249  0.0648168 ]\n",
      "   ...\n",
      "   [0.03935433 0.0368188  0.03846154]\n",
      "   [0.0407828  0.03878294 0.04485394]\n",
      "   [0.04174702 0.03989001 0.04696093]]\n",
      "\n",
      "  [[0.0508178  0.05221056 0.0642097 ]\n",
      "   [0.0508178  0.05221056 0.0642097 ]\n",
      "   [0.04113992 0.04149704 0.04817513]\n",
      "   ...\n",
      "   [0.04013999 0.03799729 0.04153275]\n",
      "   [0.0398543  0.03814013 0.04342547]\n",
      "   [0.04085422 0.03892579 0.04403257]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04035426 0.03824727 0.03981858]\n",
      "   [0.04035426 0.03824727 0.03981858]\n",
      "   [0.04121134 0.03989001 0.04246125]\n",
      "   ...\n",
      "   [0.04038997 0.04306835 0.04588958]\n",
      "   [0.04478252 0.04485394 0.05321049]\n",
      "   [0.05060353 0.05256767 0.06338833]]\n",
      "\n",
      "  [[0.04367545 0.04206842 0.04824656]\n",
      "   [0.04367545 0.04206842 0.04824656]\n",
      "   [0.03939004 0.03781873 0.04313977]\n",
      "   ...\n",
      "   [0.04771088 0.0468538  0.05674595]\n",
      "   [0.04756803 0.04663952 0.05831726]\n",
      "   [0.0514249  0.05231769 0.06460253]]\n",
      "\n",
      "  [[0.04524677 0.04413971 0.05210342]\n",
      "   [0.04524677 0.04413971 0.05210342]\n",
      "   [0.03999714 0.03874723 0.04367545]\n",
      "   ...\n",
      "   [0.04896079 0.05099636 0.06285265]\n",
      "   [0.04560389 0.04567531 0.05746018]\n",
      "   [0.04835369 0.04938933 0.05699593]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.04031855 0.03574745 0.04042568]\n",
      "   [0.04031855 0.03574745 0.04042568]\n",
      "   [0.04053282 0.03614027 0.04767517]\n",
      "   ...\n",
      "   [0.0374259  0.03492608 0.02846225]\n",
      "   [0.03671166 0.03314049 0.02628384]\n",
      "   [0.03567602 0.02989072 0.02371259]]\n",
      "\n",
      "  [[0.04031855 0.03574745 0.04042568]\n",
      "   [0.04031855 0.03574745 0.04042568]\n",
      "   [0.04053282 0.03614027 0.04767517]\n",
      "   ...\n",
      "   [0.0374259  0.03492608 0.02846225]\n",
      "   [0.03671166 0.03314049 0.02628384]\n",
      "   [0.03567602 0.02989072 0.02371259]]\n",
      "\n",
      "  [[0.03871152 0.03299764 0.03024784]\n",
      "   [0.03871152 0.03299764 0.03024784]\n",
      "   [0.04196129 0.03810442 0.04713949]\n",
      "   ...\n",
      "   [0.03689022 0.03521177 0.02835512]\n",
      "   [0.03514035 0.03160489 0.0234269 ]\n",
      "   [0.03242626 0.02510535 0.01746304]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03624741 0.03385472 0.02421256]\n",
      "   [0.03624741 0.03385472 0.02421256]\n",
      "   [0.03649739 0.03496179 0.02456967]\n",
      "   ...\n",
      "   [0.0328548  0.02735519 0.01782016]\n",
      "   [0.03242626 0.02621241 0.0173559 ]\n",
      "   [0.03260481 0.02606957 0.01749875]]\n",
      "\n",
      "  [[0.03617599 0.03471181 0.02481966]\n",
      "   [0.03617599 0.03471181 0.02481966]\n",
      "   [0.03628312 0.03453325 0.02442683]\n",
      "   ...\n",
      "   [0.03335476 0.027998   0.01717735]\n",
      "   [0.03267624 0.0261767  0.01682023]\n",
      "   [0.03314049 0.02589101 0.01778444]]\n",
      "\n",
      "  [[0.03639026 0.03467609 0.0243554 ]\n",
      "   [0.03639026 0.03467609 0.0243554 ]\n",
      "   [0.03642597 0.03446182 0.0243554 ]\n",
      "   ...\n",
      "   [0.03339047 0.02656953 0.01717735]\n",
      "   [0.03210485 0.0258553  0.01667738]\n",
      "   [0.03271195 0.02635526 0.01742733]]]\n",
      "\n",
      "\n",
      " [[[0.02531962 0.01935576 0.01060638]\n",
      "   [0.02531962 0.01935576 0.01060638]\n",
      "   [0.0249625  0.01867724 0.01074923]\n",
      "   ...\n",
      "   [0.02614099 0.02199843 0.01274909]\n",
      "   [0.02664095 0.02364117 0.01407042]\n",
      "   [0.02714092 0.02431969 0.01364188]]\n",
      "\n",
      "  [[0.02531962 0.01935576 0.01060638]\n",
      "   [0.02531962 0.01935576 0.01060638]\n",
      "   [0.0249625  0.01867724 0.01074923]\n",
      "   ...\n",
      "   [0.02614099 0.02199843 0.01274909]\n",
      "   [0.02664095 0.02364117 0.01407042]\n",
      "   [0.02714092 0.02431969 0.01364188]]\n",
      "\n",
      "  [[0.02456967 0.01828441 0.00967788]\n",
      "   [0.02456967 0.01828441 0.00967788]\n",
      "   [0.02421256 0.0167488  0.00992786]\n",
      "   ...\n",
      "   [0.02674809 0.02360546 0.01371331]\n",
      "   [0.02692665 0.02356975 0.01421327]\n",
      "   [0.02696236 0.02392686 0.01321334]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02449825 0.01828441 0.0103564 ]\n",
      "   [0.02449825 0.01828441 0.0103564 ]\n",
      "   [0.02521249 0.02092708 0.01146347]\n",
      "   ...\n",
      "   [0.02503393 0.01874866 0.01067781]\n",
      "   [0.02389115 0.01699879 0.00928505]\n",
      "   [0.02492679 0.01724877 0.00953503]]\n",
      "\n",
      "  [[0.02489108 0.01785587 0.00999929]\n",
      "   [0.02489108 0.01785587 0.00999929]\n",
      "   [0.02528391 0.02074852 0.01103493]\n",
      "   ...\n",
      "   [0.02442683 0.01749875 0.00960646]\n",
      "   [0.02414113 0.01664167 0.00924934]\n",
      "   [0.0243554  0.01707021 0.00939219]]\n",
      "\n",
      "  [[0.02478394 0.01849868 0.0103564 ]\n",
      "   [0.02478394 0.01849868 0.0103564 ]\n",
      "   [0.02521249 0.01889151 0.01174916]\n",
      "   ...\n",
      "   [0.0246411  0.0182487  0.00939219]\n",
      "   [0.02428398 0.0176416  0.00964217]\n",
      "   [0.02439111 0.01807014 0.01007071]]]\n",
      "\n",
      "\n",
      " [[[0.03178344 0.02614099 0.01942718]\n",
      "   [0.03178344 0.02614099 0.01942718]\n",
      "   [0.03178344 0.02696236 0.01971288]\n",
      "   ...\n",
      "   [0.03203342 0.02849796 0.01996286]\n",
      "   [0.03192629 0.02803371 0.01889151]\n",
      "   [0.03171202 0.02867652 0.01889151]]\n",
      "\n",
      "  [[0.03178344 0.02614099 0.01942718]\n",
      "   [0.03178344 0.02614099 0.01942718]\n",
      "   [0.03178344 0.02696236 0.01971288]\n",
      "   ...\n",
      "   [0.03203342 0.02849796 0.01996286]\n",
      "   [0.03192629 0.02803371 0.01889151]\n",
      "   [0.03171202 0.02867652 0.01889151]]\n",
      "\n",
      "  [[0.03181916 0.02764088 0.0191772 ]\n",
      "   [0.03181916 0.02764088 0.0191772 ]\n",
      "   [0.03210485 0.02771231 0.01953432]\n",
      "   ...\n",
      "   [0.03174773 0.02889079 0.02007   ]\n",
      "   [0.03189058 0.02846225 0.02035569]\n",
      "   [0.031962   0.02903364 0.01964145]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03346189 0.03024784 0.02306978]\n",
      "   [0.03346189 0.03024784 0.02306978]\n",
      "   [0.03206914 0.02824798 0.01946289]\n",
      "   ...\n",
      "   [0.03128348 0.02646239 0.01803443]\n",
      "   [0.03131919 0.02660524 0.0182487 ]\n",
      "   [0.03171202 0.02664095 0.0182487 ]]\n",
      "\n",
      "  [[0.03331905 0.02999786 0.02210556]\n",
      "   [0.03331905 0.02999786 0.02210556]\n",
      "   [0.03306907 0.02896222 0.02178416]\n",
      "   ...\n",
      "   [0.0313549  0.02696236 0.01785587]\n",
      "   [0.03146204 0.02724805 0.01817727]\n",
      "   [0.03178344 0.02692665 0.0182487 ]]\n",
      "\n",
      "  [[0.03171202 0.02742661 0.01842725]\n",
      "   [0.03171202 0.02742661 0.01842725]\n",
      "   [0.03221199 0.02806942 0.01974859]\n",
      "   ...\n",
      "   [0.03142633 0.02656953 0.01782016]\n",
      "   [0.03124777 0.02656953 0.01853439]\n",
      "   [0.03117635 0.02592672 0.01803443]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.0456396  0.0313549  0.0234269 ]\n",
      "   [0.0456396  0.0313549  0.0234269 ]\n",
      "   [0.04449682 0.02964074 0.02071281]\n",
      "   ...\n",
      "   [0.04663952 0.03031926 0.02181987]\n",
      "   [0.0462467  0.0304264  0.02317692]\n",
      "   [0.04921077 0.03374759 0.02574816]]\n",
      "\n",
      "  [[0.0456396  0.0313549  0.0234269 ]\n",
      "   [0.0456396  0.0313549  0.0234269 ]\n",
      "   [0.04449682 0.02964074 0.02071281]\n",
      "   ...\n",
      "   [0.04663952 0.03031926 0.02181987]\n",
      "   [0.0462467  0.0304264  0.02317692]\n",
      "   [0.04921077 0.03374759 0.02574816]]\n",
      "\n",
      "  [[0.04638954 0.0316406  0.02596243]\n",
      "   [0.04638954 0.0316406  0.02596243]\n",
      "   [0.04428255 0.02989072 0.01910578]\n",
      "   ...\n",
      "   [0.04696093 0.03024784 0.02231983]\n",
      "   [0.04699664 0.03110492 0.02510535]\n",
      "   [0.04999643 0.03449754 0.02614099]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04642526 0.03078352 0.02421256]\n",
      "   [0.04642526 0.03078352 0.02421256]\n",
      "   [0.04646097 0.0349975  0.02864081]\n",
      "   ...\n",
      "   [0.04610385 0.03099779 0.02510535]\n",
      "   [0.04660381 0.0304264  0.02249839]\n",
      "   [0.04367545 0.02874795 0.02071281]]\n",
      "\n",
      "  [[0.04817513 0.03471181 0.02796229]\n",
      "   [0.04817513 0.03471181 0.02796229]\n",
      "   [0.04906792 0.03578316 0.0307478 ]\n",
      "   ...\n",
      "   [0.04478252 0.0298193  0.02274838]\n",
      "   [0.04506821 0.02817656 0.01989144]\n",
      "   [0.0438183  0.0273909  0.02024855]]\n",
      "\n",
      "  [[0.04878223 0.03778302 0.03321191]\n",
      "   [0.04878223 0.03778302 0.03321191]\n",
      "   [0.04878223 0.03699736 0.03192629]\n",
      "   ...\n",
      "   [0.04542533 0.0292122  0.02024855]\n",
      "   [0.04713949 0.03010499 0.02296264]\n",
      "   [0.04931791 0.03210485 0.02656953]]]\n",
      "\n",
      "\n",
      " [[[0.04985358 0.04885365 0.05521034]\n",
      "   [0.04985358 0.04885365 0.05521034]\n",
      "   [0.04917506 0.04696093 0.05013927]\n",
      "   ...\n",
      "   [0.03235483 0.03185487 0.02092708]\n",
      "   [0.03314049 0.03117635 0.02128419]\n",
      "   [0.03349761 0.03031926 0.02149846]]\n",
      "\n",
      "  [[0.04985358 0.04885365 0.05521034]\n",
      "   [0.04985358 0.04885365 0.05521034]\n",
      "   [0.04917506 0.04696093 0.05013927]\n",
      "   ...\n",
      "   [0.03235483 0.03185487 0.02092708]\n",
      "   [0.03314049 0.03117635 0.02128419]\n",
      "   [0.03349761 0.03031926 0.02149846]]\n",
      "\n",
      "  [[0.04506821 0.04278266 0.04546104]\n",
      "   [0.04506821 0.04278266 0.04546104]\n",
      "   [0.04649668 0.04235412 0.04560389]\n",
      "   ...\n",
      "   [0.03274766 0.03246197 0.0209985 ]\n",
      "   [0.03299764 0.03049782 0.02135562]\n",
      "   [0.03314049 0.0295336  0.02249839]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05217484 0.04749661 0.05156774]\n",
      "   [0.05217484 0.04749661 0.05156774]\n",
      "   [0.05831726 0.05449611 0.0593529 ]\n",
      "   ...\n",
      "   [0.04235412 0.03778302 0.03535462]\n",
      "   [0.04038997 0.03814013 0.03371188]\n",
      "   [0.0465681  0.04074709 0.03853296]]\n",
      "\n",
      "  [[0.06010285 0.05463896 0.05896007]\n",
      "   [0.06010285 0.05463896 0.05896007]\n",
      "   [0.05863867 0.05399614 0.05831726]\n",
      "   ...\n",
      "   [0.03767588 0.03396186 0.02731948]\n",
      "   [0.03824727 0.03374759 0.02628384]\n",
      "   [0.04713949 0.04074709 0.04028284]]\n",
      "\n",
      "  [[0.06470966 0.06142418 0.06803086]\n",
      "   [0.06470966 0.06142418 0.06803086]\n",
      "   [0.06470966 0.0596386  0.06342404]\n",
      "   ...\n",
      "   [0.04071138 0.03428327 0.03292622]\n",
      "   [0.04371116 0.03724734 0.03710449]\n",
      "   [0.0474609  0.04042568 0.04160417]]]\n",
      "\n",
      "\n",
      " [[[0.02942647 0.02910506 0.01803443]\n",
      "   [0.02942647 0.02910506 0.01803443]\n",
      "   [0.03581887 0.0383544  0.03610456]\n",
      "   ...\n",
      "   [0.0426041  0.04706807 0.05581744]\n",
      "   [0.0374259  0.03831869 0.03942576]\n",
      "   [0.03089065 0.03171202 0.02146275]]\n",
      "\n",
      "  [[0.02942647 0.02910506 0.01803443]\n",
      "   [0.02942647 0.02910506 0.01803443]\n",
      "   [0.03581887 0.0383544  0.03610456]\n",
      "   ...\n",
      "   [0.0426041  0.04706807 0.05581744]\n",
      "   [0.0374259  0.03831869 0.03942576]\n",
      "   [0.03089065 0.03171202 0.02146275]]\n",
      "\n",
      "  [[0.03017642 0.03028355 0.01971288]\n",
      "   [0.03017642 0.03028355 0.01971288]\n",
      "   [0.03842583 0.03992572 0.04249696]\n",
      "   ...\n",
      "   [0.03592601 0.03849725 0.03831869]\n",
      "   [0.02924791 0.02946218 0.02121277]\n",
      "   [0.0304264  0.03231912 0.02028427]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06088851 0.06620955 0.06417399]\n",
      "   [0.06088851 0.06620955 0.06417399]\n",
      "   [0.06328119 0.06624527 0.06863795]\n",
      "   ...\n",
      "   [0.03810442 0.03578316 0.02356975]\n",
      "   [0.03881866 0.03456896 0.02171274]\n",
      "   [0.04038997 0.03574745 0.02231983]]\n",
      "\n",
      "  [[0.07081637 0.07328048 0.08020855]\n",
      "   [0.07081637 0.07328048 0.08020855]\n",
      "   [0.07438754 0.07138776 0.07488751]\n",
      "   ...\n",
      "   [0.04021141 0.03649739 0.02171274]\n",
      "   [0.0407828  0.03685451 0.02231983]\n",
      "   [0.04167559 0.03674737 0.02199843]]\n",
      "\n",
      "  [[0.04435397 0.04803228 0.04142561]\n",
      "   [0.04435397 0.04803228 0.04142561]\n",
      "   [0.04235412 0.04378259 0.04099707]\n",
      "   ...\n",
      "   [0.04096136 0.03714021 0.02214128]\n",
      "   [0.04099707 0.03728305 0.0222127 ]\n",
      "   [0.04096136 0.03696164 0.02203414]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.04356832 0.03517606 0.03146204]\n",
      "   [0.04356832 0.03517606 0.03146204]\n",
      "   [0.04813942 0.04071138 0.03853296]\n",
      "   ...\n",
      "   [0.04806799 0.0444254  0.04574673]\n",
      "   [0.0468538  0.04292551 0.04513963]\n",
      "   [0.04756803 0.04128277 0.04228269]]\n",
      "\n",
      "  [[0.04356832 0.03517606 0.03146204]\n",
      "   [0.04356832 0.03517606 0.03146204]\n",
      "   [0.04813942 0.04071138 0.03853296]\n",
      "   ...\n",
      "   [0.04806799 0.0444254  0.04574673]\n",
      "   [0.0468538  0.04292551 0.04513963]\n",
      "   [0.04756803 0.04128277 0.04228269]]\n",
      "\n",
      "  [[0.04074709 0.03467609 0.03039069]\n",
      "   [0.04074709 0.03467609 0.03039069]\n",
      "   [0.04346118 0.03724734 0.0331762 ]\n",
      "   ...\n",
      "   [0.05063924 0.04388972 0.04453253]\n",
      "   [0.04853225 0.04117563 0.04713949]\n",
      "   [0.04663952 0.04163988 0.04338976]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03428327 0.02910506 0.01821299]\n",
      "   [0.03428327 0.02910506 0.01821299]\n",
      "   [0.03349761 0.02899793 0.01757017]\n",
      "   ...\n",
      "   [0.03296193 0.02885508 0.01714163]\n",
      "   [0.03314049 0.02924791 0.01753446]\n",
      "   [0.03371188 0.02917649 0.01778444]]\n",
      "\n",
      "  [[0.03385472 0.02853368 0.01724877]\n",
      "   [0.03385472 0.02853368 0.01724877]\n",
      "   [0.03356903 0.02792658 0.01692736]\n",
      "   ...\n",
      "   [0.03346189 0.02871224 0.01717735]\n",
      "   [0.0331762  0.02885508 0.01739161]\n",
      "   [0.03331905 0.02856939 0.01774873]]\n",
      "\n",
      "  [[0.03292622 0.02567674 0.01539176]\n",
      "   [0.03292622 0.02567674 0.01539176]\n",
      "   [0.03242626 0.02506964 0.01499893]\n",
      "   ...\n",
      "   [0.03314049 0.02889079 0.01778444]\n",
      "   [0.03328334 0.02814085 0.01739161]\n",
      "   [0.03303336 0.02721234 0.01724877]]]\n",
      "\n",
      "\n",
      " [[[0.02835512 0.01710592 0.00860653]\n",
      "   [0.02835512 0.01710592 0.00860653]\n",
      "   [0.02724805 0.0167488  0.00864224]\n",
      "   ...\n",
      "   [0.02774802 0.01635597 0.00860653]\n",
      "   [0.02796229 0.01632026 0.00910649]\n",
      "   [0.0286051  0.0170345  0.00878509]]\n",
      "\n",
      "  [[0.02835512 0.01710592 0.00860653]\n",
      "   [0.02835512 0.01710592 0.00860653]\n",
      "   [0.02724805 0.0167488  0.00864224]\n",
      "   ...\n",
      "   [0.02774802 0.01635597 0.00860653]\n",
      "   [0.02796229 0.01632026 0.00910649]\n",
      "   [0.0286051  0.0170345  0.00878509]]\n",
      "\n",
      "  [[0.02781944 0.01692736 0.00839226]\n",
      "   [0.02781944 0.01692736 0.00839226]\n",
      "   [0.02756946 0.01646311 0.0088208 ]\n",
      "   ...\n",
      "   [0.027998   0.01664167 0.00867795]\n",
      "   [0.02842654 0.01639169 0.00892793]\n",
      "   [0.02796229 0.01671309 0.0088208 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02803371 0.01682023 0.00874938]\n",
      "   [0.02803371 0.01682023 0.00874938]\n",
      "   [0.02778373 0.01667738 0.00864224]\n",
      "   ...\n",
      "   [0.02778373 0.01660596 0.00878509]\n",
      "   [0.02696236 0.01657025 0.00878509]\n",
      "   [0.02756946 0.01667738 0.0085351 ]]\n",
      "\n",
      "  [[0.027998   0.01639169 0.00857082]\n",
      "   [0.027998   0.01639169 0.00857082]\n",
      "   [0.02785515 0.01653453 0.00864224]\n",
      "   ...\n",
      "   [0.02760517 0.01660596 0.00835655]\n",
      "   [0.02721234 0.01653453 0.00871366]\n",
      "   [0.02753375 0.01639169 0.00903507]]\n",
      "\n",
      "  [[0.02731948 0.01660596 0.00864224]\n",
      "   [0.02731948 0.01660596 0.00864224]\n",
      "   [0.02785515 0.0167488  0.00860653]\n",
      "   ...\n",
      "   [0.02746232 0.01657025 0.00910649]\n",
      "   [0.02749804 0.01660596 0.00889222]\n",
      "   [0.02764088 0.01639169 0.00874938]]]\n",
      "\n",
      "\n",
      " [[[0.03492608 0.03510464 0.02835512]\n",
      "   [0.03492608 0.03510464 0.02835512]\n",
      "   [0.03435469 0.0343904  0.02871224]\n",
      "   ...\n",
      "   [0.03006928 0.02631955 0.01624884]\n",
      "   [0.02989072 0.02614099 0.01624884]\n",
      "   [0.0298193  0.02596243 0.01671309]]\n",
      "\n",
      "  [[0.03492608 0.03510464 0.02835512]\n",
      "   [0.03492608 0.03510464 0.02835512]\n",
      "   [0.03435469 0.0343904  0.02871224]\n",
      "   ...\n",
      "   [0.03006928 0.02631955 0.01624884]\n",
      "   [0.02989072 0.02614099 0.01624884]\n",
      "   [0.0298193  0.02596243 0.01671309]]\n",
      "\n",
      "  [[0.03446182 0.03260481 0.0255696 ]\n",
      "   [0.03446182 0.03260481 0.0255696 ]\n",
      "   [0.03199771 0.0316406  0.02503393]\n",
      "   ...\n",
      "   [0.02978359 0.02667667 0.01692736]\n",
      "   [0.03006928 0.02664095 0.01689165]\n",
      "   [0.03028355 0.02653382 0.01696307]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03153346 0.03139061 0.02135562]\n",
      "   [0.03153346 0.03139061 0.02135562]\n",
      "   [0.03281908 0.03367617 0.02299836]\n",
      "   ...\n",
      "   [0.04363974 0.04331833 0.04121134]\n",
      "   [0.04742518 0.0450325  0.04363974]\n",
      "   [0.0544604  0.05378187 0.05460324]]\n",
      "\n",
      "  [[0.0328548  0.03289051 0.02024855]\n",
      "   [0.0328548  0.03289051 0.02024855]\n",
      "   [0.03078352 0.03160489 0.01899864]\n",
      "   ...\n",
      "   [0.04221127 0.04238983 0.04088994]\n",
      "   [0.04499679 0.04278266 0.04174702]\n",
      "   [0.05335333 0.05053211 0.05303193]]\n",
      "\n",
      "  [[0.0343904  0.03199771 0.02474823]\n",
      "   [0.0343904  0.03199771 0.02474823]\n",
      "   [0.03153346 0.0310335  0.02028427]\n",
      "   ...\n",
      "   [0.04156846 0.04128277 0.03942576]\n",
      "   [0.05449611 0.05278194 0.0544604 ]\n",
      "   [0.06206699 0.06124562 0.06563817]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03149775 0.0298193  0.01628455]\n",
      "   [0.03149775 0.0298193  0.01628455]\n",
      "   [0.03081923 0.03089065 0.01607028]\n",
      "   ...\n",
      "   [0.02903364 0.02285551 0.01346332]\n",
      "   [0.02785515 0.02121277 0.0124634 ]\n",
      "   [0.02792658 0.02114135 0.01271338]]\n",
      "\n",
      "  [[0.03149775 0.0298193  0.01628455]\n",
      "   [0.03149775 0.0298193  0.01628455]\n",
      "   [0.03081923 0.03089065 0.01607028]\n",
      "   ...\n",
      "   [0.02903364 0.02285551 0.01346332]\n",
      "   [0.02785515 0.02121277 0.0124634 ]\n",
      "   [0.02792658 0.02114135 0.01271338]]\n",
      "\n",
      "  [[0.03153346 0.03003357 0.01714163]\n",
      "   [0.03153346 0.03003357 0.01714163]\n",
      "   [0.0298193  0.02746232 0.01449896]\n",
      "   ...\n",
      "   [0.0292122  0.0249625  0.01385615]\n",
      "   [0.02967645 0.02224841 0.01335619]\n",
      "   [0.02778373 0.02106992 0.01232055]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03067638 0.02710521 0.02035569]\n",
      "   [0.03067638 0.02710521 0.02035569]\n",
      "   [0.03099779 0.02742661 0.02214128]\n",
      "   ...\n",
      "   [0.03092636 0.02917649 0.01839154]\n",
      "   [0.03078352 0.02789086 0.01746304]\n",
      "   [0.03046211 0.02624813 0.01785587]]\n",
      "\n",
      "  [[0.03221199 0.02853368 0.02249839]\n",
      "   [0.03221199 0.02853368 0.02249839]\n",
      "   [0.03281908 0.02878366 0.02471252]\n",
      "   ...\n",
      "   [0.03246197 0.03028355 0.02153418]\n",
      "   [0.03124777 0.02867652 0.01971288]\n",
      "   [0.02949789 0.02699807 0.01714163]]\n",
      "\n",
      "  [[0.03185487 0.02924791 0.02267695]\n",
      "   [0.03185487 0.02924791 0.02267695]\n",
      "   [0.03306907 0.02999786 0.02574816]\n",
      "   ...\n",
      "   [0.03085494 0.02606957 0.01992715]\n",
      "   [0.0289265  0.02531962 0.0164274 ]\n",
      "   [0.02856939 0.02385544 0.01360617]]]\n",
      "\n",
      "\n",
      " [[[0.04617527 0.04203271 0.03753303]\n",
      "   [0.04617527 0.04203271 0.03753303]\n",
      "   [0.04146132 0.03831869 0.03239054]\n",
      "   ...\n",
      "   [0.04492536 0.03564031 0.0368188 ]\n",
      "   [0.04867509 0.04928219 0.04053282]\n",
      "   [0.04881794 0.04417542 0.04081851]]\n",
      "\n",
      "  [[0.04617527 0.04203271 0.03753303]\n",
      "   [0.04617527 0.04203271 0.03753303]\n",
      "   [0.04146132 0.03831869 0.03239054]\n",
      "   ...\n",
      "   [0.04492536 0.03564031 0.0368188 ]\n",
      "   [0.04867509 0.04928219 0.04053282]\n",
      "   [0.04881794 0.04417542 0.04081851]]\n",
      "\n",
      "  [[0.04153275 0.03931862 0.03406899]\n",
      "   [0.04153275 0.03931862 0.03406899]\n",
      "   [0.03992572 0.03571174 0.03139061]\n",
      "   ...\n",
      "   [0.04935362 0.04288979 0.04188986]\n",
      "   [0.04363974 0.04742518 0.03474752]\n",
      "   [0.04896079 0.04360403 0.04117563]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03685451 0.03306907 0.02349832]\n",
      "   [0.03685451 0.03306907 0.02349832]\n",
      "   [0.03714021 0.03117635 0.02371259]\n",
      "   ...\n",
      "   [0.04096136 0.03696164 0.03428327]\n",
      "   [0.03996143 0.03596172 0.0252482 ]\n",
      "   [0.0395686  0.03824727 0.03321191]]\n",
      "\n",
      "  [[0.04110421 0.04031855 0.03374759]\n",
      "   [0.04110421 0.04031855 0.03374759]\n",
      "   [0.04256839 0.03960431 0.03192629]\n",
      "   ...\n",
      "   [0.0389615  0.03510464 0.02735519]\n",
      "   [0.04006857 0.03874723 0.02628384]\n",
      "   [0.03881866 0.03839011 0.03003357]]\n",
      "\n",
      "  [[0.04538961 0.0401757  0.0395686 ]\n",
      "   [0.04538961 0.0401757  0.0395686 ]\n",
      "   [0.04556817 0.04099707 0.03946147]\n",
      "   ...\n",
      "   [0.03756874 0.03571174 0.02656953]\n",
      "   [0.04024712 0.03778302 0.02806942]\n",
      "   [0.0374259  0.03828298 0.02689094]]]\n",
      "\n",
      "\n",
      " [[[0.02546247 0.01567745 0.00871366]\n",
      "   [0.02546247 0.01567745 0.00871366]\n",
      "   [0.0252482  0.01549889 0.00849939]\n",
      "   ...\n",
      "   [0.02539104 0.01557032 0.00846368]\n",
      "   [0.0258553  0.01603457 0.00860653]\n",
      "   [0.02581958 0.0158203  0.00889222]]\n",
      "\n",
      "  [[0.02546247 0.01567745 0.00871366]\n",
      "   [0.02546247 0.01567745 0.00871366]\n",
      "   [0.0252482  0.01549889 0.00849939]\n",
      "   ...\n",
      "   [0.02539104 0.01557032 0.00846368]\n",
      "   [0.0258553  0.01603457 0.00860653]\n",
      "   [0.02581958 0.0158203  0.00889222]]\n",
      "\n",
      "  [[0.02560531 0.01549889 0.0085351 ]\n",
      "   [0.02560531 0.01549889 0.0085351 ]\n",
      "   [0.02564103 0.01546318 0.00874938]\n",
      "   ...\n",
      "   [0.02596243 0.01542747 0.00867795]\n",
      "   [0.0258553  0.01564174 0.00867795]\n",
      "   [0.02596243 0.01564174 0.00878509]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02553389 0.01592743 0.00835655]\n",
      "   [0.02553389 0.01592743 0.00835655]\n",
      "   [0.02546247 0.01549889 0.00874938]\n",
      "   ...\n",
      "   [0.02571245 0.01567745 0.00860653]\n",
      "   [0.02574816 0.01564174 0.00839226]\n",
      "   [0.0255696  0.01571316 0.00857082]]\n",
      "\n",
      "  [[0.02535533 0.01589172 0.00857082]\n",
      "   [0.02535533 0.01589172 0.00857082]\n",
      "   [0.02560531 0.01517749 0.0085351 ]\n",
      "   ...\n",
      "   [0.02553389 0.01546318 0.00857082]\n",
      "   [0.02560531 0.01539176 0.00878509]\n",
      "   [0.0252482  0.01567745 0.0088208 ]]\n",
      "\n",
      "  [[0.02603385 0.01585601 0.00860653]\n",
      "   [0.02603385 0.01585601 0.00860653]\n",
      "   [0.02589101 0.01532033 0.00817799]\n",
      "   ...\n",
      "   [0.02546247 0.0155346  0.0082137 ]\n",
      "   [0.0255696  0.01546318 0.00860653]\n",
      "   [0.02542675 0.01571316 0.00832083]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.03817584 0.03946147 0.02885508]\n",
      "   [0.03817584 0.03946147 0.02885508]\n",
      "   [0.04521106 0.04674666 0.04703236]\n",
      "   ...\n",
      "   [0.05460324 0.05735305 0.06463824]\n",
      "   [0.05496036 0.05738876 0.06578101]\n",
      "   [0.05567459 0.05931719 0.0675666 ]]\n",
      "\n",
      "  [[0.03817584 0.03946147 0.02885508]\n",
      "   [0.03817584 0.03946147 0.02885508]\n",
      "   [0.04521106 0.04674666 0.04703236]\n",
      "   ...\n",
      "   [0.05460324 0.05735305 0.06463824]\n",
      "   [0.05496036 0.05738876 0.06578101]\n",
      "   [0.05567459 0.05931719 0.0675666 ]]\n",
      "\n",
      "  [[0.03753303 0.03781873 0.02499821]\n",
      "   [0.03753303 0.03781873 0.02499821]\n",
      "   [0.03996143 0.04085422 0.03214056]\n",
      "   ...\n",
      "   [0.05406757 0.05624598 0.06338833]\n",
      "   [0.05471038 0.05696022 0.06531677]\n",
      "   [0.05485322 0.05838869 0.06599528]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07117349 0.07495893 0.09070781]\n",
      "   [0.07117349 0.07495893 0.09070781]\n",
      "   [0.07110207 0.07478037 0.08988643]\n",
      "   ...\n",
      "   [0.07199486 0.07574459 0.09324334]\n",
      "   [0.0727448  0.07710163 0.09406471]\n",
      "   [0.07478037 0.07792301 0.09535033]]\n",
      "\n",
      "  [[0.06895936 0.07303049 0.08845796]\n",
      "   [0.06895936 0.07303049 0.08845796]\n",
      "   [0.06870938 0.07328048 0.08810085]\n",
      "   ...\n",
      "   [0.0687808  0.07303049 0.08802943]\n",
      "   [0.07203057 0.07635169 0.09427898]\n",
      "   [0.07410185 0.07749446 0.09581459]]\n",
      "\n",
      "  [[0.06795943 0.07128062 0.08756518]\n",
      "   [0.06795943 0.07128062 0.08756518]\n",
      "   [0.06792372 0.07113778 0.08727948]\n",
      "   ...\n",
      "   [0.05892436 0.06067424 0.06599528]\n",
      "   [0.07124491 0.07499465 0.09006499]\n",
      "   [0.07378045 0.07813728 0.09442183]]]\n",
      "\n",
      "\n",
      " [[[0.03814013 0.03931862 0.02539104]\n",
      "   [0.03814013 0.03931862 0.02539104]\n",
      "   [0.0377473  0.03928291 0.02546247]\n",
      "   ...\n",
      "   [0.04806799 0.04906792 0.06295979]\n",
      "   [0.04796086 0.04892508 0.06181701]\n",
      "   [0.04888937 0.05042497 0.06260267]]\n",
      "\n",
      "  [[0.03814013 0.03931862 0.02539104]\n",
      "   [0.03814013 0.03931862 0.02539104]\n",
      "   [0.0377473  0.03928291 0.02546247]\n",
      "   ...\n",
      "   [0.04806799 0.04906792 0.06295979]\n",
      "   [0.04796086 0.04892508 0.06181701]\n",
      "   [0.04888937 0.05042497 0.06260267]]\n",
      "\n",
      "  [[0.03789015 0.03928291 0.02528391]\n",
      "   [0.03789015 0.03928291 0.02528391]\n",
      "   [0.03735447 0.0389615  0.02535533]\n",
      "   ...\n",
      "   [0.04888937 0.05060353 0.0645311 ]\n",
      "   [0.04849654 0.04988929 0.0636026 ]\n",
      "   [0.04856796 0.04967503 0.06260267]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0407828  0.0386401  0.03364046]\n",
      "   [0.0407828  0.0386401  0.03364046]\n",
      "   [0.04021141 0.03853296 0.0331762 ]\n",
      "   ...\n",
      "   [0.04642526 0.04771088 0.05831726]\n",
      "   [0.04781801 0.04863938 0.06067424]\n",
      "   [0.04799657 0.04835369 0.06170988]]\n",
      "\n",
      "  [[0.04053282 0.03846154 0.03346189]\n",
      "   [0.04053282 0.03846154 0.03346189]\n",
      "   [0.04010428 0.03814013 0.03306907]\n",
      "   ...\n",
      "   [0.045961   0.04660381 0.05756732]\n",
      "   [0.04638954 0.04674666 0.05767445]\n",
      "   [0.04763946 0.04771088 0.05949575]]\n",
      "\n",
      "  [[0.04028284 0.0383544  0.03331905]\n",
      "   [0.04028284 0.0383544  0.03331905]\n",
      "   [0.03989001 0.03781873 0.03214056]\n",
      "   ...\n",
      "   [0.04671095 0.04667524 0.05896007]\n",
      "   [0.04638954 0.04653239 0.05803157]\n",
      "   [0.04688951 0.04638954 0.05771016]]]\n",
      "\n",
      "\n",
      " [[[0.05331762 0.05535319 0.05624598]\n",
      "   [0.05331762 0.05535319 0.05624598]\n",
      "   [0.05249625 0.05117492 0.0535676 ]\n",
      "   ...\n",
      "   [0.03281908 0.02885508 0.01821299]\n",
      "   [0.03217627 0.02842654 0.01821299]\n",
      "   [0.03231912 0.02831941 0.01789158]]\n",
      "\n",
      "  [[0.05331762 0.05535319 0.05624598]\n",
      "   [0.05331762 0.05535319 0.05624598]\n",
      "   [0.05249625 0.05117492 0.0535676 ]\n",
      "   ...\n",
      "   [0.03281908 0.02885508 0.01821299]\n",
      "   [0.03217627 0.02842654 0.01821299]\n",
      "   [0.03231912 0.02831941 0.01789158]]\n",
      "\n",
      "  [[0.05738876 0.0553889  0.05685308]\n",
      "   [0.05738876 0.0553889  0.05685308]\n",
      "   [0.05178202 0.05024641 0.05463896]\n",
      "   ...\n",
      "   [0.03271195 0.02874795 0.01821299]\n",
      "   [0.03235483 0.02864081 0.01799871]\n",
      "   [0.03235483 0.02889079 0.01792729]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04185415 0.04192558 0.03314049]\n",
      "   [0.04185415 0.04192558 0.03314049]\n",
      "   [0.045961   0.04738947 0.04099707]\n",
      "   ...\n",
      "   [0.03249768 0.02910506 0.01949861]\n",
      "   [0.03424755 0.03067638 0.02035569]\n",
      "   [0.03574745 0.03264052 0.02278409]]\n",
      "\n",
      "  [[0.04228269 0.04160417 0.03517606]\n",
      "   [0.04228269 0.04160417 0.03517606]\n",
      "   [0.04546104 0.04635383 0.04117563]\n",
      "   ...\n",
      "   [0.03403328 0.03067638 0.02081994]\n",
      "   [0.03506893 0.03117635 0.02114135]\n",
      "   [0.03517606 0.03235483 0.02210556]]\n",
      "\n",
      "  [[0.04492536 0.04485394 0.03974716]\n",
      "   [0.04492536 0.04485394 0.03974716]\n",
      "   [0.04785372 0.04546104 0.04571102]\n",
      "   ...\n",
      "   [0.03406899 0.03049782 0.02114135]\n",
      "   [0.03453325 0.03071209 0.02114135]\n",
      "   [0.03435469 0.0316406  0.02117706]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.02889079 0.0286051  0.01564174]\n",
      "   [0.02889079 0.0286051  0.01564174]\n",
      "   [0.02881937 0.02910506 0.01571316]\n",
      "   ...\n",
      "   [0.02874795 0.02824798 0.01721306]\n",
      "   [0.02942647 0.02899793 0.01771302]\n",
      "   [0.02835512 0.02831941 0.01678452]]\n",
      "\n",
      "  [[0.02889079 0.0286051  0.01564174]\n",
      "   [0.02889079 0.0286051  0.01564174]\n",
      "   [0.02881937 0.02910506 0.01571316]\n",
      "   ...\n",
      "   [0.02874795 0.02824798 0.01721306]\n",
      "   [0.02942647 0.02899793 0.01771302]\n",
      "   [0.02835512 0.02831941 0.01678452]]\n",
      "\n",
      "  [[0.02846225 0.02853368 0.01560603]\n",
      "   [0.02846225 0.02853368 0.01560603]\n",
      "   [0.02917649 0.02874795 0.01585601]\n",
      "   ...\n",
      "   [0.02899793 0.02867652 0.01792729]\n",
      "   [0.02928362 0.03071209 0.01874866]\n",
      "   [0.02871224 0.02846225 0.01660596]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.027998   0.02299836 0.01578459]\n",
      "   [0.027998   0.02299836 0.01578459]\n",
      "   [0.02835512 0.02292693 0.01646311]\n",
      "   ...\n",
      "   [0.02714092 0.02203414 0.01417756]\n",
      "   [0.02717663 0.02256982 0.013999  ]\n",
      "   [0.02735519 0.02274838 0.01485608]]\n",
      "\n",
      "  [[0.02778373 0.02335547 0.01578459]\n",
      "   [0.02778373 0.02335547 0.01578459]\n",
      "   [0.02803371 0.02217699 0.01632026]\n",
      "   ...\n",
      "   [0.02674809 0.02135562 0.01374902]\n",
      "   [0.02660524 0.02181987 0.01364188]\n",
      "   [0.027998   0.02274838 0.01549889]]\n",
      "\n",
      "  [[0.02928362 0.02614099 0.01903435]\n",
      "   [0.02928362 0.02614099 0.01903435]\n",
      "   [0.02824798 0.02449825 0.01757017]\n",
      "   ...\n",
      "   [0.02781944 0.02439111 0.01749875]\n",
      "   [0.02789086 0.02428398 0.01632026]\n",
      "   [0.02810514 0.02417685 0.01696307]]]\n",
      "\n",
      "\n",
      " [[[0.05181773 0.04110421 0.03624741]\n",
      "   [0.05181773 0.04110421 0.03624741]\n",
      "   [0.05313906 0.04313977 0.03678309]\n",
      "   ...\n",
      "   [0.06031712 0.05106778 0.04978216]\n",
      "   [0.0596386  0.05003214 0.04235412]\n",
      "   [0.05949575 0.0471752  0.04506821]]\n",
      "\n",
      "  [[0.05181773 0.04110421 0.03624741]\n",
      "   [0.05181773 0.04110421 0.03624741]\n",
      "   [0.05313906 0.04313977 0.03678309]\n",
      "   ...\n",
      "   [0.06031712 0.05106778 0.04978216]\n",
      "   [0.0596386  0.05003214 0.04235412]\n",
      "   [0.05949575 0.0471752  0.04506821]]\n",
      "\n",
      "  [[0.04506821 0.03067638 0.02239126]\n",
      "   [0.04506821 0.03067638 0.02239126]\n",
      "   [0.04588958 0.03203342 0.02560531]\n",
      "   ...\n",
      "   [0.05913863 0.04728234 0.04246125]\n",
      "   [0.05156774 0.03885437 0.03503321]\n",
      "   [0.05285337 0.04206842 0.03642597]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06345975 0.05174631 0.04813942]\n",
      "   [0.06345975 0.05174631 0.04813942]\n",
      "   [0.06703093 0.0553889  0.05596029]\n",
      "   ...\n",
      "   [0.05067495 0.03653311 0.02339119]\n",
      "   [0.05242483 0.03642597 0.02731948]\n",
      "   [0.05285337 0.03789015 0.02971216]]\n",
      "\n",
      "  [[0.06192415 0.05138919 0.05003214]\n",
      "   [0.06192415 0.05138919 0.05003214]\n",
      "   [0.06195986 0.05167488 0.04988929]\n",
      "   ...\n",
      "   [0.04692522 0.03128348 0.01903435]\n",
      "   [0.04788944 0.0322477  0.01792729]\n",
      "   [0.04749661 0.03214056 0.01842725]]\n",
      "\n",
      "  [[0.05953146 0.04696093 0.04638954]\n",
      "   [0.05953146 0.04696093 0.04638954]\n",
      "   [0.06292408 0.05128205 0.04728234]\n",
      "   ...\n",
      "   [0.04706807 0.03206914 0.01928434]\n",
      "   [0.04910364 0.0316406  0.0225341 ]\n",
      "   [0.04799657 0.03481894 0.02135562]]]\n",
      "\n",
      "\n",
      " [[[0.04796086 0.04924648 0.06488822]\n",
      "   [0.04796086 0.04924648 0.06488822]\n",
      "   [0.04917506 0.05274623 0.06892364]\n",
      "   ...\n",
      "   [0.04967503 0.05099636 0.05121063]\n",
      "   [0.05399614 0.05196057 0.05488894]\n",
      "   [0.06263838 0.06424541 0.06763802]]\n",
      "\n",
      "  [[0.04796086 0.04924648 0.06488822]\n",
      "   [0.04796086 0.04924648 0.06488822]\n",
      "   [0.04917506 0.05274623 0.06892364]\n",
      "   ...\n",
      "   [0.04967503 0.05099636 0.05121063]\n",
      "   [0.05399614 0.05196057 0.05488894]\n",
      "   [0.06263838 0.06424541 0.06763802]]\n",
      "\n",
      "  [[0.04749661 0.04921077 0.06613813]\n",
      "   [0.04749661 0.04921077 0.06613813]\n",
      "   [0.04792515 0.04938933 0.06513821]\n",
      "   ...\n",
      "   [0.05360331 0.05367474 0.06392401]\n",
      "   [0.0453539  0.05031784 0.05792443]\n",
      "   [0.05281766 0.0529605  0.05810299]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04671095 0.05246054 0.07392329]\n",
      "   [0.04671095 0.05246054 0.07392329]\n",
      "   [0.04849654 0.05406757 0.07320905]\n",
      "   ...\n",
      "   [0.14331119 0.1414899  0.15741733]\n",
      "   [0.19127205 0.19002214 0.1990215 ]\n",
      "   [0.16195272 0.16091707 0.16427398]]\n",
      "\n",
      "  [[0.04524677 0.05181773 0.07167345]\n",
      "   [0.04524677 0.05181773 0.07167345]\n",
      "   [0.04799657 0.05292479 0.07420898]\n",
      "   ...\n",
      "   [0.1430612  0.14584672 0.15491751]\n",
      "   [0.19220056 0.19155775 0.1987358 ]\n",
      "   [0.16384543 0.16066709 0.1582387 ]]\n",
      "\n",
      "  [[0.04603243 0.05088922 0.072102  ]\n",
      "   [0.04603243 0.05088922 0.072102  ]\n",
      "   [0.04606814 0.05110349 0.07220913]\n",
      "   ...\n",
      "   [0.12527676 0.12256268 0.13341904]\n",
      "   [0.15923862 0.15606028 0.17605886]\n",
      "   [0.13624027 0.1305264  0.13799015]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.02660524 0.02171274 0.01257053]\n",
      "   [0.02660524 0.02171274 0.01257053]\n",
      "   [0.02724805 0.021927   0.01253482]\n",
      "   ...\n",
      "   [0.04499679 0.04424684 0.04506821]\n",
      "   [0.04292551 0.03635455 0.03846154]\n",
      "   [0.03824727 0.0377473  0.04131848]]\n",
      "\n",
      "  [[0.02660524 0.02171274 0.01257053]\n",
      "   [0.02660524 0.02171274 0.01257053]\n",
      "   [0.02724805 0.021927   0.01253482]\n",
      "   ...\n",
      "   [0.04499679 0.04424684 0.04506821]\n",
      "   [0.04292551 0.03635455 0.03846154]\n",
      "   [0.03824727 0.0377473  0.04131848]]\n",
      "\n",
      "  [[0.02614099 0.02146275 0.01214199]\n",
      "   [0.02614099 0.02146275 0.01214199]\n",
      "   [0.02649811 0.02260553 0.01182058]\n",
      "   ...\n",
      "   [0.03796157 0.03539033 0.03221199]\n",
      "   [0.03771159 0.0343904  0.03321191]\n",
      "   [0.03660453 0.04167559 0.03964002]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03342618 0.02581958 0.0225341 ]\n",
      "   [0.03342618 0.02581958 0.0225341 ]\n",
      "   [0.04599671 0.03860439 0.03346189]\n",
      "   ...\n",
      "   [0.03478323 0.03596172 0.03278337]\n",
      "   [0.03767588 0.03531891 0.03339047]\n",
      "   [0.03521177 0.03410471 0.03189058]]\n",
      "\n",
      "  [[0.03153346 0.02874795 0.0222127 ]\n",
      "   [0.03153346 0.02874795 0.0222127 ]\n",
      "   [0.04456824 0.03946147 0.03756874]\n",
      "   ...\n",
      "   [0.0267838  0.02581958 0.01567745]\n",
      "   [0.03685451 0.03656882 0.03078352]\n",
      "   [0.04296122 0.04263981 0.03964002]]\n",
      "\n",
      "  [[0.03935433 0.03142633 0.02824798]\n",
      "   [0.03935433 0.03142633 0.02824798]\n",
      "   [0.03942576 0.04081851 0.03578316]\n",
      "   ...\n",
      "   [0.03003357 0.03189058 0.01846297]\n",
      "   [0.04146132 0.0401757  0.03085494]\n",
      "   [0.0532462  0.05117492 0.04510392]]]\n",
      "\n",
      "\n",
      " [[[0.03149775 0.03321191 0.02360546]\n",
      "   [0.03149775 0.03321191 0.02360546]\n",
      "   [0.03292622 0.03485465 0.02685522]\n",
      "   ...\n",
      "   [0.02814085 0.02471252 0.01782016]\n",
      "   [0.02817656 0.02274838 0.01714163]\n",
      "   [0.02914078 0.02449825 0.02060567]]\n",
      "\n",
      "  [[0.03149775 0.03321191 0.02360546]\n",
      "   [0.03149775 0.03321191 0.02360546]\n",
      "   [0.03292622 0.03485465 0.02685522]\n",
      "   ...\n",
      "   [0.02814085 0.02471252 0.01782016]\n",
      "   [0.02817656 0.02274838 0.01714163]\n",
      "   [0.02914078 0.02449825 0.02060567]]\n",
      "\n",
      "  [[0.03610456 0.03717592 0.03085494]\n",
      "   [0.03610456 0.03717592 0.03085494]\n",
      "   [0.03114063 0.03403328 0.02574816]\n",
      "   ...\n",
      "   [0.027998   0.02292693 0.01707021]\n",
      "   [0.02864081 0.02349832 0.01853439]\n",
      "   [0.02853368 0.02446254 0.01867724]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02817656 0.02710521 0.01403471]\n",
      "   [0.02817656 0.02710521 0.01403471]\n",
      "   [0.02828369 0.02481966 0.01424898]\n",
      "   ...\n",
      "   [0.02946218 0.02581958 0.01749875]\n",
      "   [0.02842654 0.02546247 0.01557032]\n",
      "   [0.02839083 0.02649811 0.0155346 ]]\n",
      "\n",
      "  [[0.02828369 0.02699807 0.01421327]\n",
      "   [0.02828369 0.02699807 0.01421327]\n",
      "   [0.02856939 0.02589101 0.01571316]\n",
      "   ...\n",
      "   [0.02999786 0.02439111 0.01628455]\n",
      "   [0.02910506 0.02317692 0.0152132 ]\n",
      "   [0.02871224 0.02385544 0.01485608]]\n",
      "\n",
      "  [[0.0295336  0.02542675 0.01557032]\n",
      "   [0.0295336  0.02542675 0.01557032]\n",
      "   [0.03474752 0.03739019 0.03021213]\n",
      "   ...\n",
      "   [0.03117635 0.02989072 0.02060567]\n",
      "   [0.02885508 0.02514106 0.01532033]\n",
      "   [0.02971216 0.02489108 0.01589172]]]\n",
      "\n",
      "\n",
      " [[[0.03624741 0.03392615 0.03524748]\n",
      "   [0.03624741 0.03392615 0.03524748]\n",
      "   [0.03331905 0.03142633 0.03039069]\n",
      "   ...\n",
      "   [0.04096136 0.04431826 0.0496036 ]\n",
      "   [0.04496107 0.04863938 0.05967431]\n",
      "   [0.05310335 0.06135276 0.0745661 ]]\n",
      "\n",
      "  [[0.03624741 0.03392615 0.03524748]\n",
      "   [0.03624741 0.03392615 0.03524748]\n",
      "   [0.03331905 0.03142633 0.03039069]\n",
      "   ...\n",
      "   [0.04096136 0.04431826 0.0496036 ]\n",
      "   [0.04496107 0.04863938 0.05967431]\n",
      "   [0.05310335 0.06135276 0.0745661 ]]\n",
      "\n",
      "  [[0.03503321 0.03392615 0.03456896]\n",
      "   [0.03503321 0.03392615 0.03456896]\n",
      "   [0.03356903 0.03121206 0.03131919]\n",
      "   ...\n",
      "   [0.04396114 0.04763946 0.05413899]\n",
      "   [0.04956789 0.05556746 0.06567388]\n",
      "   [0.05871009 0.06642383 0.0794229 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03453325 0.0362117  0.03696164]\n",
      "   [0.03453325 0.0362117  0.03696164]\n",
      "   [0.03374759 0.03606885 0.03428327]\n",
      "   ...\n",
      "   [0.03753303 0.03860439 0.0401757 ]\n",
      "   [0.04071138 0.04099707 0.04178273]\n",
      "   [0.04099707 0.04174702 0.04403257]]\n",
      "\n",
      "  [[0.03453325 0.03656882 0.03678309]\n",
      "   [0.03453325 0.03656882 0.03678309]\n",
      "   [0.03467609 0.03728305 0.03567602]\n",
      "   ...\n",
      "   [0.03978287 0.0401757  0.04181844]\n",
      "   [0.04046139 0.04113992 0.04317549]\n",
      "   [0.03964002 0.04042568 0.04317549]]\n",
      "\n",
      "  [[0.03421184 0.03660453 0.03667595]\n",
      "   [0.03421184 0.03660453 0.03667595]\n",
      "   [0.03424755 0.03671166 0.03667595]\n",
      "   ...\n",
      "   [0.04038997 0.03964002 0.04228269]\n",
      "   [0.04124705 0.041997   0.04378259]\n",
      "   [0.04071138 0.04110421 0.04471109]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03399757 0.03714021 0.02467681]\n",
      "   [0.03399757 0.03714021 0.02467681]\n",
      "   [0.03374759 0.03596172 0.02317692]\n",
      "   ...\n",
      "   [0.02703378 0.02606957 0.01621313]\n",
      "   [0.0286051  0.0295336  0.01803443]\n",
      "   [0.02881937 0.03235483 0.02007   ]]\n",
      "\n",
      "  [[0.03399757 0.03714021 0.02467681]\n",
      "   [0.03399757 0.03714021 0.02467681]\n",
      "   [0.03374759 0.03596172 0.02317692]\n",
      "   ...\n",
      "   [0.02703378 0.02606957 0.01621313]\n",
      "   [0.0286051  0.0295336  0.01803443]\n",
      "   [0.02881937 0.03235483 0.02007   ]]\n",
      "\n",
      "  [[0.02821227 0.02964074 0.01514178]\n",
      "   [0.02821227 0.02964074 0.01514178]\n",
      "   [0.02689094 0.02806942 0.0146061 ]\n",
      "   ...\n",
      "   [0.02706949 0.02685522 0.01664167]\n",
      "   [0.02871224 0.02949789 0.01807014]\n",
      "   [0.02864081 0.03153346 0.01949861]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02481966 0.01999857 0.01089208]\n",
      "   [0.02481966 0.01999857 0.01089208]\n",
      "   [0.0252482  0.01996286 0.01092779]\n",
      "   ...\n",
      "   [0.02474823 0.01874866 0.01049925]\n",
      "   [0.02442683 0.01878437 0.01082066]\n",
      "   [0.02456967 0.0182487  0.01071352]]\n",
      "\n",
      "  [[0.02549818 0.02031998 0.0112492 ]\n",
      "   [0.02549818 0.02031998 0.0112492 ]\n",
      "   [0.02567674 0.02153418 0.01189201]\n",
      "   ...\n",
      "   [0.02460539 0.01942718 0.01067781]\n",
      "   [0.02456967 0.01860581 0.01057067]\n",
      "   [0.02478394 0.01835583 0.01067781]]\n",
      "\n",
      "  [[0.02521249 0.02007    0.01142776]\n",
      "   [0.02521249 0.02007    0.01142776]\n",
      "   [0.0252482  0.02007    0.01214199]\n",
      "   ...\n",
      "   [0.02410542 0.01860581 0.01032069]\n",
      "   [0.02421256 0.01810585 0.01039211]\n",
      "   [0.02481966 0.01899864 0.01121349]]]\n",
      "\n",
      "\n",
      " [[[0.06160274 0.06438826 0.0812442 ]\n",
      "   [0.06160274 0.06438826 0.0812442 ]\n",
      "   [0.06149561 0.06467395 0.08099421]\n",
      "   ...\n",
      "   [0.05738876 0.05863867 0.07213771]\n",
      "   [0.0572102  0.05860296 0.07167345]\n",
      "   [0.05753161 0.05996    0.07467324]]\n",
      "\n",
      "  [[0.06160274 0.06438826 0.0812442 ]\n",
      "   [0.06160274 0.06438826 0.0812442 ]\n",
      "   [0.06149561 0.06467395 0.08099421]\n",
      "   ...\n",
      "   [0.05738876 0.05863867 0.07213771]\n",
      "   [0.0572102  0.05860296 0.07167345]\n",
      "   [0.05753161 0.05996    0.07467324]]\n",
      "\n",
      "  [[0.06060281 0.0636026  0.07978001]\n",
      "   [0.06060281 0.0636026  0.07978001]\n",
      "   [0.06103136 0.06449539 0.08113706]\n",
      "   ...\n",
      "   [0.05756732 0.0578173  0.0715306 ]\n",
      "   [0.05760303 0.0584244  0.07217342]\n",
      "   [0.05796015 0.05899579 0.07381616]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0566031  0.05731734 0.06692379]\n",
      "   [0.0566031  0.05731734 0.06692379]\n",
      "   [0.05663881 0.05653168 0.06710235]\n",
      "   ...\n",
      "   [0.03539033 0.03478323 0.02071281]\n",
      "   [0.03556889 0.03517606 0.0206771 ]\n",
      "   [0.03567602 0.03517606 0.02046282]]\n",
      "\n",
      "  [[0.05628169 0.05681737 0.06674523]\n",
      "   [0.05628169 0.05681737 0.06674523]\n",
      "   [0.0566031  0.05742447 0.06831655]\n",
      "   ...\n",
      "   [0.03546175 0.03542604 0.02081994]\n",
      "   [0.03578316 0.0343904  0.02053425]\n",
      "   [0.03581887 0.03510464 0.02042711]]\n",
      "\n",
      "  [[0.05546032 0.05563888 0.06513821]\n",
      "   [0.05546032 0.05563888 0.06513821]\n",
      "   [0.05696022 0.05771016 0.06874509]\n",
      "   ...\n",
      "   [0.03589029 0.03492608 0.02096279]\n",
      "   [0.03606885 0.03442611 0.02056996]\n",
      "   [0.03571174 0.03489036 0.02060567]]]\n",
      "\n",
      "\n",
      " [[[0.04317549 0.04481823 0.04471109]\n",
      "   [0.04317549 0.04481823 0.04471109]\n",
      "   [0.04306835 0.04538961 0.04663952]\n",
      "   ...\n",
      "   [0.04003286 0.03899721 0.03399757]\n",
      "   [0.04188986 0.04035426 0.03639026]\n",
      "   [0.04206842 0.04038997 0.03624741]]\n",
      "\n",
      "  [[0.04317549 0.04481823 0.04471109]\n",
      "   [0.04317549 0.04481823 0.04471109]\n",
      "   [0.04306835 0.04538961 0.04663952]\n",
      "   ...\n",
      "   [0.04003286 0.03899721 0.03399757]\n",
      "   [0.04188986 0.04035426 0.03639026]\n",
      "   [0.04206842 0.04038997 0.03624741]]\n",
      "\n",
      "  [[0.0447468  0.04649668 0.04913935]\n",
      "   [0.0447468  0.04649668 0.04913935]\n",
      "   [0.04510392 0.0456396  0.04796086]\n",
      "   ...\n",
      "   [0.04146132 0.03971145 0.03553317]\n",
      "   [0.04192558 0.04006857 0.03778302]\n",
      "   [0.04149704 0.04106849 0.03785444]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03921149 0.04024712 0.03174773]\n",
      "   [0.03921149 0.04024712 0.03174773]\n",
      "   [0.041997   0.04349689 0.03981858]\n",
      "   ...\n",
      "   [0.12016999 0.12727663 0.14477538]\n",
      "   [0.15809585 0.18116564 0.20377116]\n",
      "   [0.15131062 0.16691665 0.18727234]]\n",
      "\n",
      "  [[0.03949718 0.04028284 0.03271195]\n",
      "   [0.03949718 0.04028284 0.03271195]\n",
      "   [0.04278266 0.04292551 0.04042568]\n",
      "   ...\n",
      "   [0.10638526 0.11999143 0.13566887]\n",
      "   [0.15106064 0.1713449  0.1914149 ]\n",
      "   [0.14023998 0.15906006 0.17788015]]\n",
      "\n",
      "  [[0.0395686  0.0395686  0.03192629]\n",
      "   [0.0395686  0.0395686  0.03192629]\n",
      "   [0.04367545 0.04281837 0.03914006]\n",
      "   ...\n",
      "   [0.08417256 0.08781516 0.09935005]\n",
      "   [0.12334833 0.1351332  0.1524534 ]\n",
      "   [0.14073995 0.15263195 0.17155917]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.05171059 0.04774659 0.05135347]\n",
      "   [0.05171059 0.04774659 0.05135347]\n",
      "   [0.04628241 0.04281837 0.0395686 ]\n",
      "   ...\n",
      "   [0.03581887 0.03514035 0.02599814]\n",
      "   [0.03539033 0.03510464 0.02517677]\n",
      "   [0.03689022 0.03592601 0.02839083]]\n",
      "\n",
      "  [[0.05171059 0.04774659 0.05135347]\n",
      "   [0.05171059 0.04774659 0.05135347]\n",
      "   [0.04628241 0.04281837 0.0395686 ]\n",
      "   ...\n",
      "   [0.03581887 0.03514035 0.02599814]\n",
      "   [0.03539033 0.03510464 0.02517677]\n",
      "   [0.03689022 0.03592601 0.02839083]]\n",
      "\n",
      "  [[0.04217556 0.03906864 0.03656882]\n",
      "   [0.04217556 0.03906864 0.03656882]\n",
      "   [0.05171059 0.05078209 0.04710378]\n",
      "   ...\n",
      "   [0.03406899 0.03460467 0.02339119]\n",
      "   [0.03410471 0.03539033 0.02235555]\n",
      "   [0.03435469 0.03456896 0.02424827]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03999714 0.04053282 0.03139061]\n",
      "   [0.03999714 0.04053282 0.03139061]\n",
      "   [0.03892579 0.03914006 0.02917649]\n",
      "   ...\n",
      "   [0.05596029 0.05517463 0.05624598]\n",
      "   [0.05928148 0.05771016 0.06006714]\n",
      "   [0.05188915 0.04724662 0.0477823 ]]\n",
      "\n",
      "  [[0.03685451 0.03689022 0.02899793]\n",
      "   [0.03685451 0.03689022 0.02899793]\n",
      "   [0.03717592 0.03574745 0.03028355]\n",
      "   ...\n",
      "   [0.06113849 0.06142418 0.06381687]\n",
      "   [0.05871009 0.05699593 0.05931719]\n",
      "   [0.0553889  0.05192486 0.0529605 ]]\n",
      "\n",
      "  [[0.03424755 0.03328334 0.02274838]\n",
      "   [0.03424755 0.03328334 0.02274838]\n",
      "   [0.03428327 0.03217627 0.01899864]\n",
      "   ...\n",
      "   [0.04406828 0.04438969 0.03828298]\n",
      "   [0.04721091 0.04521106 0.04063996]\n",
      "   [0.05221056 0.04967503 0.04867509]]]\n",
      "\n",
      "\n",
      " [[[0.03089065 0.02824798 0.02189129]\n",
      "   [0.03089065 0.02824798 0.02189129]\n",
      "   [0.03217627 0.03114063 0.02360546]\n",
      "   ...\n",
      "   [0.03389044 0.02814085 0.0228198 ]\n",
      "   [0.03410471 0.02867652 0.02224841]\n",
      "   [0.03321191 0.02964074 0.0234269 ]]\n",
      "\n",
      "  [[0.03089065 0.02824798 0.02189129]\n",
      "   [0.03089065 0.02824798 0.02189129]\n",
      "   [0.03217627 0.03114063 0.02360546]\n",
      "   ...\n",
      "   [0.03389044 0.02814085 0.0228198 ]\n",
      "   [0.03410471 0.02867652 0.02224841]\n",
      "   [0.03321191 0.02964074 0.0234269 ]]\n",
      "\n",
      "  [[0.03199771 0.03121206 0.01999857]\n",
      "   [0.03199771 0.03121206 0.01999857]\n",
      "   [0.03174773 0.03067638 0.02049854]\n",
      "   ...\n",
      "   [0.03117635 0.02717663 0.02096279]\n",
      "   [0.02992643 0.02603385 0.02007   ]\n",
      "   [0.03210485 0.02746232 0.02353403]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02803371 0.02317692 0.01646311]\n",
      "   [0.02803371 0.02317692 0.01646311]\n",
      "   [0.02949789 0.02510535 0.01910578]\n",
      "   ...\n",
      "   [0.03514035 0.03106921 0.0301407 ]\n",
      "   [0.03753303 0.03399757 0.03981858]\n",
      "   [0.03078352 0.02846225 0.02274838]]\n",
      "\n",
      "  [[0.02956932 0.02574816 0.02014142]\n",
      "   [0.02956932 0.02574816 0.02014142]\n",
      "   [0.02889079 0.0258553  0.01896293]\n",
      "   ...\n",
      "   [0.04513963 0.04038997 0.04031855]\n",
      "   [0.05017499 0.04910364 0.05138919]\n",
      "   [0.03424755 0.0307478  0.02660524]]\n",
      "\n",
      "  [[0.03467609 0.03017642 0.02456967]\n",
      "   [0.03467609 0.03017642 0.02456967]\n",
      "   [0.02946218 0.02560531 0.01860581]\n",
      "   ...\n",
      "   [0.0477823  0.04638954 0.04710378]\n",
      "   [0.07317334 0.07110207 0.07260196]\n",
      "   [0.05106778 0.04971074 0.04706807]]]\n",
      "\n",
      "\n",
      " [[[0.04088994 0.0383544  0.04738947]\n",
      "   [0.04088994 0.0383544  0.04738947]\n",
      "   [0.04117563 0.03874723 0.0477823 ]\n",
      "   ...\n",
      "   [0.05331762 0.0547818  0.06367403]\n",
      "   [0.04949646 0.0502107  0.05467467]\n",
      "   [0.04481823 0.04578244 0.04478252]]\n",
      "\n",
      "  [[0.04088994 0.0383544  0.04738947]\n",
      "   [0.04088994 0.0383544  0.04738947]\n",
      "   [0.04117563 0.03874723 0.0477823 ]\n",
      "   ...\n",
      "   [0.05331762 0.0547818  0.06367403]\n",
      "   [0.04949646 0.0502107  0.05467467]\n",
      "   [0.04481823 0.04578244 0.04478252]]\n",
      "\n",
      "  [[0.0407828  0.03892579 0.04871081]\n",
      "   [0.0407828  0.03892579 0.04871081]\n",
      "   [0.04088994 0.03831869 0.04713949]\n",
      "   ...\n",
      "   [0.05449611 0.05653168 0.07013785]\n",
      "   [0.05485322 0.05617456 0.06910221]\n",
      "   [0.05231769 0.05388901 0.06435255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05553175 0.05767445 0.07103064]\n",
      "   [0.05553175 0.05767445 0.07103064]\n",
      "   [0.05524606 0.05710306 0.0712092 ]\n",
      "   ...\n",
      "   [0.04531819 0.0450325  0.05810299]\n",
      "   [0.04556817 0.04542533 0.05731734]\n",
      "   [0.04528248 0.04510392 0.05713877]]\n",
      "\n",
      "  [[0.05524606 0.05656739 0.06974502]\n",
      "   [0.05524606 0.05656739 0.06974502]\n",
      "   [0.05503178 0.05674595 0.07092351]\n",
      "   ...\n",
      "   [0.04567531 0.04496107 0.05778159]\n",
      "   [0.0462467  0.0450325  0.05799586]\n",
      "   [0.04581816 0.04506821 0.05767445]]\n",
      "\n",
      "  [[0.05435326 0.05628169 0.06856653]\n",
      "   [0.05435326 0.05628169 0.06856653]\n",
      "   [0.05438897 0.05638883 0.0696736 ]\n",
      "   ...\n",
      "   [0.04592529 0.04513963 0.05681737]\n",
      "   [0.04521106 0.04446111 0.05756732]\n",
      "   [0.04528248 0.04460396 0.05631741]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.02903364 0.02289122 0.01182058]\n",
      "   [0.02903364 0.02289122 0.01182058]\n",
      "   [0.02899793 0.02256982 0.01174916]\n",
      "   ...\n",
      "   [0.02914078 0.02349832 0.01178487]\n",
      "   [0.02910506 0.02371259 0.01199914]\n",
      "   [0.02939076 0.02317692 0.01178487]]\n",
      "\n",
      "  [[0.02903364 0.02289122 0.01182058]\n",
      "   [0.02903364 0.02289122 0.01182058]\n",
      "   [0.02899793 0.02256982 0.01174916]\n",
      "   ...\n",
      "   [0.02914078 0.02349832 0.01178487]\n",
      "   [0.02910506 0.02371259 0.01199914]\n",
      "   [0.02939076 0.02317692 0.01178487]]\n",
      "\n",
      "  [[0.0289265  0.0228198  0.01196343]\n",
      "   [0.0289265  0.0228198  0.01196343]\n",
      "   [0.02964074 0.02228412 0.01192772]\n",
      "   ...\n",
      "   [0.02881937 0.02299836 0.01182058]\n",
      "   [0.02910506 0.0234269  0.01160631]\n",
      "   [0.02903364 0.02335547 0.01192772]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02896222 0.0225341  0.01121349]\n",
      "   [0.02896222 0.0225341  0.01121349]\n",
      "   [0.02881937 0.02274838 0.01135633]\n",
      "   ...\n",
      "   [0.0286051  0.02206985 0.01164203]\n",
      "   [0.02910506 0.02203414 0.01121349]\n",
      "   [0.02878366 0.02196272 0.01164203]]\n",
      "\n",
      "  [[0.02924791 0.0222127  0.01135633]\n",
      "   [0.02924791 0.0222127  0.01135633]\n",
      "   [0.02903364 0.02224841 0.01135633]\n",
      "   ...\n",
      "   [0.02896222 0.02239126 0.01199914]\n",
      "   [0.02881937 0.0222127  0.01117777]\n",
      "   [0.02871224 0.02231983 0.01167774]]\n",
      "\n",
      "  [[0.02899793 0.02210556 0.01149918]\n",
      "   [0.02899793 0.02210556 0.01149918]\n",
      "   [0.02896222 0.02217699 0.01139204]\n",
      "   ...\n",
      "   [0.02889079 0.02242697 0.01149918]\n",
      "   [0.0286051  0.02246268 0.01117777]\n",
      "   [0.02899793 0.0228198  0.01182058]]]\n",
      "\n",
      "\n",
      " [[[0.02624813 0.01760589 0.01282051]\n",
      "   [0.02624813 0.01760589 0.01282051]\n",
      "   [0.03267624 0.02742661 0.02828369]\n",
      "   ...\n",
      "   [0.03603314 0.03539033 0.03564031]\n",
      "   [0.03678309 0.03524748 0.03571174]\n",
      "   [0.03571174 0.03203342 0.03296193]]\n",
      "\n",
      "  [[0.02624813 0.01760589 0.01282051]\n",
      "   [0.02624813 0.01760589 0.01282051]\n",
      "   [0.03267624 0.02742661 0.02828369]\n",
      "   ...\n",
      "   [0.03603314 0.03539033 0.03564031]\n",
      "   [0.03678309 0.03524748 0.03571174]\n",
      "   [0.03571174 0.03203342 0.03296193]]\n",
      "\n",
      "  [[0.02728377 0.01932005 0.01482037]\n",
      "   [0.02728377 0.01932005 0.01482037]\n",
      "   [0.03349761 0.02756946 0.02846225]\n",
      "   ...\n",
      "   [0.03585458 0.03503321 0.03442611]\n",
      "   [0.03585458 0.03492608 0.03435469]\n",
      "   [0.03517606 0.03399757 0.03289051]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03606885 0.03403328 0.03235483]\n",
      "   [0.03606885 0.03403328 0.03235483]\n",
      "   [0.03771159 0.03535462 0.03699736]\n",
      "   ...\n",
      "   [0.03767588 0.03660453 0.03692593]\n",
      "   [0.03931862 0.0386401  0.04056853]\n",
      "   [0.04049711 0.04053282 0.04399686]]\n",
      "\n",
      "  [[0.03624741 0.03385472 0.03321191]\n",
      "   [0.03624741 0.03385472 0.03321191]\n",
      "   [0.03614027 0.03342618 0.03253339]\n",
      "   ...\n",
      "   [0.03889008 0.03824727 0.03953289]\n",
      "   [0.03971145 0.03971145 0.04196129]\n",
      "   [0.04063996 0.04042568 0.04306835]]\n",
      "\n",
      "  [[0.03674737 0.03489036 0.03360474]\n",
      "   [0.03674737 0.03489036 0.03360474]\n",
      "   [0.03535462 0.03206914 0.03089065]\n",
      "   ...\n",
      "   [0.03728305 0.03631883 0.03628312]\n",
      "   [0.03806871 0.03746161 0.03806871]\n",
      "   [0.03860439 0.0386401  0.03935433]]]\n",
      "\n",
      "\n",
      " [[[0.05278194 0.05924577 0.06192415]\n",
      "   [0.05278194 0.05924577 0.06192415]\n",
      "   [0.04496107 0.04667524 0.04921077]\n",
      "   ...\n",
      "   [0.03799729 0.03928291 0.04367545]\n",
      "   [0.03714021 0.03814013 0.04146132]\n",
      "   [0.03717592 0.03781873 0.04160417]]\n",
      "\n",
      "  [[0.05278194 0.05924577 0.06192415]\n",
      "   [0.05278194 0.05924577 0.06192415]\n",
      "   [0.04496107 0.04667524 0.04921077]\n",
      "   ...\n",
      "   [0.03799729 0.03928291 0.04367545]\n",
      "   [0.03714021 0.03814013 0.04146132]\n",
      "   [0.03717592 0.03781873 0.04160417]]\n",
      "\n",
      "  [[0.04460396 0.04649668 0.0468538 ]\n",
      "   [0.04460396 0.04649668 0.0468538 ]\n",
      "   [0.04060424 0.04146132 0.04185415]\n",
      "   ...\n",
      "   [0.038033   0.04024712 0.04360403]\n",
      "   [0.03731876 0.03885437 0.041997  ]\n",
      "   [0.03710449 0.03806871 0.04210414]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04238983 0.04324691 0.0483894 ]\n",
      "   [0.04238983 0.04324691 0.0483894 ]\n",
      "   [0.04403257 0.04871081 0.05738876]\n",
      "   ...\n",
      "   [0.04146132 0.04574673 0.05271052]\n",
      "   [0.04099707 0.04385401 0.05028212]\n",
      "   [0.03949718 0.04206842 0.04713949]]\n",
      "\n",
      "  [[0.04285408 0.04349689 0.04888937]\n",
      "   [0.04285408 0.04349689 0.04888937]\n",
      "   [0.04367545 0.04803228 0.0578173 ]\n",
      "   ...\n",
      "   [0.04085422 0.04517534 0.05224627]\n",
      "   [0.04135419 0.04492536 0.05167488]\n",
      "   [0.04110421 0.04392543 0.05113921]]\n",
      "\n",
      "  [[0.04288979 0.04488965 0.04942504]\n",
      "   [0.04288979 0.04488965 0.04942504]\n",
      "   [0.04392543 0.04824656 0.05788872]\n",
      "   ...\n",
      "   [0.04117563 0.04585387 0.05328191]\n",
      "   [0.04099707 0.04517534 0.05267481]\n",
      "   [0.04088994 0.04413971 0.05131776]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.0444254  0.04388972 0.04917506]\n",
      "   [0.0444254  0.04388972 0.04917506]\n",
      "   [0.04485394 0.04438969 0.05131776]\n",
      "   ...\n",
      "   [0.05124634 0.0547818  0.07135205]\n",
      "   [0.05517463 0.05828155 0.0748518 ]\n",
      "   [0.05756732 0.06088851 0.07913721]]\n",
      "\n",
      "  [[0.0444254  0.04388972 0.04917506]\n",
      "   [0.0444254  0.04388972 0.04917506]\n",
      "   [0.04485394 0.04438969 0.05131776]\n",
      "   ...\n",
      "   [0.05124634 0.0547818  0.07135205]\n",
      "   [0.05517463 0.05828155 0.0748518 ]\n",
      "   [0.05756732 0.06088851 0.07913721]]\n",
      "\n",
      "  [[0.04742518 0.04681809 0.0553889 ]\n",
      "   [0.04742518 0.04681809 0.0553889 ]\n",
      "   [0.05278194 0.05388901 0.06324548]\n",
      "   ...\n",
      "   [0.05878152 0.06270981 0.08049425]\n",
      "   [0.06017427 0.06528105 0.08395829]\n",
      "   [0.0602457  0.06538819 0.08445825]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04867509 0.05028212 0.05871009]\n",
      "   [0.04867509 0.05028212 0.05871009]\n",
      "   [0.04810371 0.05085351 0.05746018]\n",
      "   ...\n",
      "   [0.04485394 0.04478252 0.03714021]\n",
      "   [0.04478252 0.04399686 0.03567602]\n",
      "   [0.04374687 0.04292551 0.03478323]]\n",
      "\n",
      "  [[0.0477823  0.04985358 0.05631741]\n",
      "   [0.0477823  0.04985358 0.05631741]\n",
      "   [0.04771088 0.04967503 0.05596029]\n",
      "   ...\n",
      "   [0.04449682 0.0450325  0.03839011]\n",
      "   [0.04481823 0.04399686 0.03703307]\n",
      "   [0.04388972 0.04299693 0.03546175]]\n",
      "\n",
      "  [[0.04817513 0.04913935 0.05631741]\n",
      "   [0.04817513 0.04913935 0.05631741]\n",
      "   [0.04917506 0.05006785 0.05799586]\n",
      "   ...\n",
      "   [0.04517534 0.0450325  0.03842583]\n",
      "   [0.04549675 0.04496107 0.03817584]\n",
      "   [0.0444254  0.04396114 0.03628312]]]\n",
      "\n",
      "\n",
      " [[[0.03067638 0.02646239 0.01717735]\n",
      "   [0.03067638 0.02646239 0.01717735]\n",
      "   [0.03121206 0.02581958 0.01699879]\n",
      "   ...\n",
      "   [0.02939076 0.02214128 0.01396329]\n",
      "   [0.02978359 0.02421256 0.0161417 ]\n",
      "   [0.0310335  0.02546247 0.01899864]]\n",
      "\n",
      "  [[0.03067638 0.02646239 0.01717735]\n",
      "   [0.03067638 0.02646239 0.01717735]\n",
      "   [0.03121206 0.02581958 0.01699879]\n",
      "   ...\n",
      "   [0.02939076 0.02214128 0.01396329]\n",
      "   [0.02978359 0.02421256 0.0161417 ]\n",
      "   [0.0310335  0.02546247 0.01899864]]\n",
      "\n",
      "  [[0.03099779 0.02549818 0.01624884]\n",
      "   [0.03099779 0.02549818 0.01624884]\n",
      "   [0.03081923 0.02539104 0.01664167]\n",
      "   ...\n",
      "   [0.02956932 0.02299836 0.01446325]\n",
      "   [0.0289265  0.02128419 0.01389186]\n",
      "   [0.03039069 0.02364117 0.01628455]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03053353 0.02492679 0.0158203 ]\n",
      "   [0.03053353 0.02492679 0.0158203 ]\n",
      "   [0.03092636 0.02521249 0.01628455]\n",
      "   ...\n",
      "   [0.03146204 0.02667667 0.01785587]\n",
      "   [0.03085494 0.02503393 0.01696307]\n",
      "   [0.03021213 0.02360546 0.01442754]]\n",
      "\n",
      "  [[0.03046211 0.02535533 0.01524891]\n",
      "   [0.03046211 0.02535533 0.01524891]\n",
      "   [0.03071209 0.02553389 0.01524891]\n",
      "   ...\n",
      "   [0.03249768 0.02792658 0.02014142]\n",
      "   [0.03128348 0.02589101 0.0173559 ]\n",
      "   [0.03024784 0.02267695 0.01382044]]\n",
      "\n",
      "  [[0.0301407  0.02392686 0.01489179]\n",
      "   [0.0301407  0.02392686 0.01489179]\n",
      "   [0.03006928 0.0246411  0.01535605]\n",
      "   ...\n",
      "   [0.0331762  0.02881937 0.02171274]\n",
      "   [0.03199771 0.02889079 0.01903435]\n",
      "   [0.02978359 0.02267695 0.01403471]]]\n",
      "\n",
      "\n",
      " [[[0.06020999 0.0626741  0.06303121]\n",
      "   [0.06020999 0.0626741  0.06303121]\n",
      "   [0.0648168  0.06620955 0.07145918]\n",
      "   ...\n",
      "   [0.05917434 0.06253125 0.06667381]\n",
      "   [0.06053139 0.06156703 0.06828084]\n",
      "   [0.06949504 0.06945933 0.08320834]]\n",
      "\n",
      "  [[0.06020999 0.0626741  0.06303121]\n",
      "   [0.06020999 0.0626741  0.06303121]\n",
      "   [0.0648168  0.06620955 0.07145918]\n",
      "   ...\n",
      "   [0.05917434 0.06253125 0.06667381]\n",
      "   [0.06053139 0.06156703 0.06828084]\n",
      "   [0.06949504 0.06945933 0.08320834]]\n",
      "\n",
      "  [[0.06763802 0.06699521 0.07385187]\n",
      "   [0.06763802 0.06699521 0.07385187]\n",
      "   [0.07160203 0.08327977 0.08567245]\n",
      "   ...\n",
      "   [0.05867438 0.0636026  0.07085208]\n",
      "   [0.06174559 0.07470895 0.08595815]\n",
      "   [0.06949504 0.06728091 0.0970645 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06053139 0.06631669 0.07442325]\n",
      "   [0.06053139 0.06631669 0.07442325]\n",
      "   [0.06063852 0.06231698 0.07188772]\n",
      "   ...\n",
      "   [0.05524606 0.05585315 0.06128134]\n",
      "   [0.05392472 0.05581744 0.05856724]\n",
      "   [0.05371045 0.05413899 0.05763874]]\n",
      "\n",
      "  [[0.06088851 0.06142418 0.06963788]\n",
      "   [0.06088851 0.06142418 0.06963788]\n",
      "   [0.06203128 0.06428112 0.07295907]\n",
      "   ...\n",
      "   [0.05013927 0.05124634 0.05046068]\n",
      "   [0.05221056 0.0535676  0.05749589]\n",
      "   [0.05381759 0.05346047 0.05878152]]\n",
      "\n",
      "  [[0.05763874 0.06081709 0.0672452 ]\n",
      "   [0.05763874 0.06081709 0.0672452 ]\n",
      "   [0.05835297 0.05971002 0.06381687]\n",
      "   ...\n",
      "   [0.04796086 0.04913935 0.04681809]\n",
      "   [0.05131776 0.05271052 0.05653168]\n",
      "   [0.05210342 0.05217484 0.05710306]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.04928219 0.04556817 0.0508178 ]\n",
      "   [0.04928219 0.04556817 0.0508178 ]\n",
      "   [0.05178202 0.04910364 0.05488894]\n",
      "   ...\n",
      "   [0.04163988 0.03867581 0.03503321]\n",
      "   [0.03760446 0.03531891 0.03167631]\n",
      "   [0.0377473  0.03728305 0.03253339]]\n",
      "\n",
      "  [[0.04928219 0.04556817 0.0508178 ]\n",
      "   [0.04928219 0.04556817 0.0508178 ]\n",
      "   [0.05178202 0.04910364 0.05488894]\n",
      "   ...\n",
      "   [0.04163988 0.03867581 0.03503321]\n",
      "   [0.03760446 0.03531891 0.03167631]\n",
      "   [0.0377473  0.03728305 0.03253339]]\n",
      "\n",
      "  [[0.04874652 0.04553246 0.05113921]\n",
      "   [0.04874652 0.04553246 0.05113921]\n",
      "   [0.0514249  0.04856796 0.05531748]\n",
      "   ...\n",
      "   [0.03821156 0.03389044 0.03217627]\n",
      "   [0.04063996 0.03664024 0.03631883]\n",
      "   [0.04092565 0.03871152 0.03628312]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02942647 0.02806942 0.01532033]\n",
      "   [0.02942647 0.02806942 0.01532033]\n",
      "   [0.03017642 0.02899793 0.01839154]\n",
      "   ...\n",
      "   [0.03078352 0.0255696  0.01832012]\n",
      "   [0.03024784 0.02889079 0.01849868]\n",
      "   [0.03189058 0.02942647 0.02081994]]\n",
      "\n",
      "  [[0.02960503 0.02703378 0.01453468]\n",
      "   [0.02960503 0.02703378 0.01453468]\n",
      "   [0.02889079 0.02656953 0.01574888]\n",
      "   ...\n",
      "   [0.03128348 0.02853368 0.01932005]\n",
      "   [0.03006928 0.02899793 0.01799871]\n",
      "   [0.03010499 0.02806942 0.01828441]]\n",
      "\n",
      "  [[0.02992643 0.02610528 0.01432041]\n",
      "   [0.02992643 0.02610528 0.01432041]\n",
      "   [0.02935505 0.02596243 0.01617742]\n",
      "   ...\n",
      "   [0.03235483 0.02978359 0.02199843]\n",
      "   [0.03246197 0.02749804 0.02131991]\n",
      "   [0.0313549  0.02906935 0.02014142]]]\n",
      "\n",
      "\n",
      " [[[0.04371116 0.03685451 0.03874723]\n",
      "   [0.04371116 0.03685451 0.03874723]\n",
      "   [0.04213985 0.03714021 0.0331762 ]\n",
      "   ...\n",
      "   [0.04346118 0.03528319 0.02846225]\n",
      "   [0.04224698 0.03460467 0.02828369]\n",
      "   [0.0392472  0.03381901 0.02621241]]\n",
      "\n",
      "  [[0.04371116 0.03685451 0.03874723]\n",
      "   [0.04371116 0.03685451 0.03874723]\n",
      "   [0.04213985 0.03714021 0.0331762 ]\n",
      "   ...\n",
      "   [0.04346118 0.03528319 0.02846225]\n",
      "   [0.04224698 0.03460467 0.02828369]\n",
      "   [0.0392472  0.03381901 0.02621241]]\n",
      "\n",
      "  [[0.04399686 0.03664024 0.03660453]\n",
      "   [0.04399686 0.03664024 0.03660453]\n",
      "   [0.04271124 0.03678309 0.0356046 ]\n",
      "   ...\n",
      "   [0.04646097 0.03942576 0.03149775]\n",
      "   [0.04096136 0.03828298 0.02667667]\n",
      "   [0.03810442 0.03535462 0.0231412 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0666381  0.06099564 0.06460253]\n",
      "   [0.0666381  0.06099564 0.06460253]\n",
      "   [0.06963788 0.06628098 0.06899507]\n",
      "   ...\n",
      "   [0.03935433 0.03185487 0.02267695]\n",
      "   [0.03978287 0.03239054 0.0225341 ]\n",
      "   [0.03989001 0.03360474 0.02381973]]\n",
      "\n",
      "  [[0.06910221 0.06485251 0.06763802]\n",
      "   [0.06910221 0.06485251 0.06763802]\n",
      "   [0.07692308 0.07260196 0.07935148]\n",
      "   ...\n",
      "   [0.03935433 0.03228341 0.02353403]\n",
      "   [0.03931862 0.03199771 0.02249839]\n",
      "   [0.03892579 0.03160489 0.0228198 ]]\n",
      "\n",
      "  [[0.06828084 0.06303121 0.06492393]\n",
      "   [0.06828084 0.06303121 0.06492393]\n",
      "   [0.07338762 0.06874509 0.07206628]\n",
      "   ...\n",
      "   [0.03971145 0.03364046 0.02560531]\n",
      "   [0.04031855 0.03289051 0.02481966]\n",
      "   [0.04021141 0.03231912 0.0234269 ]]]\n",
      "\n",
      "\n",
      " [[[0.06824513 0.07781587 0.08877937]\n",
      "   [0.06824513 0.07781587 0.08877937]\n",
      "   [0.06742375 0.07803014 0.08688665]\n",
      "   ...\n",
      "   [0.05896007 0.06335261 0.07431612]\n",
      "   [0.05588887 0.05663881 0.06631669]\n",
      "   [0.05246054 0.05210342 0.05956717]]\n",
      "\n",
      "  [[0.06824513 0.07781587 0.08877937]\n",
      "   [0.06824513 0.07781587 0.08877937]\n",
      "   [0.06742375 0.07803014 0.08688665]\n",
      "   ...\n",
      "   [0.05896007 0.06335261 0.07431612]\n",
      "   [0.05588887 0.05663881 0.06631669]\n",
      "   [0.05246054 0.05210342 0.05956717]]\n",
      "\n",
      "  [[0.06749518 0.07803014 0.08670809]\n",
      "   [0.06749518 0.07803014 0.08670809]\n",
      "   [0.06628098 0.07531605 0.08513678]\n",
      "   ...\n",
      "   [0.05378187 0.05553175 0.06274552]\n",
      "   [0.04910364 0.04774659 0.05196057]\n",
      "   [0.04985358 0.04824656 0.05453182]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06313835 0.06792372 0.08113706]\n",
      "   [0.06313835 0.06792372 0.08113706]\n",
      "   [0.05981716 0.0651025  0.07656596]\n",
      "   ...\n",
      "   [0.05206771 0.05160346 0.06053139]\n",
      "   [0.05253196 0.0529605  0.06120991]\n",
      "   [0.05367474 0.05578173 0.06310263]]\n",
      "\n",
      "  [[0.06017427 0.06431683 0.07410185]\n",
      "   [0.06017427 0.06431683 0.07410185]\n",
      "   [0.05471038 0.05613885 0.06595957]\n",
      "   ...\n",
      "   [0.05999571 0.06667381 0.07463752]\n",
      "   [0.05363902 0.05610314 0.06506678]\n",
      "   [0.05188915 0.05210342 0.05824584]]\n",
      "\n",
      "  [[0.05856724 0.06124562 0.07138776]\n",
      "   [0.05856724 0.06124562 0.07138776]\n",
      "   [0.05438897 0.05438897 0.06563817]\n",
      "   ...\n",
      "   [0.06538819 0.0724234  0.08649382]\n",
      "   [0.05746018 0.0602457  0.07092351]\n",
      "   [0.05181773 0.05306764 0.05863867]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.02714092 0.0255696  0.01307049]\n",
      "   [0.02714092 0.0255696  0.01307049]\n",
      "   [0.02853368 0.02535533 0.01392758]\n",
      "   ...\n",
      "   [0.03024784 0.02828369 0.01817727]\n",
      "   [0.03106921 0.027998   0.0173559 ]\n",
      "   [0.03710449 0.03339047 0.02003428]]\n",
      "\n",
      "  [[0.02714092 0.0255696  0.01307049]\n",
      "   [0.02714092 0.0255696  0.01307049]\n",
      "   [0.02853368 0.02535533 0.01392758]\n",
      "   ...\n",
      "   [0.03024784 0.02828369 0.01817727]\n",
      "   [0.03106921 0.027998   0.0173559 ]\n",
      "   [0.03710449 0.03339047 0.02003428]]\n",
      "\n",
      "  [[0.02703378 0.02478394 0.01228484]\n",
      "   [0.02703378 0.02478394 0.01228484]\n",
      "   [0.02592672 0.0209985  0.01135633]\n",
      "   ...\n",
      "   [0.03089065 0.02839083 0.01807014]\n",
      "   [0.03485465 0.03089065 0.01899864]\n",
      "   [0.03839011 0.03474752 0.02078423]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03931862 0.03374759 0.02053425]\n",
      "   [0.03931862 0.03374759 0.02053425]\n",
      "   [0.04088994 0.03649739 0.02239126]\n",
      "   ...\n",
      "   [0.04299693 0.04749661 0.04692522]\n",
      "   [0.03874723 0.04160417 0.04024712]\n",
      "   [0.0477823  0.05260339 0.05917434]]\n",
      "\n",
      "  [[0.04031855 0.03603314 0.02153418]\n",
      "   [0.04031855 0.03603314 0.02153418]\n",
      "   [0.04167559 0.03771159 0.0234269 ]\n",
      "   ...\n",
      "   [0.03321191 0.03214056 0.02256982]\n",
      "   [0.03067638 0.03221199 0.02371259]\n",
      "   [0.04578244 0.04460396 0.04599671]]\n",
      "\n",
      "  [[0.04135419 0.0377473  0.02242697]\n",
      "   [0.04135419 0.0377473  0.02242697]\n",
      "   [0.04246125 0.03846154 0.02349832]\n",
      "   ...\n",
      "   [0.03396186 0.03589029 0.02746232]\n",
      "   [0.03406899 0.03539033 0.03114063]\n",
      "   [0.04617527 0.0438183  0.04299693]]]\n",
      "\n",
      "\n",
      " [[[0.03324762 0.03206914 0.02856939]\n",
      "   [0.03324762 0.03206914 0.02856939]\n",
      "   [0.03796157 0.03460467 0.03428327]\n",
      "   ...\n",
      "   [0.03746161 0.0368188  0.03656882]\n",
      "   [0.03524748 0.03246197 0.03246197]\n",
      "   [0.0356046  0.03428327 0.03246197]]\n",
      "\n",
      "  [[0.03324762 0.03206914 0.02856939]\n",
      "   [0.03324762 0.03206914 0.02856939]\n",
      "   [0.03796157 0.03460467 0.03428327]\n",
      "   ...\n",
      "   [0.03746161 0.0368188  0.03656882]\n",
      "   [0.03524748 0.03246197 0.03246197]\n",
      "   [0.0356046  0.03428327 0.03246197]]\n",
      "\n",
      "  [[0.03396186 0.0325691  0.03006928]\n",
      "   [0.03396186 0.0325691  0.03006928]\n",
      "   [0.03453325 0.03249768 0.03281908]\n",
      "   ...\n",
      "   [0.03756874 0.03574745 0.03546175]\n",
      "   [0.03510464 0.03335476 0.03249768]\n",
      "   [0.03631883 0.03431898 0.03421184]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03867581 0.03856868 0.03710449]\n",
      "   [0.03867581 0.03856868 0.03710449]\n",
      "   [0.03960431 0.03903292 0.03789015]\n",
      "   ...\n",
      "   [0.02956932 0.02596243 0.01860581]\n",
      "   [0.02881937 0.02514106 0.01889151]\n",
      "   [0.0331762  0.03206914 0.02417685]]\n",
      "\n",
      "  [[0.03874723 0.03960431 0.03614027]\n",
      "   [0.03874723 0.03960431 0.03614027]\n",
      "   [0.03921149 0.03842583 0.03824727]\n",
      "   ...\n",
      "   [0.03149775 0.02724805 0.01946289]\n",
      "   [0.02960503 0.02589101 0.01985572]\n",
      "   [0.03567602 0.03446182 0.02660524]]\n",
      "\n",
      "  [[0.03760446 0.03756874 0.03646168]\n",
      "   [0.03760446 0.03756874 0.03646168]\n",
      "   [0.03917577 0.03810442 0.03874723]\n",
      "   ...\n",
      "   [0.03539033 0.03228341 0.03078352]\n",
      "   [0.03374759 0.02992643 0.0249625 ]\n",
      "   [0.03824727 0.03617599 0.03142633]]]\n",
      "\n",
      "\n",
      " [[[0.03564031 0.03003357 0.03528319]\n",
      "   [0.03564031 0.03003357 0.03528319]\n",
      "   [0.0450325  0.04074709 0.04363974]\n",
      "   ...\n",
      "   [0.03389044 0.02796229 0.02256982]\n",
      "   [0.03639026 0.02946218 0.02578387]\n",
      "   [0.04317549 0.03539033 0.03278337]]\n",
      "\n",
      "  [[0.03564031 0.03003357 0.03528319]\n",
      "   [0.03564031 0.03003357 0.03528319]\n",
      "   [0.0450325  0.04074709 0.04363974]\n",
      "   ...\n",
      "   [0.03389044 0.02796229 0.02256982]\n",
      "   [0.03639026 0.02946218 0.02578387]\n",
      "   [0.04317549 0.03539033 0.03278337]]\n",
      "\n",
      "  [[0.03867581 0.03339047 0.03814013]\n",
      "   [0.03867581 0.03339047 0.03814013]\n",
      "   [0.04378259 0.04053282 0.04174702]\n",
      "   ...\n",
      "   [0.03492608 0.03035497 0.02521249]\n",
      "   [0.03799729 0.02960503 0.02571245]\n",
      "   [0.04213985 0.03510464 0.03310478]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03778302 0.03471181 0.03035497]\n",
      "   [0.03778302 0.03471181 0.03035497]\n",
      "   [0.0407828  0.03696164 0.03649739]\n",
      "   ...\n",
      "   [0.03603314 0.03456896 0.02546247]\n",
      "   [0.03610456 0.03349761 0.03071209]\n",
      "   [0.03274766 0.02610528 0.02474823]]\n",
      "\n",
      "  [[0.04238983 0.03435469 0.03160489]\n",
      "   [0.04238983 0.03435469 0.03160489]\n",
      "   [0.04053282 0.03610456 0.03267624]\n",
      "   ...\n",
      "   [0.03406899 0.03149775 0.02549818]\n",
      "   [0.03339047 0.02806942 0.02849796]\n",
      "   [0.03603314 0.03121206 0.03549746]]\n",
      "\n",
      "  [[0.03796157 0.0304264  0.02889079]\n",
      "   [0.03796157 0.0304264  0.02889079]\n",
      "   [0.03771159 0.03189058 0.03010499]\n",
      "   ...\n",
      "   [0.03406899 0.02764088 0.02760517]\n",
      "   [0.03485465 0.03106921 0.03364046]\n",
      "   [0.03931862 0.03599743 0.03846154]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.04738947 0.04006857 0.0228198 ]\n",
      "   [0.04738947 0.04006857 0.0228198 ]\n",
      "   [0.0483894  0.04010428 0.02381973]\n",
      "   ...\n",
      "   [0.04771088 0.03796157 0.02349832]\n",
      "   [0.04774659 0.03728305 0.02389115]\n",
      "   [0.045961   0.03435469 0.02124848]]\n",
      "\n",
      "  [[0.04738947 0.04006857 0.0228198 ]\n",
      "   [0.04738947 0.04006857 0.0228198 ]\n",
      "   [0.0483894  0.04010428 0.02381973]\n",
      "   ...\n",
      "   [0.04771088 0.03796157 0.02349832]\n",
      "   [0.04774659 0.03728305 0.02389115]\n",
      "   [0.045961   0.03435469 0.02124848]]\n",
      "\n",
      "  [[0.04806799 0.03953289 0.02356975]\n",
      "   [0.04806799 0.03953289 0.02356975]\n",
      "   [0.04796086 0.04028284 0.02367688]\n",
      "   ...\n",
      "   [0.04742518 0.0374259  0.02364117]\n",
      "   [0.04806799 0.03674737 0.02456967]\n",
      "   [0.04803228 0.03574745 0.0243554 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05156774 0.04299693 0.03124777]\n",
      "   [0.05156774 0.04299693 0.03124777]\n",
      "   [0.05010356 0.04121134 0.02856939]\n",
      "   ...\n",
      "   [0.04874652 0.03846154 0.02231983]\n",
      "   [0.04796086 0.03906864 0.02146275]\n",
      "   [0.04756803 0.03960431 0.02185558]]\n",
      "\n",
      "  [[0.05167488 0.04388972 0.03146204]\n",
      "   [0.05167488 0.04388972 0.03146204]\n",
      "   [0.05135347 0.04217556 0.02971216]\n",
      "   ...\n",
      "   [0.0483894  0.0389615  0.02214128]\n",
      "   [0.04842511 0.0383544  0.02178416]\n",
      "   [0.04792515 0.03831869 0.02271266]]\n",
      "\n",
      "  [[0.05053211 0.04463967 0.03167631]\n",
      "   [0.05053211 0.04463967 0.03167631]\n",
      "   [0.05121063 0.04181844 0.02935505]\n",
      "   ...\n",
      "   [0.04849654 0.03914006 0.02074852]\n",
      "   [0.04806799 0.03785444 0.02164131]\n",
      "   [0.04792515 0.03828298 0.02199843]]]\n",
      "\n",
      "\n",
      " [[[0.03221199 0.02742661 0.01685594]\n",
      "   [0.03221199 0.02742661 0.01685594]\n",
      "   [0.0301407  0.02296264 0.0146061 ]\n",
      "   ...\n",
      "   [0.03381901 0.03374759 0.01803443]\n",
      "   [0.03356903 0.03349761 0.01835583]\n",
      "   [0.03367617 0.03346189 0.01803443]]\n",
      "\n",
      "  [[0.03221199 0.02742661 0.01685594]\n",
      "   [0.03221199 0.02742661 0.01685594]\n",
      "   [0.0301407  0.02296264 0.0146061 ]\n",
      "   ...\n",
      "   [0.03381901 0.03374759 0.01803443]\n",
      "   [0.03356903 0.03349761 0.01835583]\n",
      "   [0.03367617 0.03346189 0.01803443]]\n",
      "\n",
      "  [[0.03271195 0.03117635 0.01721306]\n",
      "   [0.03271195 0.03117635 0.01721306]\n",
      "   [0.03110492 0.02503393 0.01560603]\n",
      "   ...\n",
      "   [0.03367617 0.03281908 0.01810585]\n",
      "   [0.03424755 0.03360474 0.01821299]\n",
      "   [0.03396186 0.03385472 0.01835583]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03242626 0.03142633 0.01749875]\n",
      "   [0.03242626 0.03142633 0.01749875]\n",
      "   [0.03278337 0.03067638 0.01728448]\n",
      "   ...\n",
      "   [0.03417613 0.03292622 0.01982001]\n",
      "   [0.03346189 0.03160489 0.01907007]\n",
      "   [0.03339047 0.03006928 0.01810585]]\n",
      "\n",
      "  [[0.03249768 0.0316406  0.0176416 ]\n",
      "   [0.03249768 0.0316406  0.0176416 ]\n",
      "   [0.03292622 0.03049782 0.01682023]\n",
      "   ...\n",
      "   [0.03417613 0.03574745 0.02024855]\n",
      "   [0.03428327 0.03446182 0.02199843]\n",
      "   [0.03649739 0.03603314 0.02671238]]\n",
      "\n",
      "  [[0.0328548  0.03099779 0.01760589]\n",
      "   [0.0328548  0.03099779 0.01760589]\n",
      "   [0.03271195 0.02985501 0.01721306]\n",
      "   ...\n",
      "   [0.03428327 0.03610456 0.01996286]\n",
      "   [0.03589029 0.03571174 0.02546247]\n",
      "   [0.03724734 0.03781873 0.03078352]]]\n",
      "\n",
      "\n",
      " [[[0.06535248 0.06806657 0.08463681]\n",
      "   [0.06535248 0.06806657 0.08463681]\n",
      "   [0.06449539 0.06795943 0.08313692]\n",
      "   ...\n",
      "   [0.04524677 0.04149704 0.0426041 ]\n",
      "   [0.04574673 0.04203271 0.04342547]\n",
      "   [0.04571102 0.04221127 0.04346118]]\n",
      "\n",
      "  [[0.06535248 0.06806657 0.08463681]\n",
      "   [0.06535248 0.06806657 0.08463681]\n",
      "   [0.06449539 0.06795943 0.08313692]\n",
      "   ...\n",
      "   [0.04524677 0.04149704 0.0426041 ]\n",
      "   [0.04574673 0.04203271 0.04342547]\n",
      "   [0.04571102 0.04221127 0.04346118]]\n",
      "\n",
      "  [[0.06753089 0.07042354 0.08638669]\n",
      "   [0.06753089 0.07042354 0.08638669]\n",
      "   [0.06495965 0.06885222 0.08502964]\n",
      "   ...\n",
      "   [0.04538961 0.04253267 0.04428255]\n",
      "   [0.04538961 0.04203271 0.0432112 ]\n",
      "   [0.04560389 0.04217556 0.04303264]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04785372 0.04692522 0.04374687]\n",
      "   [0.04785372 0.04692522 0.04374687]\n",
      "   [0.04703236 0.04546104 0.04010428]\n",
      "   ...\n",
      "   [0.05481751 0.05792443 0.072102  ]\n",
      "   [0.0553889  0.0584244  0.07049496]\n",
      "   [0.0544604  0.0572102  0.07113778]]\n",
      "\n",
      "  [[0.04606814 0.04385401 0.03921149]\n",
      "   [0.04606814 0.04385401 0.03921149]\n",
      "   [0.04635383 0.04506821 0.03871152]\n",
      "   ...\n",
      "   [0.05535319 0.05763874 0.07228055]\n",
      "   [0.05642454 0.05906721 0.07113778]\n",
      "   [0.0566031  0.05949575 0.07170916]]\n",
      "\n",
      "  [[0.04413971 0.04181844 0.03553317]\n",
      "   [0.04413971 0.04181844 0.03553317]\n",
      "   [0.04603243 0.04396114 0.03785444]\n",
      "   ...\n",
      "   [0.05688879 0.0590315  0.07213771]\n",
      "   [0.05638883 0.05810299 0.07163774]\n",
      "   [0.05613885 0.05878152 0.0706021 ]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.04878223 0.055996   0.0675666 ]\n",
      "   [0.04878223 0.055996   0.0675666 ]\n",
      "   [0.04860367 0.05535319 0.0657453 ]\n",
      "   ...\n",
      "   [0.06120991 0.07285194 0.08927934]\n",
      "   [0.05981716 0.07188772 0.08749375]\n",
      "   [0.05988858 0.07110207 0.08767231]]\n",
      "\n",
      "  [[0.04878223 0.055996   0.0675666 ]\n",
      "   [0.04878223 0.055996   0.0675666 ]\n",
      "   [0.04860367 0.05535319 0.0657453 ]\n",
      "   ...\n",
      "   [0.06120991 0.07285194 0.08927934]\n",
      "   [0.05981716 0.07188772 0.08749375]\n",
      "   [0.05988858 0.07110207 0.08767231]]\n",
      "\n",
      "  [[0.05335333 0.06128134 0.07285194]\n",
      "   [0.05335333 0.06128134 0.07285194]\n",
      "   [0.05078209 0.05913863 0.07053068]\n",
      "   ...\n",
      "   [0.05946004 0.06956646 0.08663667]\n",
      "   [0.0584244  0.07056639 0.08560103]\n",
      "   [0.06063852 0.07199486 0.08792229]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04028284 0.04496107 0.04531819]\n",
      "   [0.04028284 0.04496107 0.04531819]\n",
      "   [0.03953289 0.04228269 0.0456396 ]\n",
      "   ...\n",
      "   [0.05124634 0.06274552 0.07503036]\n",
      "   [0.05331762 0.06406685 0.0776016 ]\n",
      "   [0.05381759 0.06660239 0.0797443 ]]\n",
      "\n",
      "  [[0.03321191 0.0316406  0.02414113]\n",
      "   [0.03321191 0.0316406  0.02414113]\n",
      "   [0.03464038 0.03346189 0.02814085]\n",
      "   ...\n",
      "   [0.05088922 0.05906721 0.07085208]\n",
      "   [0.05106778 0.06120991 0.0742447 ]\n",
      "   [0.05135347 0.06142418 0.07438754]]\n",
      "\n",
      "  [[0.03406899 0.03281908 0.02835512]\n",
      "   [0.03406899 0.03281908 0.02835512]\n",
      "   [0.03467609 0.03396186 0.03085494]\n",
      "   ...\n",
      "   [0.04806799 0.05546032 0.06738804]\n",
      "   [0.04942504 0.05821013 0.07085208]\n",
      "   [0.05049639 0.05924577 0.07235198]]]\n",
      "\n",
      "\n",
      " [[[0.03335476 0.03035497 0.01807014]\n",
      "   [0.03335476 0.03035497 0.01807014]\n",
      "   [0.03289051 0.02974788 0.01814156]\n",
      "   ...\n",
      "   [0.04310406 0.0401757  0.04449682]\n",
      "   [0.04413971 0.04056853 0.04642526]\n",
      "   [0.04431826 0.04121134 0.04635383]]\n",
      "\n",
      "  [[0.03335476 0.03035497 0.01807014]\n",
      "   [0.03335476 0.03035497 0.01807014]\n",
      "   [0.03289051 0.02974788 0.01814156]\n",
      "   ...\n",
      "   [0.04310406 0.0401757  0.04449682]\n",
      "   [0.04413971 0.04056853 0.04642526]\n",
      "   [0.04431826 0.04121134 0.04635383]]\n",
      "\n",
      "  [[0.03249768 0.03060496 0.01832012]\n",
      "   [0.03249768 0.03060496 0.01832012]\n",
      "   [0.03228341 0.03056924 0.01842725]\n",
      "   ...\n",
      "   [0.04403257 0.0407828  0.04556817]\n",
      "   [0.04485394 0.04171131 0.04724662]\n",
      "   [0.04581816 0.04349689 0.05060353]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03824727 0.03664024 0.03417613]\n",
      "   [0.03824727 0.03664024 0.03417613]\n",
      "   [0.03881866 0.03671166 0.03546175]\n",
      "   ...\n",
      "   [0.04288979 0.0426041  0.04238983]\n",
      "   [0.04574673 0.04510392 0.04949646]\n",
      "   [0.04885365 0.04892508 0.05631741]]\n",
      "\n",
      "  [[0.03964002 0.03792586 0.03792586]\n",
      "   [0.03964002 0.03792586 0.03792586]\n",
      "   [0.03939004 0.03721163 0.03639026]\n",
      "   ...\n",
      "   [0.04981787 0.05042497 0.05896007]\n",
      "   [0.05063924 0.05131776 0.05956717]\n",
      "   [0.05067495 0.05167488 0.06031712]]\n",
      "\n",
      "  [[0.0386401  0.03589029 0.0337833 ]\n",
      "   [0.0386401  0.03589029 0.0337833 ]\n",
      "   [0.03949718 0.03667595 0.03585458]\n",
      "   ...\n",
      "   [0.05121063 0.05242483 0.06235269]\n",
      "   [0.05088922 0.05260339 0.06199557]\n",
      "   [0.05146061 0.05338904 0.06295979]]]\n",
      "\n",
      "\n",
      " [[[0.03856868 0.03596172 0.03760446]\n",
      "   [0.03856868 0.03596172 0.03760446]\n",
      "   [0.0407828  0.03871152 0.04074709]\n",
      "   ...\n",
      "   [0.04071138 0.03781873 0.03517606]\n",
      "   [0.04221127 0.03992572 0.03831869]\n",
      "   [0.04481823 0.04267552 0.04385401]]\n",
      "\n",
      "  [[0.03856868 0.03596172 0.03760446]\n",
      "   [0.03856868 0.03596172 0.03760446]\n",
      "   [0.0407828  0.03871152 0.04074709]\n",
      "   ...\n",
      "   [0.04071138 0.03781873 0.03517606]\n",
      "   [0.04221127 0.03992572 0.03831869]\n",
      "   [0.04481823 0.04267552 0.04385401]]\n",
      "\n",
      "  [[0.03710449 0.03353332 0.03117635]\n",
      "   [0.03710449 0.03353332 0.03117635]\n",
      "   [0.03767588 0.03278337 0.03203342]\n",
      "   ...\n",
      "   [0.04128277 0.03917577 0.03671166]\n",
      "   [0.04421113 0.04103278 0.04163988]\n",
      "   [0.04467538 0.04331833 0.04267552]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03639026 0.03039069 0.02481966]\n",
      "   [0.03639026 0.03039069 0.02481966]\n",
      "   [0.03628312 0.03028355 0.02406971]\n",
      "   ...\n",
      "   [0.03928291 0.03592601 0.03178344]\n",
      "   [0.04610385 0.04281837 0.04317549]\n",
      "   [0.0413899  0.03828298 0.03342618]]\n",
      "\n",
      "  [[0.03564031 0.03028355 0.02474823]\n",
      "   [0.03564031 0.03028355 0.02474823]\n",
      "   [0.03542604 0.02989072 0.02367688]\n",
      "   ...\n",
      "   [0.04213985 0.04060424 0.03517606]\n",
      "   [0.04660381 0.04403257 0.04371116]\n",
      "   [0.03999714 0.03567602 0.02924791]]\n",
      "\n",
      "  [[0.03578316 0.02924791 0.02381973]\n",
      "   [0.03578316 0.02924791 0.02381973]\n",
      "   [0.03496179 0.02946218 0.02256982]\n",
      "   ...\n",
      "   [0.04285408 0.04149704 0.03778302]\n",
      "   [0.04285408 0.03921149 0.03892579]\n",
      "   [0.03828298 0.03481894 0.02885508]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03328334 0.02731948 0.02321263]\n",
      "   [0.03328334 0.02731948 0.02321263]\n",
      "   [0.03531891 0.03071209 0.02671238]\n",
      "   ...\n",
      "   [0.03821156 0.03464038 0.03821156]\n",
      "   [0.03739019 0.03442611 0.03746161]\n",
      "   [0.03746161 0.03514035 0.03842583]]\n",
      "\n",
      "  [[0.03328334 0.02731948 0.02321263]\n",
      "   [0.03328334 0.02731948 0.02321263]\n",
      "   [0.03531891 0.03071209 0.02671238]\n",
      "   ...\n",
      "   [0.03821156 0.03464038 0.03821156]\n",
      "   [0.03739019 0.03442611 0.03746161]\n",
      "   [0.03746161 0.03514035 0.03842583]]\n",
      "\n",
      "  [[0.03281908 0.02964074 0.01992715]\n",
      "   [0.03281908 0.02964074 0.01992715]\n",
      "   [0.03274766 0.03085494 0.02242697]\n",
      "   ...\n",
      "   [0.03874723 0.03456896 0.0377473 ]\n",
      "   [0.03842583 0.03478323 0.03753303]\n",
      "   [0.03824727 0.03456896 0.03824727]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03374759 0.03071209 0.02149846]\n",
      "   [0.03374759 0.03071209 0.02149846]\n",
      "   [0.03371188 0.03085494 0.02235555]\n",
      "   ...\n",
      "   [0.03128348 0.02721234 0.01632026]\n",
      "   [0.03192629 0.0273909  0.01714163]\n",
      "   [0.0325691  0.02914078 0.01924863]]\n",
      "\n",
      "  [[0.03385472 0.03099779 0.021927  ]\n",
      "   [0.03385472 0.03099779 0.021927  ]\n",
      "   [0.0343904  0.03167631 0.0234269 ]\n",
      "   ...\n",
      "   [0.03081923 0.0276766  0.01771302]\n",
      "   [0.03071209 0.02781944 0.01724877]\n",
      "   [0.0307478  0.02753375 0.01692736]]\n",
      "\n",
      "  [[0.03606885 0.03521177 0.02853368]\n",
      "   [0.03606885 0.03521177 0.02853368]\n",
      "   [0.03910435 0.03624741 0.02935505]\n",
      "   ...\n",
      "   [0.03181916 0.02867652 0.0182487 ]\n",
      "   [0.03171202 0.02828369 0.01903435]\n",
      "   [0.0310335  0.02824798 0.01860581]]]\n",
      "\n",
      "\n",
      " [[[0.04071138 0.03678309 0.03599743]\n",
      "   [0.04071138 0.03678309 0.03599743]\n",
      "   [0.04071138 0.03717592 0.03685451]\n",
      "   ...\n",
      "   [0.04174702 0.03810442 0.03799729]\n",
      "   [0.0413899  0.03749732 0.03756874]\n",
      "   [0.03989001 0.03460467 0.03549746]]\n",
      "\n",
      "  [[0.04071138 0.03678309 0.03599743]\n",
      "   [0.04071138 0.03678309 0.03599743]\n",
      "   [0.04071138 0.03717592 0.03685451]\n",
      "   ...\n",
      "   [0.04174702 0.03810442 0.03799729]\n",
      "   [0.0413899  0.03749732 0.03756874]\n",
      "   [0.03989001 0.03460467 0.03549746]]\n",
      "\n",
      "  [[0.04056853 0.03646168 0.03664024]\n",
      "   [0.04056853 0.03646168 0.03664024]\n",
      "   [0.04035426 0.03671166 0.03685451]\n",
      "   ...\n",
      "   [0.04156846 0.03756874 0.03739019]\n",
      "   [0.03967574 0.03581887 0.03628312]\n",
      "   [0.03785444 0.03289051 0.0328548 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04246125 0.03971145 0.04024712]\n",
      "   [0.04246125 0.03971145 0.04024712]\n",
      "   [0.04217556 0.03839011 0.03921149]\n",
      "   ...\n",
      "   [0.03689022 0.0356046  0.02992643]\n",
      "   [0.03767588 0.0368188  0.03346189]\n",
      "   [0.04110421 0.04188986 0.03853296]]\n",
      "\n",
      "  [[0.04206842 0.03928291 0.03981858]\n",
      "   [0.04206842 0.03928291 0.03981858]\n",
      "   [0.04224698 0.03892579 0.03999714]\n",
      "   ...\n",
      "   [0.03639026 0.03524748 0.02899793]\n",
      "   [0.03639026 0.03728305 0.03231912]\n",
      "   [0.04131848 0.04160417 0.03781873]]\n",
      "\n",
      "  [[0.04274695 0.03942576 0.03871152]\n",
      "   [0.04274695 0.03942576 0.03871152]\n",
      "   [0.04306835 0.03928291 0.03978287]\n",
      "   ...\n",
      "   [0.03514035 0.03403328 0.02567674]\n",
      "   [0.03606885 0.03724734 0.03060496]\n",
      "   [0.03789015 0.03842583 0.03139061]]]\n",
      "\n",
      "\n",
      " [[[0.04938933 0.05042497 0.0362117 ]\n",
      "   [0.04938933 0.05042497 0.0362117 ]\n",
      "   [0.0502107  0.05156774 0.03753303]\n",
      "   ...\n",
      "   [0.0337833  0.03749732 0.02096279]\n",
      "   [0.03389044 0.03703307 0.02149846]\n",
      "   [0.03535462 0.03778302 0.02453396]]\n",
      "\n",
      "  [[0.04938933 0.05042497 0.0362117 ]\n",
      "   [0.04938933 0.05042497 0.0362117 ]\n",
      "   [0.0502107  0.05156774 0.03753303]\n",
      "   ...\n",
      "   [0.0337833  0.03749732 0.02096279]\n",
      "   [0.03389044 0.03703307 0.02149846]\n",
      "   [0.03535462 0.03778302 0.02453396]]\n",
      "\n",
      "  [[0.05010356 0.05128205 0.03721163]\n",
      "   [0.05010356 0.05128205 0.03721163]\n",
      "   [0.04971074 0.05106778 0.03728305]\n",
      "   ...\n",
      "   [0.03403328 0.03753303 0.02114135]\n",
      "   [0.03510464 0.03889008 0.02546247]\n",
      "   [0.03821156 0.04085422 0.03324762]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03421184 0.03381901 0.02149846]\n",
      "   [0.03421184 0.03381901 0.02149846]\n",
      "   [0.03389044 0.03396186 0.02096279]\n",
      "   ...\n",
      "   [0.08910078 0.09388615 0.1016356 ]\n",
      "   [0.08760089 0.09338619 0.09956431]\n",
      "   [0.08370831 0.08985072 0.09674309]]\n",
      "\n",
      "  [[0.03289051 0.02928362 0.01942718]\n",
      "   [0.03289051 0.02928362 0.01942718]\n",
      "   [0.03314049 0.03292622 0.02024855]\n",
      "   ...\n",
      "   [0.08899365 0.09406471 0.10238554]\n",
      "   [0.08727948 0.09327905 0.10049282]\n",
      "   [0.08649382 0.09238626 0.09885008]]\n",
      "\n",
      "  [[0.03278337 0.03085494 0.01957003]\n",
      "   [0.03278337 0.03085494 0.01957003]\n",
      "   [0.03324762 0.03289051 0.02071281]\n",
      "   ...\n",
      "   [0.09077923 0.09760017 0.10667095]\n",
      "   [0.08899365 0.09592172 0.10484965]\n",
      "   [0.08799371 0.09470752 0.10145704]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.02967645 0.0246411  0.0146061 ]\n",
      "   [0.02967645 0.0246411  0.0146061 ]\n",
      "   [0.03028355 0.02421256 0.01374902]\n",
      "   ...\n",
      "   [0.0328548  0.02967645 0.01989144]\n",
      "   [0.03271195 0.02885508 0.01942718]\n",
      "   [0.03260481 0.0295336  0.02042711]]\n",
      "\n",
      "  [[0.02967645 0.0246411  0.0146061 ]\n",
      "   [0.02967645 0.0246411  0.0146061 ]\n",
      "   [0.03028355 0.02421256 0.01374902]\n",
      "   ...\n",
      "   [0.0328548  0.02967645 0.01989144]\n",
      "   [0.03271195 0.02885508 0.01942718]\n",
      "   [0.03260481 0.0295336  0.02042711]]\n",
      "\n",
      "  [[0.02996214 0.02514106 0.01467752]\n",
      "   [0.02996214 0.02514106 0.01467752]\n",
      "   [0.03010499 0.02564103 0.01439183]\n",
      "   ...\n",
      "   [0.03178344 0.02896222 0.01942718]\n",
      "   [0.03178344 0.02946218 0.01878437]\n",
      "   [0.03235483 0.02935505 0.01999857]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02889079 0.02285551 0.01314192]\n",
      "   [0.02889079 0.02285551 0.01314192]\n",
      "   [0.02881937 0.0234269  0.01374902]\n",
      "   ...\n",
      "   [0.03067638 0.02589101 0.01649882]\n",
      "   [0.02985501 0.02446254 0.01599886]\n",
      "   [0.03078352 0.02571245 0.01749875]]\n",
      "\n",
      "  [[0.02946218 0.02360546 0.01457039]\n",
      "   [0.02946218 0.02360546 0.01457039]\n",
      "   [0.02903364 0.02346261 0.01417756]\n",
      "   ...\n",
      "   [0.03039069 0.02549818 0.01667738]\n",
      "   [0.03031926 0.02664095 0.01617742]\n",
      "   [0.03092636 0.0252482  0.01689165]]\n",
      "\n",
      "  [[0.0301407  0.02421256 0.01428469]\n",
      "   [0.0301407  0.02421256 0.01428469]\n",
      "   [0.02971216 0.02414113 0.01507035]\n",
      "   ...\n",
      "   [0.02971216 0.02449825 0.01510606]\n",
      "   [0.03049782 0.02492679 0.01596314]\n",
      "   [0.02974788 0.02439111 0.01567745]]]\n",
      "\n",
      "\n",
      " [[[0.04213985 0.0383544  0.03674737]\n",
      "   [0.04213985 0.0383544  0.03674737]\n",
      "   [0.04181844 0.03824727 0.03771159]\n",
      "   ...\n",
      "   [0.02896222 0.02442683 0.01639169]\n",
      "   [0.02906935 0.02349832 0.01714163]\n",
      "   [0.03474752 0.03210485 0.0328548 ]]\n",
      "\n",
      "  [[0.04213985 0.0383544  0.03674737]\n",
      "   [0.04213985 0.0383544  0.03674737]\n",
      "   [0.04181844 0.03824727 0.03771159]\n",
      "   ...\n",
      "   [0.02896222 0.02442683 0.01639169]\n",
      "   [0.02906935 0.02349832 0.01714163]\n",
      "   [0.03474752 0.03210485 0.0328548 ]]\n",
      "\n",
      "  [[0.04360403 0.04046139 0.03935433]\n",
      "   [0.04360403 0.04046139 0.03935433]\n",
      "   [0.04185415 0.03781873 0.03792586]\n",
      "   ...\n",
      "   [0.0276766  0.02142704 0.01482037]\n",
      "   [0.03185487 0.02874795 0.02460539]\n",
      "   [0.04024712 0.04174702 0.05096065]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03364046 0.03121206 0.02589101]\n",
      "   [0.03364046 0.03121206 0.02589101]\n",
      "   [0.04003286 0.03710449 0.03831869]\n",
      "   ...\n",
      "   [0.03167631 0.02992643 0.01982001]\n",
      "   [0.03417613 0.03228341 0.02260553]\n",
      "   [0.03531891 0.03417613 0.02514106]]\n",
      "\n",
      "  [[0.03367617 0.0310335  0.02628384]\n",
      "   [0.03367617 0.0310335  0.02628384]\n",
      "   [0.04174702 0.0395686  0.04263981]\n",
      "   ...\n",
      "   [0.03342618 0.03085494 0.02106992]\n",
      "   [0.03528319 0.03335476 0.02596243]\n",
      "   [0.03628312 0.03414042 0.0261767 ]]\n",
      "\n",
      "  [[0.03428327 0.03085494 0.02549818]\n",
      "   [0.03428327 0.03085494 0.02549818]\n",
      "   [0.0386401  0.03635455 0.03771159]\n",
      "   ...\n",
      "   [0.03485465 0.03253339 0.02492679]\n",
      "   [0.03692593 0.03485465 0.03078352]\n",
      "   [0.03760446 0.03506893 0.03028355]]]\n",
      "\n",
      "\n",
      " [[[0.03339047 0.02624813 0.01471324]\n",
      "   [0.03339047 0.02624813 0.01471324]\n",
      "   [0.03321191 0.02624813 0.01496322]\n",
      "   ...\n",
      "   [0.03299764 0.02596243 0.01567745]\n",
      "   [0.03410471 0.02642668 0.01571316]\n",
      "   [0.03396186 0.02560531 0.01535605]]\n",
      "\n",
      "  [[0.03339047 0.02624813 0.01471324]\n",
      "   [0.03339047 0.02624813 0.01471324]\n",
      "   [0.03321191 0.02624813 0.01496322]\n",
      "   ...\n",
      "   [0.03299764 0.02596243 0.01567745]\n",
      "   [0.03410471 0.02642668 0.01571316]\n",
      "   [0.03396186 0.02560531 0.01535605]]\n",
      "\n",
      "  [[0.03349761 0.02628384 0.01492751]\n",
      "   [0.03349761 0.02628384 0.01492751]\n",
      "   [0.03321191 0.02639097 0.01492751]\n",
      "   ...\n",
      "   [0.03299764 0.02574816 0.0155346 ]\n",
      "   [0.03403328 0.02656953 0.0158203 ]\n",
      "   [0.03403328 0.02635526 0.01589172]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03217627 0.0246411  0.01342761]\n",
      "   [0.03217627 0.0246411  0.01342761]\n",
      "   [0.03203342 0.02474823 0.01374902]\n",
      "   ...\n",
      "   [0.03374759 0.02703378 0.0155346 ]\n",
      "   [0.0337833  0.02692665 0.01524891]\n",
      "   [0.03406899 0.02689094 0.01592743]]\n",
      "\n",
      "  [[0.03214056 0.02446254 0.01360617]\n",
      "   [0.03214056 0.02446254 0.01360617]\n",
      "   [0.03217627 0.02439111 0.01378473]\n",
      "   ...\n",
      "   [0.03306907 0.02660524 0.01549889]\n",
      "   [0.03335476 0.02653382 0.0155346 ]\n",
      "   [0.03381901 0.02656953 0.0158203 ]]\n",
      "\n",
      "  [[0.03231912 0.02421256 0.01421327]\n",
      "   [0.03231912 0.02421256 0.01421327]\n",
      "   [0.03264052 0.02481966 0.013999  ]\n",
      "   ...\n",
      "   [0.03278337 0.02603385 0.01496322]\n",
      "   [0.03328334 0.02628384 0.01507035]\n",
      "   [0.03306907 0.02624813 0.01539176]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03503321 0.02599814 0.01664167]\n",
      "   [0.03503321 0.02599814 0.01664167]\n",
      "   [0.03564031 0.02778373 0.01721306]\n",
      "   ...\n",
      "   [0.04674666 0.03860439 0.03460467]\n",
      "   [0.04542533 0.03935433 0.03585458]\n",
      "   [0.04506821 0.03821156 0.03396186]]\n",
      "\n",
      "  [[0.03503321 0.02599814 0.01664167]\n",
      "   [0.03503321 0.02599814 0.01664167]\n",
      "   [0.03564031 0.02778373 0.01721306]\n",
      "   ...\n",
      "   [0.04674666 0.03860439 0.03460467]\n",
      "   [0.04542533 0.03935433 0.03585458]\n",
      "   [0.04506821 0.03821156 0.03396186]]\n",
      "\n",
      "  [[0.03464038 0.02581958 0.01664167]\n",
      "   [0.03464038 0.02581958 0.01664167]\n",
      "   [0.03524748 0.02603385 0.01589172]\n",
      "   ...\n",
      "   [0.04481823 0.03614027 0.03403328]\n",
      "   [0.0489965  0.03964002 0.03931862]\n",
      "   [0.03892579 0.02992643 0.02610528]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05317477 0.04706807 0.04213985]\n",
      "   [0.05317477 0.04706807 0.04213985]\n",
      "   [0.04613956 0.0362117  0.03306907]\n",
      "   ...\n",
      "   [0.03789015 0.03249768 0.02271266]\n",
      "   [0.04035426 0.03210485 0.02728377]\n",
      "   [0.03931862 0.03010499 0.02489108]]\n",
      "\n",
      "  [[0.05763874 0.04931791 0.04749661]\n",
      "   [0.05763874 0.04931791 0.04749661]\n",
      "   [0.0547818  0.04617527 0.04421113]\n",
      "   ...\n",
      "   [0.04031855 0.03610456 0.02935505]\n",
      "   [0.04196129 0.03356903 0.02842654]\n",
      "   [0.03949718 0.02949789 0.02560531]]\n",
      "\n",
      "  [[0.05853153 0.05099636 0.04731805]\n",
      "   [0.05853153 0.05099636 0.04731805]\n",
      "   [0.05403186 0.04738947 0.04574673]\n",
      "   ...\n",
      "   [0.04267552 0.03606885 0.03324762]\n",
      "   [0.04021141 0.0298193  0.0243554 ]\n",
      "   [0.03724734 0.02546247 0.02028427]]]\n",
      "\n",
      "\n",
      " [[[0.0447468  0.05185344 0.03978287]\n",
      "   [0.0447468  0.05185344 0.03978287]\n",
      "   [0.04460396 0.05153203 0.03921149]\n",
      "   ...\n",
      "   [0.06235269 0.07213771 0.11113492]\n",
      "   [0.06260267 0.07199486 0.11070638]\n",
      "   [0.06335261 0.07249482 0.11109921]]\n",
      "\n",
      "  [[0.0447468  0.05185344 0.03978287]\n",
      "   [0.0447468  0.05185344 0.03978287]\n",
      "   [0.04460396 0.05153203 0.03921149]\n",
      "   ...\n",
      "   [0.06235269 0.07213771 0.11113492]\n",
      "   [0.06260267 0.07199486 0.11070638]\n",
      "   [0.06335261 0.07249482 0.11109921]]\n",
      "\n",
      "  [[0.04410399 0.05099636 0.03910435]\n",
      "   [0.04410399 0.05099636 0.03910435]\n",
      "   [0.04446111 0.05103207 0.03885437]\n",
      "   ...\n",
      "   [0.06256696 0.0727448  0.11152775]\n",
      "   [0.0633169  0.0727448  0.11131348]\n",
      "   [0.06249554 0.07199486 0.11084922]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05053211 0.05421041 0.08110135]\n",
      "   [0.05053211 0.05421041 0.08110135]\n",
      "   [0.0514249  0.05567459 0.08099421]\n",
      "   ...\n",
      "   [0.04938933 0.05088922 0.07053068]\n",
      "   [0.04949646 0.05131776 0.0715306 ]\n",
      "   [0.04856796 0.0514249  0.07092351]]\n",
      "\n",
      "  [[0.05053211 0.05467467 0.08120848]\n",
      "   [0.05053211 0.05467467 0.08120848]\n",
      "   [0.05078209 0.05467467 0.08099421]\n",
      "   ...\n",
      "   [0.04931791 0.05092493 0.07038783]\n",
      "   [0.04956789 0.05096065 0.07128062]\n",
      "   [0.04992501 0.052032   0.07160203]]\n",
      "\n",
      "  [[0.05046068 0.05435326 0.08045854]\n",
      "   [0.05046068 0.05435326 0.08045854]\n",
      "   [0.05024641 0.05403186 0.08042283]\n",
      "   ...\n",
      "   [0.04938933 0.05121063 0.07010213]\n",
      "   [0.04917506 0.05074637 0.07006642]\n",
      "   [0.04978216 0.05185344 0.07024498]]]\n",
      "\n",
      "\n",
      " [[[0.03128348 0.0337833  0.01921291]\n",
      "   [0.03128348 0.0337833  0.01921291]\n",
      "   [0.0313549  0.03417613 0.01928434]\n",
      "   ...\n",
      "   [0.03139061 0.03331905 0.01846297]\n",
      "   [0.03099779 0.03131919 0.02060567]\n",
      "   [0.03146204 0.03067638 0.02049854]]\n",
      "\n",
      "  [[0.03128348 0.0337833  0.01921291]\n",
      "   [0.03128348 0.0337833  0.01921291]\n",
      "   [0.0313549  0.03417613 0.01928434]\n",
      "   ...\n",
      "   [0.03139061 0.03331905 0.01846297]\n",
      "   [0.03099779 0.03131919 0.02060567]\n",
      "   [0.03146204 0.03067638 0.02049854]]\n",
      "\n",
      "  [[0.03089065 0.03278337 0.01896293]\n",
      "   [0.03089065 0.03278337 0.01896293]\n",
      "   [0.03114063 0.03349761 0.01949861]\n",
      "   ...\n",
      "   [0.03121206 0.0304264  0.01742733]\n",
      "   [0.03006928 0.02717663 0.01757017]\n",
      "   [0.03214056 0.03146204 0.02153418]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03735447 0.03628312 0.03810442]\n",
      "   [0.03735447 0.03628312 0.03810442]\n",
      "   [0.04149704 0.04499679 0.05313906]\n",
      "   ...\n",
      "   [0.03206914 0.03214056 0.02264124]\n",
      "   [0.03210485 0.03181916 0.02181987]\n",
      "   [0.03178344 0.03174773 0.02167702]]\n",
      "\n",
      "  [[0.0325691  0.03174773 0.02781944]\n",
      "   [0.0325691  0.03174773 0.02781944]\n",
      "   [0.03906864 0.03839011 0.03942576]\n",
      "   ...\n",
      "   [0.03210485 0.0325691  0.02178416]\n",
      "   [0.03228341 0.03192629 0.02246268]\n",
      "   [0.03171202 0.03242626 0.02235555]]\n",
      "\n",
      "  [[0.04585387 0.04724662 0.0547818 ]\n",
      "   [0.04585387 0.04724662 0.0547818 ]\n",
      "   [0.04756803 0.04992501 0.06263838]\n",
      "   ...\n",
      "   [0.03189058 0.031962   0.02199843]\n",
      "   [0.03178344 0.03174773 0.02210556]\n",
      "   [0.03174773 0.03203342 0.02174845]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.03371188 0.03242626 0.02553389]\n",
      "   [0.03371188 0.03242626 0.02553389]\n",
      "   [0.0328548  0.03246197 0.02517677]\n",
      "   ...\n",
      "   [0.0331762  0.03264052 0.0252482 ]\n",
      "   [0.03214056 0.0316406  0.024034  ]\n",
      "   [0.03149775 0.02881937 0.02171274]]\n",
      "\n",
      "  [[0.03371188 0.03242626 0.02553389]\n",
      "   [0.03371188 0.03242626 0.02553389]\n",
      "   [0.0328548  0.03246197 0.02517677]\n",
      "   ...\n",
      "   [0.0331762  0.03264052 0.0252482 ]\n",
      "   [0.03214056 0.0316406  0.024034  ]\n",
      "   [0.03149775 0.02881937 0.02171274]]\n",
      "\n",
      "  [[0.03353332 0.03235483 0.0258553 ]\n",
      "   [0.03353332 0.03235483 0.0258553 ]\n",
      "   [0.03228341 0.03167631 0.02456967]\n",
      "   ...\n",
      "   [0.03253339 0.03117635 0.02428398]\n",
      "   [0.0313549  0.02960503 0.02285551]\n",
      "   [0.02946218 0.02706949 0.02049854]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03585458 0.0362117  0.03292622]\n",
      "   [0.03585458 0.0362117  0.03292622]\n",
      "   [0.03714021 0.03685451 0.0349975 ]\n",
      "   ...\n",
      "   [0.03160489 0.03249768 0.02196272]\n",
      "   [0.03178344 0.0316406  0.02239126]\n",
      "   [0.03149775 0.03185487 0.02249839]]\n",
      "\n",
      "  [[0.03453325 0.03460467 0.03160489]\n",
      "   [0.03453325 0.03460467 0.03160489]\n",
      "   [0.03596172 0.03528319 0.03346189]\n",
      "   ...\n",
      "   [0.03199771 0.03281908 0.02324834]\n",
      "   [0.03228341 0.03267624 0.02381973]\n",
      "   [0.03235483 0.03249768 0.02514106]]\n",
      "\n",
      "  [[0.03331905 0.03306907 0.02996214]\n",
      "   [0.03331905 0.03306907 0.02996214]\n",
      "   [0.03514035 0.03467609 0.03081923]\n",
      "   ...\n",
      "   [0.03206914 0.03289051 0.02242697]\n",
      "   [0.03206914 0.03253339 0.02349832]\n",
      "   [0.03167631 0.03206914 0.0237483 ]]]\n",
      "\n",
      "\n",
      " [[[0.03724734 0.03471181 0.0304264 ]\n",
      "   [0.03724734 0.03471181 0.0304264 ]\n",
      "   [0.04271124 0.04356832 0.04785372]\n",
      "   ...\n",
      "   [0.03792586 0.03767588 0.02699807]\n",
      "   [0.03753303 0.03781873 0.02728377]\n",
      "   [0.03796157 0.03760446 0.02753375]]\n",
      "\n",
      "  [[0.03724734 0.03471181 0.0304264 ]\n",
      "   [0.03724734 0.03471181 0.0304264 ]\n",
      "   [0.04271124 0.04356832 0.04785372]\n",
      "   ...\n",
      "   [0.03792586 0.03767588 0.02699807]\n",
      "   [0.03753303 0.03781873 0.02728377]\n",
      "   [0.03796157 0.03760446 0.02753375]]\n",
      "\n",
      "  [[0.03514035 0.03085494 0.02278409]\n",
      "   [0.03514035 0.03085494 0.02278409]\n",
      "   [0.03571174 0.03246197 0.02706949]\n",
      "   ...\n",
      "   [0.03771159 0.03764017 0.02685522]\n",
      "   [0.03739019 0.03746161 0.02717663]\n",
      "   [0.03771159 0.03739019 0.0276766 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04781801 0.04788944 0.05571031]\n",
      "   [0.04781801 0.04788944 0.05571031]\n",
      "   [0.04674666 0.04824656 0.05281766]\n",
      "   ...\n",
      "   [0.05188915 0.05560317 0.07299478]\n",
      "   [0.05185344 0.05453182 0.0742447 ]\n",
      "   [0.05246054 0.05560317 0.07431612]]\n",
      "\n",
      "  [[0.04728234 0.04803228 0.05592458]\n",
      "   [0.04728234 0.04803228 0.05592458]\n",
      "   [0.04728234 0.04831798 0.05331762]\n",
      "   ...\n",
      "   [0.05338904 0.05713877 0.07656596]\n",
      "   [0.05428184 0.05817442 0.07835155]\n",
      "   [0.05413899 0.05706735 0.07574459]]\n",
      "\n",
      "  [[0.04760374 0.04888937 0.05892436]\n",
      "   [0.04760374 0.04888937 0.05892436]\n",
      "   [0.04688951 0.0477823  0.05449611]\n",
      "   ...\n",
      "   [0.05442468 0.05796015 0.07688736]\n",
      "   [0.05363902 0.05788872 0.07585172]\n",
      "   [0.05306764 0.05656739 0.07506607]]]\n",
      "\n",
      "\n",
      " [[[0.0483894  0.0465681  0.04853225]\n",
      "   [0.0483894  0.0465681  0.04853225]\n",
      "   [0.04860367 0.04760374 0.04996072]\n",
      "   ...\n",
      "   [0.06910221 0.07495893 0.08170845]\n",
      "   [0.06885222 0.0757803  0.08452968]\n",
      "   [0.06535248 0.06874509 0.07724448]]\n",
      "\n",
      "  [[0.0483894  0.0465681  0.04853225]\n",
      "   [0.0483894  0.0465681  0.04853225]\n",
      "   [0.04860367 0.04760374 0.04996072]\n",
      "   ...\n",
      "   [0.06910221 0.07495893 0.08170845]\n",
      "   [0.06885222 0.0757803  0.08452968]\n",
      "   [0.06535248 0.06874509 0.07724448]]\n",
      "\n",
      "  [[0.04613956 0.04485394 0.0450325 ]\n",
      "   [0.04613956 0.04485394 0.0450325 ]\n",
      "   [0.04603243 0.04510392 0.04574673]\n",
      "   ...\n",
      "   [0.06503107 0.06935219 0.07920863]\n",
      "   [0.06678095 0.06870938 0.07917292]\n",
      "   [0.0614599  0.06463824 0.07220913]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05188915 0.05221056 0.0578173 ]\n",
      "   [0.05188915 0.05221056 0.0578173 ]\n",
      "   [0.05031784 0.04996072 0.0544604 ]\n",
      "   ...\n",
      "   [0.06256696 0.06881651 0.08617242]\n",
      "   [0.08706521 0.08599386 0.09806442]\n",
      "   [0.09370759 0.09913578 0.1031712 ]]\n",
      "\n",
      "  [[0.05138919 0.05106778 0.05799586]\n",
      "   [0.05138919 0.05106778 0.05799586]\n",
      "   [0.05253196 0.05117492 0.05692451]\n",
      "   ...\n",
      "   [0.06956646 0.07260196 0.08860081]\n",
      "   [0.07331619 0.07960146 0.08356546]\n",
      "   [0.07231627 0.07749446 0.09317192]]\n",
      "\n",
      "  [[0.05410328 0.05724591 0.06728091]\n",
      "   [0.05410328 0.05724591 0.06728091]\n",
      "   [0.05956717 0.05931719 0.06806657]\n",
      "   ...\n",
      "   [0.06456681 0.07017356 0.0846011 ]\n",
      "   [0.06385258 0.06649525 0.07110207]\n",
      "   [0.06406685 0.06803086 0.07513749]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.09456468 0.09635026 0.11531319]\n",
      "   [0.09456468 0.09635026 0.11531319]\n",
      "   [0.07588743 0.07953003 0.09285051]\n",
      "   ...\n",
      "   [0.05313906 0.05192486 0.0642097 ]\n",
      "   [0.05042497 0.05038926 0.05713877]\n",
      "   [0.04413971 0.04431826 0.0471752 ]]\n",
      "\n",
      "  [[0.09456468 0.09635026 0.11531319]\n",
      "   [0.09456468 0.09635026 0.11531319]\n",
      "   [0.07588743 0.07953003 0.09285051]\n",
      "   ...\n",
      "   [0.05313906 0.05192486 0.0642097 ]\n",
      "   [0.05042497 0.05038926 0.05713877]\n",
      "   [0.04413971 0.04431826 0.0471752 ]]\n",
      "\n",
      "  [[0.08181559 0.08374402 0.09995715]\n",
      "   [0.08181559 0.08374402 0.09995715]\n",
      "   [0.06217413 0.06670952 0.07195915]\n",
      "   ...\n",
      "   [0.04488965 0.04288979 0.04610385]\n",
      "   [0.04413971 0.04228269 0.0450325 ]\n",
      "   [0.04013999 0.03503321 0.03506893]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06442397 0.06078137 0.066031  ]\n",
      "   [0.06442397 0.06078137 0.066031  ]\n",
      "   [0.05578173 0.05231769 0.05342476]\n",
      "   ...\n",
      "   [0.04749661 0.04585387 0.04928219]\n",
      "   [0.04910364 0.04771088 0.05199629]\n",
      "   [0.04510392 0.04292551 0.04485394]]\n",
      "\n",
      "  [[0.05821013 0.05849582 0.0626741 ]\n",
      "   [0.05821013 0.05849582 0.0626741 ]\n",
      "   [0.04892508 0.04646097 0.05060353]\n",
      "   ...\n",
      "   [0.04781801 0.04213985 0.04546104]\n",
      "   [0.04374687 0.04053282 0.04560389]\n",
      "   [0.04203271 0.03764017 0.04053282]]\n",
      "\n",
      "  [[0.05488894 0.05363902 0.05928148]\n",
      "   [0.05488894 0.05363902 0.05928148]\n",
      "   [0.04296122 0.03699736 0.04274695]\n",
      "   ...\n",
      "   [0.04178273 0.03478323 0.03471181]\n",
      "   [0.04235412 0.03642597 0.04049711]\n",
      "   [0.03989001 0.038033   0.03996143]]]\n",
      "\n",
      "\n",
      " [[[0.0276766  0.02967645 0.01374902]\n",
      "   [0.0276766  0.02967645 0.01374902]\n",
      "   [0.02789086 0.03017642 0.01424898]\n",
      "   ...\n",
      "   [0.02489108 0.01907007 0.01042783]\n",
      "   [0.02453396 0.01699879 0.00982073]\n",
      "   [0.0243554  0.01842725 0.01067781]]\n",
      "\n",
      "  [[0.0276766  0.02967645 0.01374902]\n",
      "   [0.0276766  0.02967645 0.01374902]\n",
      "   [0.02789086 0.03017642 0.01424898]\n",
      "   ...\n",
      "   [0.02489108 0.01907007 0.01042783]\n",
      "   [0.02453396 0.01699879 0.00982073]\n",
      "   [0.0243554  0.01842725 0.01067781]]\n",
      "\n",
      "  [[0.02774802 0.02974788 0.01364188]\n",
      "   [0.02774802 0.02974788 0.01364188]\n",
      "   [0.02785515 0.02992643 0.01403471]\n",
      "   ...\n",
      "   [0.02392686 0.01671309 0.00996357]\n",
      "   [0.02531962 0.0188558  0.01092779]\n",
      "   [0.02631955 0.02242697 0.01264195]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02828369 0.03024784 0.01357046]\n",
      "   [0.02828369 0.03024784 0.01357046]\n",
      "   [0.027998   0.02999786 0.01335619]\n",
      "   ...\n",
      "   [0.04478252 0.04331833 0.04631812]\n",
      "   [0.03910435 0.03660453 0.03521177]\n",
      "   [0.03839011 0.03303336 0.03142633]]\n",
      "\n",
      "  [[0.02821227 0.02996214 0.0133919 ]\n",
      "   [0.02821227 0.02996214 0.0133919 ]\n",
      "   [0.02831941 0.0298193  0.01349904]\n",
      "   ...\n",
      "   [0.04435397 0.04099707 0.04192558]\n",
      "   [0.04249696 0.03785444 0.03767588]\n",
      "   [0.0392472  0.03678309 0.03524748]]\n",
      "\n",
      "  [[0.02749804 0.02989072 0.01307049]\n",
      "   [0.02749804 0.02989072 0.01307049]\n",
      "   [0.0276766  0.02967645 0.01346332]\n",
      "   ...\n",
      "   [0.04478252 0.04403257 0.04560389]\n",
      "   [0.04328262 0.04113992 0.04146132]\n",
      "   [0.04142561 0.03689022 0.03735447]]]\n",
      "\n",
      "\n",
      " [[[0.04496107 0.04349689 0.04988929]\n",
      "   [0.04496107 0.04349689 0.04988929]\n",
      "   [0.04588958 0.04428255 0.05135347]\n",
      "   ...\n",
      "   [0.03114063 0.0267838  0.02078423]\n",
      "   [0.03021213 0.02503393 0.01767731]\n",
      "   [0.02971216 0.02610528 0.01842725]]\n",
      "\n",
      "  [[0.04496107 0.04349689 0.04988929]\n",
      "   [0.04496107 0.04349689 0.04988929]\n",
      "   [0.04588958 0.04428255 0.05135347]\n",
      "   ...\n",
      "   [0.03114063 0.0267838  0.02078423]\n",
      "   [0.03021213 0.02503393 0.01767731]\n",
      "   [0.02971216 0.02610528 0.01842725]]\n",
      "\n",
      "  [[0.04492536 0.04342547 0.04949646]\n",
      "   [0.04492536 0.04342547 0.04949646]\n",
      "   [0.04513963 0.04431826 0.04921077]\n",
      "   ...\n",
      "   [0.03035497 0.02596243 0.01907007]\n",
      "   [0.03346189 0.02956932 0.0216056 ]\n",
      "   [0.03617599 0.03331905 0.02778373]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03485465 0.03353332 0.02974788]\n",
      "   [0.03485465 0.03353332 0.02974788]\n",
      "   [0.03689022 0.03564031 0.03292622]\n",
      "   ...\n",
      "   [0.03542604 0.03485465 0.02853368]\n",
      "   [0.03414042 0.03417613 0.0276766 ]\n",
      "   [0.03456896 0.03385472 0.02881937]]\n",
      "\n",
      "  [[0.03460467 0.03367617 0.02917649]\n",
      "   [0.03460467 0.03367617 0.02917649]\n",
      "   [0.03710449 0.03689022 0.03456896]\n",
      "   ...\n",
      "   [0.03506893 0.03510464 0.02999786]\n",
      "   [0.03385472 0.03328334 0.02681951]\n",
      "   [0.03399757 0.03371188 0.02781944]]\n",
      "\n",
      "  [[0.03478323 0.03371188 0.0289265 ]\n",
      "   [0.03478323 0.03371188 0.0289265 ]\n",
      "   [0.03624741 0.03631883 0.03356903]\n",
      "   ...\n",
      "   [0.03685451 0.03596172 0.02996214]\n",
      "   [0.03367617 0.03367617 0.02610528]\n",
      "   [0.03389044 0.03471181 0.02810514]]]], shape=(128, 64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.03396186 0.02781944 0.01664167]\n",
      "   [0.03396186 0.02781944 0.01664167]\n",
      "   [0.03456896 0.02549818 0.01549889]\n",
      "   ...\n",
      "   [0.0368188  0.02974788 0.02146275]\n",
      "   [0.03817584 0.03067638 0.02410542]\n",
      "   [0.03906864 0.03178344 0.02421256]]\n",
      "\n",
      "  [[0.03396186 0.02781944 0.01664167]\n",
      "   [0.03396186 0.02781944 0.01664167]\n",
      "   [0.03456896 0.02549818 0.01549889]\n",
      "   ...\n",
      "   [0.0368188  0.02974788 0.02146275]\n",
      "   [0.03817584 0.03067638 0.02410542]\n",
      "   [0.03906864 0.03178344 0.02421256]]\n",
      "\n",
      "  [[0.03406899 0.02699807 0.01696307]\n",
      "   [0.03406899 0.02699807 0.01696307]\n",
      "   [0.0343904  0.0249625  0.01546318]\n",
      "   ...\n",
      "   [0.03974716 0.03503321 0.0261767 ]\n",
      "   [0.0398543  0.03381901 0.03217627]\n",
      "   [0.03899721 0.03167631 0.02471252]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03689022 0.03228341 0.02017713]\n",
      "   [0.03689022 0.03228341 0.02017713]\n",
      "   [0.03910435 0.03349761 0.02485537]\n",
      "   ...\n",
      "   [0.03703307 0.03331905 0.02074852]\n",
      "   [0.03914006 0.03714021 0.02439111]\n",
      "   [0.03785444 0.03446182 0.02228412]]\n",
      "\n",
      "  [[0.03867581 0.03367617 0.02246268]\n",
      "   [0.03867581 0.03367617 0.02246268]\n",
      "   [0.04185415 0.03567602 0.03296193]\n",
      "   ...\n",
      "   [0.03981858 0.03810442 0.02521249]\n",
      "   [0.03849725 0.0356046  0.02421256]\n",
      "   [0.0368188  0.03171202 0.02106992]]\n",
      "\n",
      "  [[0.03696164 0.03421184 0.02156989]\n",
      "   [0.03696164 0.03421184 0.02156989]\n",
      "   [0.03892579 0.03485465 0.0255696 ]\n",
      "   ...\n",
      "   [0.03999714 0.03796157 0.02828369]\n",
      "   [0.03821156 0.03506893 0.02371259]\n",
      "   [0.03871152 0.03410471 0.0225341 ]]]\n",
      "\n",
      "\n",
      " [[[0.04421113 0.04360403 0.02631955]\n",
      "   [0.04421113 0.04360403 0.02631955]\n",
      "   [0.04417542 0.04288979 0.02639097]\n",
      "   ...\n",
      "   [0.04235412 0.04167559 0.02424827]\n",
      "   [0.04238983 0.04213985 0.02442683]\n",
      "   [0.04288979 0.04213985 0.02489108]]\n",
      "\n",
      "  [[0.04421113 0.04360403 0.02631955]\n",
      "   [0.04421113 0.04360403 0.02631955]\n",
      "   [0.04417542 0.04288979 0.02639097]\n",
      "   ...\n",
      "   [0.04235412 0.04167559 0.02424827]\n",
      "   [0.04238983 0.04213985 0.02442683]\n",
      "   [0.04288979 0.04213985 0.02489108]]\n",
      "\n",
      "  [[0.04413971 0.04346118 0.02646239]\n",
      "   [0.04413971 0.04346118 0.02646239]\n",
      "   [0.04338976 0.04331833 0.02628384]\n",
      "   ...\n",
      "   [0.04203271 0.04156846 0.024034  ]\n",
      "   [0.0426041  0.04178273 0.02442683]\n",
      "   [0.04310406 0.04178273 0.02471252]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04299693 0.04203271 0.02460539]\n",
      "   [0.04299693 0.04203271 0.02460539]\n",
      "   [0.04296122 0.04196129 0.0249625 ]\n",
      "   ...\n",
      "   [0.04178273 0.03996143 0.02346261]\n",
      "   [0.04206842 0.04056853 0.02321263]\n",
      "   [0.04153275 0.04117563 0.02456967]]\n",
      "\n",
      "  [[0.04299693 0.04299693 0.02553389]\n",
      "   [0.04299693 0.04299693 0.02553389]\n",
      "   [0.04263981 0.04235412 0.02503393]\n",
      "   ...\n",
      "   [0.04217556 0.0413899  0.02414113]\n",
      "   [0.0432112  0.04160417 0.02439111]\n",
      "   [0.04335405 0.04217556 0.02546247]]\n",
      "\n",
      "  [[0.04363974 0.0438183  0.02535533]\n",
      "   [0.04363974 0.0438183  0.02535533]\n",
      "   [0.04285408 0.04242554 0.0249625 ]\n",
      "   ...\n",
      "   [0.04256839 0.04235412 0.0249625 ]\n",
      "   [0.04356832 0.04253267 0.02514106]\n",
      "   [0.04392543 0.04285408 0.02546247]]]\n",
      "\n",
      "\n",
      " [[[0.02956932 0.02656953 0.01532033]\n",
      "   [0.02956932 0.02656953 0.01532033]\n",
      "   [0.02967645 0.02728377 0.01567745]\n",
      "   ...\n",
      "   [0.03114063 0.03028355 0.02014142]\n",
      "   [0.03178344 0.0310335  0.02139133]\n",
      "   [0.03217627 0.03067638 0.02246268]]\n",
      "\n",
      "  [[0.02956932 0.02656953 0.01532033]\n",
      "   [0.02956932 0.02656953 0.01532033]\n",
      "   [0.02967645 0.02728377 0.01567745]\n",
      "   ...\n",
      "   [0.03114063 0.03028355 0.02014142]\n",
      "   [0.03178344 0.0310335  0.02139133]\n",
      "   [0.03217627 0.03067638 0.02246268]]\n",
      "\n",
      "  [[0.02856939 0.02560531 0.01546318]\n",
      "   [0.02856939 0.02560531 0.01546318]\n",
      "   [0.03010499 0.02642668 0.01528462]\n",
      "   ...\n",
      "   [0.02967645 0.0276766  0.01749875]\n",
      "   [0.03060496 0.02917649 0.01928434]\n",
      "   [0.0322477  0.03056924 0.02224841]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03071209 0.02514106 0.01814156]\n",
      "   [0.03071209 0.02514106 0.01814156]\n",
      "   [0.03131919 0.02549818 0.02042711]\n",
      "   ...\n",
      "   [0.02760517 0.02128419 0.01378473]\n",
      "   [0.02774802 0.02060567 0.01242768]\n",
      "   [0.02796229 0.0222127  0.01328477]]\n",
      "\n",
      "  [[0.02917649 0.02317692 0.01489179]\n",
      "   [0.02917649 0.02317692 0.01489179]\n",
      "   [0.03028355 0.02514106 0.01924863]\n",
      "   ...\n",
      "   [0.02731948 0.01982001 0.01232055]\n",
      "   [0.02714092 0.01974859 0.01171345]\n",
      "   [0.02764088 0.02121277 0.01242768]]\n",
      "\n",
      "  [[0.02778373 0.02149846 0.01410613]\n",
      "   [0.02778373 0.02149846 0.01410613]\n",
      "   [0.02989072 0.02428398 0.01753446]\n",
      "   ...\n",
      "   [0.02635526 0.01921291 0.0118563 ]\n",
      "   [0.02753375 0.02053425 0.01207057]\n",
      "   [0.02760517 0.02071281 0.01232055]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.04906792 0.05103207 0.07410185]\n",
      "   [0.04906792 0.05103207 0.07410185]\n",
      "   [0.04871081 0.05099636 0.07506607]\n",
      "   ...\n",
      "   [0.0657453  0.07320905 0.10402828]\n",
      "   [0.06738804 0.07742304 0.10856368]\n",
      "   [0.06731662 0.07595886 0.10731376]]\n",
      "\n",
      "  [[0.04906792 0.05103207 0.07410185]\n",
      "   [0.04906792 0.05103207 0.07410185]\n",
      "   [0.04871081 0.05099636 0.07506607]\n",
      "   ...\n",
      "   [0.0657453  0.07320905 0.10402828]\n",
      "   [0.06738804 0.07742304 0.10856368]\n",
      "   [0.06731662 0.07595886 0.10731376]]\n",
      "\n",
      "  [[0.04885365 0.05156774 0.07513749]\n",
      "   [0.04885365 0.05156774 0.07513749]\n",
      "   [0.04906792 0.05160346 0.07553032]\n",
      "   ...\n",
      "   [0.06760231 0.07653025 0.1077423 ]\n",
      "   [0.0669595  0.07585172 0.10688522]\n",
      "   [0.06592386 0.07528034 0.10338547]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05160346 0.05467467 0.08027998]\n",
      "   [0.05160346 0.05467467 0.08027998]\n",
      "   [0.05149632 0.05438897 0.07917292]\n",
      "   ...\n",
      "   [0.05178202 0.05396043 0.07574459]\n",
      "   [0.05185344 0.05403186 0.07620884]\n",
      "   [0.05178202 0.05474609 0.07670881]]\n",
      "\n",
      "  [[0.05099636 0.05485322 0.07988715]\n",
      "   [0.05099636 0.05485322 0.07988715]\n",
      "   [0.05092493 0.05399614 0.07913721]\n",
      "   ...\n",
      "   [0.05121063 0.05371045 0.07595886]\n",
      "   [0.05181773 0.05378187 0.07628027]\n",
      "   [0.05181773 0.05438897 0.07720877]]\n",
      "\n",
      "  [[0.05124634 0.05435326 0.07963717]\n",
      "   [0.05124634 0.05435326 0.07963717]\n",
      "   [0.05099636 0.05413899 0.07917292]\n",
      "   ...\n",
      "   [0.05153203 0.05338904 0.07620884]\n",
      "   [0.05156774 0.05338904 0.07574459]\n",
      "   [0.05156774 0.05317477 0.07531605]]]\n",
      "\n",
      "\n",
      " [[[0.03674737 0.0298193  0.02389115]\n",
      "   [0.03674737 0.0298193  0.02389115]\n",
      "   [0.03474752 0.0304264  0.02189129]\n",
      "   ...\n",
      "   [0.03931862 0.03596172 0.02746232]\n",
      "   [0.04928219 0.04471109 0.04024712]\n",
      "   [0.04703236 0.0447468  0.03614027]]\n",
      "\n",
      "  [[0.03674737 0.0298193  0.02389115]\n",
      "   [0.03674737 0.0298193  0.02389115]\n",
      "   [0.03474752 0.0304264  0.02189129]\n",
      "   ...\n",
      "   [0.03931862 0.03596172 0.02746232]\n",
      "   [0.04928219 0.04471109 0.04024712]\n",
      "   [0.04703236 0.0447468  0.03614027]]\n",
      "\n",
      "  [[0.03514035 0.03214056 0.02353403]\n",
      "   [0.03514035 0.03214056 0.02353403]\n",
      "   [0.03435469 0.03096207 0.02060567]\n",
      "   ...\n",
      "   [0.04603243 0.03931862 0.03478323]\n",
      "   [0.04749661 0.04349689 0.03635455]\n",
      "   [0.04603243 0.04846082 0.03428327]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03121206 0.02285551 0.01649882]\n",
      "   [0.03121206 0.02285551 0.01649882]\n",
      "   [0.03049782 0.02274838 0.01524891]\n",
      "   ...\n",
      "   [0.03699736 0.03564031 0.02856939]\n",
      "   [0.04549675 0.04513963 0.0392472 ]\n",
      "   [0.04921077 0.04424684 0.04449682]]\n",
      "\n",
      "  [[0.0301407  0.02339119 0.0158203 ]\n",
      "   [0.0301407  0.02339119 0.0158203 ]\n",
      "   [0.0301407  0.02385544 0.0161417 ]\n",
      "   ...\n",
      "   [0.03410471 0.0316406  0.021927  ]\n",
      "   [0.04203271 0.03814013 0.03321191]\n",
      "   [0.04828227 0.04167559 0.04206842]]\n",
      "\n",
      "  [[0.03035497 0.02489108 0.01532033]\n",
      "   [0.03035497 0.02489108 0.01532033]\n",
      "   [0.02949789 0.02306978 0.0152132 ]\n",
      "   ...\n",
      "   [0.03339047 0.02939076 0.01996286]\n",
      "   [0.03785444 0.03517606 0.02856939]\n",
      "   [0.04631812 0.04106849 0.03781873]]]\n",
      "\n",
      "\n",
      " [[[0.04371116 0.04099707 0.04367545]\n",
      "   [0.04371116 0.04099707 0.04367545]\n",
      "   [0.04435397 0.04071138 0.04560389]\n",
      "   ...\n",
      "   [0.06438826 0.05688879 0.06778087]\n",
      "   [0.06820942 0.07149489 0.07785158]\n",
      "   [0.05717449 0.05596029 0.07531605]]\n",
      "\n",
      "  [[0.04371116 0.04099707 0.04367545]\n",
      "   [0.04371116 0.04099707 0.04367545]\n",
      "   [0.04435397 0.04071138 0.04560389]\n",
      "   ...\n",
      "   [0.06438826 0.05688879 0.06778087]\n",
      "   [0.06820942 0.07149489 0.07785158]\n",
      "   [0.05717449 0.05596029 0.07531605]]\n",
      "\n",
      "  [[0.06270981 0.06549532 0.06945933]\n",
      "   [0.06270981 0.06549532 0.06945933]\n",
      "   [0.0514249  0.05067495 0.05510321]\n",
      "   ...\n",
      "   [0.05949575 0.05806728 0.06506678]\n",
      "   [0.06003143 0.06138847 0.07110207]\n",
      "   [0.05010356 0.04971074 0.06899507]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04317549 0.0468538  0.06320977]\n",
      "   [0.04317549 0.0468538  0.06320977]\n",
      "   [0.06195986 0.05471038 0.0794229 ]\n",
      "   ...\n",
      "   [0.05360331 0.0535676  0.05860296]\n",
      "   [0.05267481 0.04788944 0.05535319]\n",
      "   [0.05206771 0.05167488 0.05510321]]\n",
      "\n",
      "  [[0.04671095 0.04813942 0.06349546]\n",
      "   [0.04671095 0.04813942 0.06349546]\n",
      "   [0.05046068 0.04971074 0.07313763]\n",
      "   ...\n",
      "   [0.06206699 0.05738876 0.07388758]\n",
      "   [0.07320905 0.06592386 0.07581601]\n",
      "   [0.06538819 0.05931719 0.06285265]]\n",
      "\n",
      "  [[0.045961   0.04524677 0.06192415]\n",
      "   [0.045961   0.04524677 0.06192415]\n",
      "   [0.04581816 0.045961   0.06256696]\n",
      "   ...\n",
      "   [0.07556603 0.06531677 0.08445825]\n",
      "   [0.07874437 0.09970716 0.08952932]\n",
      "   [0.07406614 0.0782087  0.08670809]]]], shape=(128, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.03446182 0.03078352 0.03453325]\n",
      "   [0.03446182 0.03078352 0.03453325]\n",
      "   [0.03417613 0.0304264  0.03314049]\n",
      "   ...\n",
      "   [0.04013999 0.04192558 0.04278266]\n",
      "   [0.04160417 0.04303264 0.04567531]\n",
      "   [0.04110421 0.04242554 0.04721091]]\n",
      "\n",
      "  [[0.03446182 0.03078352 0.03453325]\n",
      "   [0.03446182 0.03078352 0.03453325]\n",
      "   [0.03417613 0.0304264  0.03314049]\n",
      "   ...\n",
      "   [0.04013999 0.04192558 0.04278266]\n",
      "   [0.04160417 0.04303264 0.04567531]\n",
      "   [0.04110421 0.04242554 0.04721091]]\n",
      "\n",
      "  [[0.03471181 0.03085494 0.03514035]\n",
      "   [0.03471181 0.03085494 0.03514035]\n",
      "   [0.03478323 0.03039069 0.03453325]\n",
      "   ...\n",
      "   [0.03910435 0.04013999 0.04246125]\n",
      "   [0.04013999 0.04013999 0.04342547]\n",
      "   [0.0389615  0.03871152 0.04488965]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03324762 0.02903364 0.02960503]\n",
      "   [0.03324762 0.02903364 0.02960503]\n",
      "   [0.03403328 0.02903364 0.03003357]\n",
      "   ...\n",
      "   [0.03606885 0.03306907 0.03703307]\n",
      "   [0.03646168 0.03356903 0.038033  ]\n",
      "   [0.03717592 0.03449754 0.03842583]]\n",
      "\n",
      "  [[0.03324762 0.02846225 0.02931933]\n",
      "   [0.03324762 0.02846225 0.02931933]\n",
      "   [0.03296193 0.02821227 0.0292122 ]\n",
      "   ...\n",
      "   [0.03546175 0.03239054 0.03496179]\n",
      "   [0.03649739 0.03478323 0.03939004]\n",
      "   [0.04049711 0.03789015 0.04167559]]\n",
      "\n",
      "  [[0.03342618 0.02931933 0.0313549 ]\n",
      "   [0.03342618 0.02931933 0.0313549 ]\n",
      "   [0.03406899 0.02881937 0.03171202]\n",
      "   ...\n",
      "   [0.03478323 0.03110492 0.03410471]\n",
      "   [0.03474752 0.03271195 0.03596172]\n",
      "   [0.03646168 0.03449754 0.03749732]]]\n",
      "\n",
      "\n",
      " [[[0.03871152 0.03346189 0.02885508]\n",
      "   [0.03871152 0.03346189 0.02885508]\n",
      "   [0.03571174 0.03321191 0.02603385]\n",
      "   ...\n",
      "   [0.03860439 0.03503321 0.02896222]\n",
      "   [0.03574745 0.03121206 0.02717663]\n",
      "   [0.03374759 0.03060496 0.02278409]]\n",
      "\n",
      "  [[0.03871152 0.03346189 0.02885508]\n",
      "   [0.03871152 0.03346189 0.02885508]\n",
      "   [0.03571174 0.03321191 0.02603385]\n",
      "   ...\n",
      "   [0.03860439 0.03503321 0.02896222]\n",
      "   [0.03574745 0.03121206 0.02717663]\n",
      "   [0.03374759 0.03060496 0.02278409]]\n",
      "\n",
      "  [[0.03617599 0.03274766 0.02789086]\n",
      "   [0.03617599 0.03274766 0.02789086]\n",
      "   [0.03799729 0.03589029 0.0304264 ]\n",
      "   ...\n",
      "   [0.03324762 0.03046211 0.02542675]\n",
      "   [0.0328548  0.02753375 0.0234269 ]\n",
      "   [0.03517606 0.03028355 0.02674809]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03767588 0.03371188 0.02917649]\n",
      "   [0.03767588 0.03371188 0.02917649]\n",
      "   [0.03849725 0.03467609 0.03867581]\n",
      "   ...\n",
      "   [0.03110492 0.03024784 0.01846297]\n",
      "   [0.0328548  0.02992643 0.02181987]\n",
      "   [0.03531891 0.03035497 0.02681951]]\n",
      "\n",
      "  [[0.04342547 0.03839011 0.03756874]\n",
      "   [0.04342547 0.03839011 0.03756874]\n",
      "   [0.0401757  0.03503321 0.03781873]\n",
      "   ...\n",
      "   [0.0325691  0.03171202 0.02021284]\n",
      "   [0.03356903 0.03021213 0.02171274]\n",
      "   [0.03539033 0.0328548  0.02546247]]\n",
      "\n",
      "  [[0.04581816 0.03860439 0.04149704]\n",
      "   [0.04581816 0.03860439 0.04149704]\n",
      "   [0.04046139 0.03567602 0.03492608]\n",
      "   ...\n",
      "   [0.03367617 0.02989072 0.02485537]\n",
      "   [0.03324762 0.02931933 0.02292693]\n",
      "   [0.03271195 0.0301407  0.02114135]]]\n",
      "\n",
      "\n",
      " [[[0.05438897 0.05792443 0.08524391]\n",
      "   [0.05438897 0.05792443 0.08524391]\n",
      "   [0.05396043 0.05692451 0.08167274]\n",
      "   ...\n",
      "   [0.05985287 0.06842368 0.10542104]\n",
      "   [0.05985287 0.06960217 0.10509963]\n",
      "   [0.06245982 0.07142347 0.10809942]]\n",
      "\n",
      "  [[0.05438897 0.05792443 0.08524391]\n",
      "   [0.05438897 0.05792443 0.08524391]\n",
      "   [0.05396043 0.05692451 0.08167274]\n",
      "   ...\n",
      "   [0.05985287 0.06842368 0.10542104]\n",
      "   [0.05985287 0.06960217 0.10509963]\n",
      "   [0.06245982 0.07142347 0.10809942]]\n",
      "\n",
      "  [[0.05556746 0.06067424 0.08827941]\n",
      "   [0.05556746 0.06067424 0.08827941]\n",
      "   [0.05567459 0.05971002 0.08542247]\n",
      "   ...\n",
      "   [0.05981716 0.06838797 0.10517106]\n",
      "   [0.06128134 0.06985215 0.10706378]\n",
      "   [0.06242411 0.07117349 0.10827798]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05053211 0.05321049 0.07167345]\n",
      "   [0.05053211 0.05321049 0.07167345]\n",
      "   [0.05046068 0.0523534  0.07078066]\n",
      "   ...\n",
      "   [0.06438826 0.0733519  0.10945646]\n",
      "   [0.06445968 0.07288765 0.10995643]\n",
      "   [0.06338833 0.07345904 0.11124206]]\n",
      "\n",
      "  [[0.05074637 0.05363902 0.07235198]\n",
      "   [0.05074637 0.05363902 0.07235198]\n",
      "   [0.05078209 0.05246054 0.0706021 ]\n",
      "   ...\n",
      "   [0.06356689 0.07303049 0.10838512]\n",
      "   [0.06317406 0.07145918 0.10781373]\n",
      "   [0.06374545 0.07174487 0.10881366]]\n",
      "\n",
      "  [[0.04988929 0.05206771 0.07024498]\n",
      "   [0.04988929 0.05206771 0.07024498]\n",
      "   [0.05028212 0.05210342 0.07003071]\n",
      "   ...\n",
      "   [0.06917363 0.07781587 0.11313478]\n",
      "   [0.0687808  0.07978001 0.11345618]\n",
      "   [0.06924506 0.07899436 0.11342047]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.0225341  0.01999857 0.01089208]\n",
      "   [0.0225341  0.01999857 0.01089208]\n",
      "   [0.02171274 0.01989144 0.01017784]\n",
      "   ...\n",
      "   [0.02385544 0.02053425 0.0124634 ]\n",
      "   [0.02356975 0.01999857 0.0121777 ]\n",
      "   [0.02378402 0.02053425 0.01242768]]\n",
      "\n",
      "  [[0.0225341  0.01999857 0.01089208]\n",
      "   [0.0225341  0.01999857 0.01089208]\n",
      "   [0.02171274 0.01989144 0.01017784]\n",
      "   ...\n",
      "   [0.02385544 0.02053425 0.0124634 ]\n",
      "   [0.02356975 0.01999857 0.0121777 ]\n",
      "   [0.02378402 0.02053425 0.01242768]]\n",
      "\n",
      "  [[0.02296264 0.02181987 0.01139204]\n",
      "   [0.02296264 0.02181987 0.01139204]\n",
      "   [0.02278409 0.02049854 0.01074923]\n",
      "   ...\n",
      "   [0.02449825 0.02260553 0.01299907]\n",
      "   [0.02442683 0.02274838 0.01321334]\n",
      "   [0.02353403 0.01999857 0.01249911]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02589101 0.02406971 0.01728448]\n",
      "   [0.02589101 0.02406971 0.01728448]\n",
      "   [0.0249625  0.02203414 0.0161417 ]\n",
      "   ...\n",
      "   [0.02292693 0.02164131 0.01196343]\n",
      "   [0.02389115 0.02196272 0.01249911]\n",
      "   [0.02249839 0.01899864 0.01057067]]\n",
      "\n",
      "  [[0.02367688 0.02096279 0.01371331]\n",
      "   [0.02367688 0.02096279 0.01371331]\n",
      "   [0.02381973 0.01957003 0.01353475]\n",
      "   ...\n",
      "   [0.02142704 0.01778444 0.00971359]\n",
      "   [0.02231983 0.02014142 0.01082066]\n",
      "   [0.02206985 0.0197843  0.01099921]]\n",
      "\n",
      "  [[0.02499821 0.02060567 0.01539176]\n",
      "   [0.02499821 0.02060567 0.01539176]\n",
      "   [0.02353403 0.02046282 0.01385615]\n",
      "   ...\n",
      "   [0.02124848 0.01671309 0.00917792]\n",
      "   [0.02214128 0.01935576 0.01024927]\n",
      "   [0.02228412 0.01939147 0.01078494]]]\n",
      "\n",
      "\n",
      " [[[0.03949718 0.03931862 0.03417613]\n",
      "   [0.03949718 0.03931862 0.03417613]\n",
      "   [0.04171131 0.04106849 0.03946147]\n",
      "   ...\n",
      "   [0.04585387 0.03928291 0.03728305]\n",
      "   [0.04521106 0.0374259  0.03910435]\n",
      "   [0.04317549 0.03853296 0.03867581]]\n",
      "\n",
      "  [[0.03949718 0.03931862 0.03417613]\n",
      "   [0.03949718 0.03931862 0.03417613]\n",
      "   [0.04171131 0.04106849 0.03946147]\n",
      "   ...\n",
      "   [0.04585387 0.03928291 0.03728305]\n",
      "   [0.04521106 0.0374259  0.03910435]\n",
      "   [0.04317549 0.03853296 0.03867581]]\n",
      "\n",
      "  [[0.03624741 0.03414042 0.02906935]\n",
      "   [0.03624741 0.03414042 0.02906935]\n",
      "   [0.0362117  0.03353332 0.02999786]\n",
      "   ...\n",
      "   [0.04342547 0.03778302 0.04038997]\n",
      "   [0.04378259 0.04099707 0.03678309]\n",
      "   [0.04524677 0.03853296 0.03696164]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0362117  0.03492608 0.02599814]\n",
      "   [0.0362117  0.03492608 0.02599814]\n",
      "   [0.03331905 0.03110492 0.02185558]\n",
      "   ...\n",
      "   [0.03903292 0.03146204 0.02935505]\n",
      "   [0.03606885 0.03121206 0.0276766 ]\n",
      "   [0.03649739 0.02989072 0.02571245]]\n",
      "\n",
      "  [[0.03678309 0.03485465 0.02624813]\n",
      "   [0.03678309 0.03485465 0.02624813]\n",
      "   [0.03356903 0.0313549  0.02203414]\n",
      "   ...\n",
      "   [0.03917577 0.03346189 0.03064067]\n",
      "   [0.04063996 0.03421184 0.03346189]\n",
      "   [0.03931862 0.03496179 0.03149775]]\n",
      "\n",
      "  [[0.03471181 0.03203342 0.02406971]\n",
      "   [0.03471181 0.03203342 0.02406971]\n",
      "   [0.03281908 0.02949789 0.0216056 ]\n",
      "   ...\n",
      "   [0.03696164 0.03228341 0.02885508]\n",
      "   [0.03842583 0.03321191 0.0304264 ]\n",
      "   [0.03881866 0.03264052 0.03071209]]]\n",
      "\n",
      "\n",
      " [[[0.05303193 0.05146061 0.05421041]\n",
      "   [0.05303193 0.05146061 0.05421041]\n",
      "   [0.05106778 0.04896079 0.05053211]\n",
      "   ...\n",
      "   [0.02949789 0.02867652 0.01867724]\n",
      "   [0.02964074 0.02831941 0.01871295]\n",
      "   [0.02956932 0.02746232 0.01867724]]\n",
      "\n",
      "  [[0.05303193 0.05146061 0.05421041]\n",
      "   [0.05303193 0.05146061 0.05421041]\n",
      "   [0.05106778 0.04896079 0.05053211]\n",
      "   ...\n",
      "   [0.02949789 0.02867652 0.01867724]\n",
      "   [0.02964074 0.02831941 0.01871295]\n",
      "   [0.02956932 0.02746232 0.01867724]]\n",
      "\n",
      "  [[0.05038926 0.04846082 0.05024641]\n",
      "   [0.05038926 0.04846082 0.05024641]\n",
      "   [0.05399614 0.05163917 0.05438897]\n",
      "   ...\n",
      "   [0.02964074 0.02835512 0.01853439]\n",
      "   [0.0295336  0.0273909  0.01803443]\n",
      "   [0.02939076 0.02656953 0.01810585]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03371188 0.03478323 0.02771231]\n",
      "   [0.03371188 0.03478323 0.02771231]\n",
      "   [0.03421184 0.03481894 0.02939076]\n",
      "   ...\n",
      "   [0.03728305 0.03706878 0.03203342]\n",
      "   [0.03871152 0.03871152 0.03371188]\n",
      "   [0.03942576 0.03946147 0.03492608]]\n",
      "\n",
      "  [[0.03353332 0.03467609 0.02792658]\n",
      "   [0.03353332 0.03467609 0.02792658]\n",
      "   [0.03449754 0.03485465 0.02917649]\n",
      "   ...\n",
      "   [0.03756874 0.03764017 0.03221199]\n",
      "   [0.03585458 0.03674737 0.02849796]\n",
      "   [0.03453325 0.03685451 0.02881937]]\n",
      "\n",
      "  [[0.0337833  0.03489036 0.02899793]\n",
      "   [0.0337833  0.03489036 0.02899793]\n",
      "   [0.03449754 0.03553317 0.02946218]\n",
      "   ...\n",
      "   [0.03321191 0.03278337 0.02571245]\n",
      "   [0.03274766 0.03274766 0.02442683]\n",
      "   [0.03274766 0.03474752 0.02478394]]]], shape=(128, 64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 18:30:31.419385: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "def preview_dataset(dataset):\n",
    "    for image, label in dataset.take(20):\n",
    "        print(image)\n",
    "preview_dataset(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d56762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLIP\n",
    "def augment_flip(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image\n",
    "# AUGMENT COLOR\n",
    "def augment_color(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_hue(image, max_delta=0.08)\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_brightness(image, 0.07)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "    return image\n",
    "def augment_hue(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_hue(image, max_delta=0.08)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "    return image\n",
    "def augment_saturation(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "    return image\n",
    "def augment_brightness(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_brightness(image, 0.07)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "    return image\n",
    "def augment_contrast(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "    return image\n",
    "# ROTATE\n",
    "def augment_rotation(image: tf.Tensor) -> tf.Tensor:\n",
    "    # Rotate 0, 90, 180, 270 degrees\n",
    "    return tf.image.rot90(\n",
    "        image,\n",
    "        tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    )\n",
    "#INVERT\n",
    "def augment_inversion(image: tf.Tensor) -> tf.Tensor:\n",
    "    random = tf.random.uniform(shape=[], minval=0, maxval=1)\n",
    "    if random > 0.5:\n",
    "        image = tf.math.multiply(image, -1)\n",
    "        image = tf.math.add(image, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775c9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image,label):\n",
    "  #image=augment_flip(image)\n",
    "  #image=augment_color(image)\n",
    "  #image=augment_rotation(image)\n",
    "  #image=augment_inversion(image)\n",
    "  #image=augment_hue(image)\n",
    "  image=augment_saturation(image)\n",
    "  #image=augment_brightness(image)\n",
    "  #image=augment_contrast(image)\n",
    "\n",
    "\n",
    "  return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8256dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_augmented = ds_train.map(augment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75256822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "resnet = tf.keras.applications.MobileNet(include_top = False,\n",
    "                                          input_shape = (64,64,3),\n",
    "                                          classes = 10)\n",
    "\n",
    "model = tf.keras.models.Sequential(resnet)\n",
    "model.add(tf.keras.layers.Dropout(0.8))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9944c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.000005),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563eeb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 18:30:35.761873: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-19 18:30:36.473854: W tensorflow/core/common_runtime/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - ETA: 0s - loss: 6.1968 - sparse_categorical_accuracy: 0.1151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:01-val_loss:2.413/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:01-val_loss:2.413/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 21s 94ms/step - loss: 6.1968 - sparse_categorical_accuracy: 0.1151 - val_loss: 2.4126 - val_sparse_categorical_accuracy: 0.0959\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 4.6422 - sparse_categorical_accuracy: 0.1403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:02-val_loss:2.283/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:02-val_loss:2.283/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 4.6422 - sparse_categorical_accuracy: 0.1403 - val_loss: 2.2832 - val_sparse_categorical_accuracy: 0.1830\n",
      "Epoch 3/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 3.7431 - sparse_categorical_accuracy: 0.1772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:03-val_loss:1.964/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:03-val_loss:1.964/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 88ms/step - loss: 3.7428 - sparse_categorical_accuracy: 0.1775 - val_loss: 1.9638 - val_sparse_categorical_accuracy: 0.2778\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.2246 - sparse_categorical_accuracy: 0.2077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:04-val_loss:1.815/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:04-val_loss:1.815/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 3.2246 - sparse_categorical_accuracy: 0.2077 - val_loss: 1.8149 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.8248 - sparse_categorical_accuracy: 0.2442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:05-val_loss:1.713/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:05-val_loss:1.713/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 2.8248 - sparse_categorical_accuracy: 0.2442 - val_loss: 1.7134 - val_sparse_categorical_accuracy: 0.4230\n",
      "Epoch 6/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 2.5169 - sparse_categorical_accuracy: 0.2824"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:06-val_loss:1.633/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:06-val_loss:1.633/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 2.5166 - sparse_categorical_accuracy: 0.2824 - val_loss: 1.6334 - val_sparse_categorical_accuracy: 0.4656\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.3028 - sparse_categorical_accuracy: 0.3206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:07-val_loss:1.543/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:07-val_loss:1.543/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 2.3028 - sparse_categorical_accuracy: 0.3206 - val_loss: 1.5427 - val_sparse_categorical_accuracy: 0.5026\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.1088 - sparse_categorical_accuracy: 0.3572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:08-val_loss:1.452/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:08-val_loss:1.452/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 2.1088 - sparse_categorical_accuracy: 0.3572 - val_loss: 1.4520 - val_sparse_categorical_accuracy: 0.5296\n",
      "Epoch 9/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 1.9411 - sparse_categorical_accuracy: 0.4060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:09-val_loss:1.359/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:09-val_loss:1.359/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 1.9427 - sparse_categorical_accuracy: 0.4057 - val_loss: 1.3595 - val_sparse_categorical_accuracy: 0.5619\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8083 - sparse_categorical_accuracy: 0.4412"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:10-val_loss:1.271/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:10-val_loss:1.271/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 1.8083 - sparse_categorical_accuracy: 0.4412 - val_loss: 1.2706 - val_sparse_categorical_accuracy: 0.5907\n",
      "Epoch 11/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 1.6536 - sparse_categorical_accuracy: 0.4808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:11-val_loss:1.181/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:11-val_loss:1.181/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 1.6550 - sparse_categorical_accuracy: 0.4806 - val_loss: 1.1806 - val_sparse_categorical_accuracy: 0.6185\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5506 - sparse_categorical_accuracy: 0.5125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:12-val_loss:1.098/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:12-val_loss:1.098/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 1.5506 - sparse_categorical_accuracy: 0.5125 - val_loss: 1.0981 - val_sparse_categorical_accuracy: 0.6537\n",
      "Epoch 13/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 1.4074 - sparse_categorical_accuracy: 0.5538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:13-val_loss:1.021/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:13-val_loss:1.021/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 1.4069 - sparse_categorical_accuracy: 0.5538 - val_loss: 1.0213 - val_sparse_categorical_accuracy: 0.6752\n",
      "Epoch 14/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 1.3439 - sparse_categorical_accuracy: 0.5728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:14-val_loss:0.948/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:14-val_loss:0.948/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 1.3444 - sparse_categorical_accuracy: 0.5728 - val_loss: 0.9484 - val_sparse_categorical_accuracy: 0.7004\n",
      "Epoch 15/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 1.2541 - sparse_categorical_accuracy: 0.5990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:15-val_loss:0.888/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:15-val_loss:0.888/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 1.2540 - sparse_categorical_accuracy: 0.5990 - val_loss: 0.8877 - val_sparse_categorical_accuracy: 0.7233\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1698 - sparse_categorical_accuracy: 0.6246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:16-val_loss:0.829/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:16-val_loss:0.829/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 1.1698 - sparse_categorical_accuracy: 0.6246 - val_loss: 0.8289 - val_sparse_categorical_accuracy: 0.7437\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1258 - sparse_categorical_accuracy: 0.6383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:17-val_loss:0.778/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:17-val_loss:0.778/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 1.1258 - sparse_categorical_accuracy: 0.6383 - val_loss: 0.7784 - val_sparse_categorical_accuracy: 0.7585\n",
      "Epoch 18/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 1.0625 - sparse_categorical_accuracy: 0.6610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:18-val_loss:0.731/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:18-val_loss:0.731/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 1.0624 - sparse_categorical_accuracy: 0.6610 - val_loss: 0.7308 - val_sparse_categorical_accuracy: 0.7733\n",
      "Epoch 19/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.9784 - sparse_categorical_accuracy: 0.6856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:19-val_loss:0.689/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:19-val_loss:0.689/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.9775 - sparse_categorical_accuracy: 0.6858 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 20/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.9349 - sparse_categorical_accuracy: 0.6993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:20-val_loss:0.652/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:20-val_loss:0.652/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.9352 - sparse_categorical_accuracy: 0.6992 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.8048\n",
      "Epoch 21/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.8854 - sparse_categorical_accuracy: 0.7167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:21-val_loss:0.619/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:21-val_loss:0.619/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.8850 - sparse_categorical_accuracy: 0.7169 - val_loss: 0.6192 - val_sparse_categorical_accuracy: 0.8137\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8374 - sparse_categorical_accuracy: 0.7319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:22-val_loss:0.587/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:22-val_loss:0.587/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.8374 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.5869 - val_sparse_categorical_accuracy: 0.8237\n",
      "Epoch 23/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7895 - sparse_categorical_accuracy: 0.7429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:23-val_loss:0.559/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:23-val_loss:0.559/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.7882 - sparse_categorical_accuracy: 0.7433 - val_loss: 0.5593 - val_sparse_categorical_accuracy: 0.8344\n",
      "Epoch 24/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7520 - sparse_categorical_accuracy: 0.7601"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:24-val_loss:0.533/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:24-val_loss:0.533/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.7525 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.8444\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7262 - sparse_categorical_accuracy: 0.7672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:25-val_loss:0.506/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:25-val_loss:0.506/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.7262 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.5058 - val_sparse_categorical_accuracy: 0.8526\n",
      "Epoch 26/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6929 - sparse_categorical_accuracy: 0.7772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:26-val_loss:0.486/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:26-val_loss:0.486/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.6925 - sparse_categorical_accuracy: 0.7772 - val_loss: 0.4859 - val_sparse_categorical_accuracy: 0.8567\n",
      "Epoch 27/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6527 - sparse_categorical_accuracy: 0.7898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:27-val_loss:0.467/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:27-val_loss:0.467/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.6542 - sparse_categorical_accuracy: 0.7895 - val_loss: 0.4673 - val_sparse_categorical_accuracy: 0.8607\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6233 - sparse_categorical_accuracy: 0.8013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:28-val_loss:0.448/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:28-val_loss:0.448/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.6233 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.4475 - val_sparse_categorical_accuracy: 0.8689\n",
      "Epoch 29/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5966 - sparse_categorical_accuracy: 0.8097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:29-val_loss:0.431/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:29-val_loss:0.431/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.5971 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8744\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.5754 - sparse_categorical_accuracy: 0.8192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:30-val_loss:0.415/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:30-val_loss:0.415/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 92ms/step - loss: 0.5754 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.4147 - val_sparse_categorical_accuracy: 0.8785\n",
      "Epoch 31/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5455 - sparse_categorical_accuracy: 0.8268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:31-val_loss:0.400/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:31-val_loss:0.400/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.4001 - val_sparse_categorical_accuracy: 0.8830\n",
      "Epoch 32/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5294 - sparse_categorical_accuracy: 0.8308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:32-val_loss:0.388/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:32-val_loss:0.388/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.5297 - sparse_categorical_accuracy: 0.8308 - val_loss: 0.3879 - val_sparse_categorical_accuracy: 0.8863\n",
      "Epoch 33/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5125 - sparse_categorical_accuracy: 0.8382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:33-val_loss:0.375/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:33-val_loss:0.375/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.5122 - sparse_categorical_accuracy: 0.8382 - val_loss: 0.3748 - val_sparse_categorical_accuracy: 0.8889\n",
      "Epoch 34/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4874 - sparse_categorical_accuracy: 0.8462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:34-val_loss:0.366/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:34-val_loss:0.366/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.4875 - sparse_categorical_accuracy: 0.8463 - val_loss: 0.3655 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4770 - sparse_categorical_accuracy: 0.8506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:35-val_loss:0.355/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:35-val_loss:0.355/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.4770 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.3546 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 36/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4525 - sparse_categorical_accuracy: 0.8557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:36-val_loss:0.344/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:36-val_loss:0.344/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.4519 - sparse_categorical_accuracy: 0.8557 - val_loss: 0.3437 - val_sparse_categorical_accuracy: 0.8963\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4366 - sparse_categorical_accuracy: 0.8637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:37-val_loss:0.335/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:37-val_loss:0.335/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.4366 - sparse_categorical_accuracy: 0.8637 - val_loss: 0.3349 - val_sparse_categorical_accuracy: 0.8996\n",
      "Epoch 38/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4159 - sparse_categorical_accuracy: 0.8688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:38-val_loss:0.327/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:38-val_loss:0.327/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.4161 - sparse_categorical_accuracy: 0.8687 - val_loss: 0.3266 - val_sparse_categorical_accuracy: 0.9004\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3987 - sparse_categorical_accuracy: 0.8731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:39-val_loss:0.318/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:39-val_loss:0.318/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.3987 - sparse_categorical_accuracy: 0.8731 - val_loss: 0.3178 - val_sparse_categorical_accuracy: 0.9033\n",
      "Epoch 40/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3918 - sparse_categorical_accuracy: 0.8776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:40-val_loss:0.311/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:40-val_loss:0.311/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.3924 - sparse_categorical_accuracy: 0.8775 - val_loss: 0.3109 - val_sparse_categorical_accuracy: 0.9030\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3904 - sparse_categorical_accuracy: 0.8805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:41-val_loss:0.303/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:41-val_loss:0.303/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.3904 - sparse_categorical_accuracy: 0.8805 - val_loss: 0.3028 - val_sparse_categorical_accuracy: 0.9052\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3664 - sparse_categorical_accuracy: 0.8845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:42-val_loss:0.298/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:42-val_loss:0.298/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.3664 - sparse_categorical_accuracy: 0.8845 - val_loss: 0.2981 - val_sparse_categorical_accuracy: 0.9070\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3562 - sparse_categorical_accuracy: 0.8874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:43-val_loss:0.291/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:43-val_loss:0.291/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.3562 - sparse_categorical_accuracy: 0.8874 - val_loss: 0.2909 - val_sparse_categorical_accuracy: 0.9122\n",
      "Epoch 44/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3426 - sparse_categorical_accuracy: 0.8904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:44-val_loss:0.284/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:44-val_loss:0.284/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.3425 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.2842 - val_sparse_categorical_accuracy: 0.9144\n",
      "Epoch 45/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3330 - sparse_categorical_accuracy: 0.8941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:45-val_loss:0.279/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:45-val_loss:0.279/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.3330 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.2794 - val_sparse_categorical_accuracy: 0.9144\n",
      "Epoch 46/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3291 - sparse_categorical_accuracy: 0.8976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:46-val_loss:0.273/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:46-val_loss:0.273/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.3295 - sparse_categorical_accuracy: 0.8978 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.9170\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3107 - sparse_categorical_accuracy: 0.9028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:47-val_loss:0.269/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:47-val_loss:0.269/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.3107 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.2692 - val_sparse_categorical_accuracy: 0.9189\n",
      "Epoch 48/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3046 - sparse_categorical_accuracy: 0.9054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:48-val_loss:0.266/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:48-val_loss:0.266/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.3043 - sparse_categorical_accuracy: 0.9055 - val_loss: 0.2655 - val_sparse_categorical_accuracy: 0.9189\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2972 - sparse_categorical_accuracy: 0.9080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:49-val_loss:0.261/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:49-val_loss:0.261/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.2972 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.2614 - val_sparse_categorical_accuracy: 0.9204\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2930 - sparse_categorical_accuracy: 0.9072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:50-val_loss:0.258/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:50-val_loss:0.258/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.2930 - sparse_categorical_accuracy: 0.9072 - val_loss: 0.2584 - val_sparse_categorical_accuracy: 0.9200\n",
      "Epoch 51/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2746 - sparse_categorical_accuracy: 0.9112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:51-val_loss:0.255/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:51-val_loss:0.255/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.2743 - sparse_categorical_accuracy: 0.9112 - val_loss: 0.2547 - val_sparse_categorical_accuracy: 0.9211\n",
      "Epoch 52/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2703 - sparse_categorical_accuracy: 0.9150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:52-val_loss:0.248/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:52-val_loss:0.248/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2707 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.2482 - val_sparse_categorical_accuracy: 0.9226\n",
      "Epoch 53/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2636 - sparse_categorical_accuracy: 0.9189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:53-val_loss:0.245/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:53-val_loss:0.245/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2634 - sparse_categorical_accuracy: 0.9189 - val_loss: 0.2450 - val_sparse_categorical_accuracy: 0.9256\n",
      "Epoch 54/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2502 - sparse_categorical_accuracy: 0.9230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:54-val_loss:0.241/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:54-val_loss:0.241/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.2505 - sparse_categorical_accuracy: 0.9229 - val_loss: 0.2411 - val_sparse_categorical_accuracy: 0.9259\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2515 - sparse_categorical_accuracy: 0.9219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:55-val_loss:0.238/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:55-val_loss:0.238/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2515 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.9281\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2430 - sparse_categorical_accuracy: 0.9252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:56-val_loss:0.235/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:56-val_loss:0.235/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2430 - sparse_categorical_accuracy: 0.9252 - val_loss: 0.2351 - val_sparse_categorical_accuracy: 0.9281\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2310 - sparse_categorical_accuracy: 0.9276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:57-val_loss:0.232/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:57-val_loss:0.232/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2310 - sparse_categorical_accuracy: 0.9276 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9281\n",
      "Epoch 58/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2302 - sparse_categorical_accuracy: 0.9286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:58-val_loss:0.231/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:58-val_loss:0.231/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2300 - sparse_categorical_accuracy: 0.9286 - val_loss: 0.2314 - val_sparse_categorical_accuracy: 0.9281\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2223 - sparse_categorical_accuracy: 0.9308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:59-val_loss:0.228/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:59-val_loss:0.228/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2223 - sparse_categorical_accuracy: 0.9308 - val_loss: 0.2282 - val_sparse_categorical_accuracy: 0.9293\n",
      "Epoch 60/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2103 - sparse_categorical_accuracy: 0.9324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:60-val_loss:0.227/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:60-val_loss:0.227/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2101 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.2274 - val_sparse_categorical_accuracy: 0.9293\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2117 - sparse_categorical_accuracy: 0.9318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:61-val_loss:0.226/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:61-val_loss:0.226/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.2117 - sparse_categorical_accuracy: 0.9318 - val_loss: 0.2259 - val_sparse_categorical_accuracy: 0.9304\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2092 - sparse_categorical_accuracy: 0.9341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:62-val_loss:0.222/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:62-val_loss:0.222/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2092 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.2224 - val_sparse_categorical_accuracy: 0.9315\n",
      "Epoch 63/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2055 - sparse_categorical_accuracy: 0.9350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:63-val_loss:0.220/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:63-val_loss:0.220/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9351 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1961 - sparse_categorical_accuracy: 0.9374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:64-val_loss:0.217/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:64-val_loss:0.217/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.1961 - sparse_categorical_accuracy: 0.9374 - val_loss: 0.2167 - val_sparse_categorical_accuracy: 0.9330\n",
      "Epoch 65/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.1829 - sparse_categorical_accuracy: 0.9410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:65-val_loss:0.215/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:65-val_loss:0.215/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.1833 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.2154 - val_sparse_categorical_accuracy: 0.9348\n",
      "Epoch 66/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.1831 - sparse_categorical_accuracy: 0.9433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:66-val_loss:0.213/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:66-val_loss:0.213/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.1834 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.2127 - val_sparse_categorical_accuracy: 0.9359\n",
      "Epoch 67/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.1708 - sparse_categorical_accuracy: 0.9442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:67-val_loss:0.211/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:67-val_loss:0.211/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 91ms/step - loss: 0.1710 - sparse_categorical_accuracy: 0.9443 - val_loss: 0.2107 - val_sparse_categorical_accuracy: 0.9352\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1736 - sparse_categorical_accuracy: 0.9450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:68-val_loss:0.210/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:68-val_loss:0.210/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.1736 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.2097 - val_sparse_categorical_accuracy: 0.9356\n",
      "Epoch 69/100\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.1664 - sparse_categorical_accuracy: 0.9470"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:69-val_loss:0.209/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:69-val_loss:0.209/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 89ms/step - loss: 0.1663 - sparse_categorical_accuracy: 0.9471 - val_loss: 0.2087 - val_sparse_categorical_accuracy: 0.9363\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1619 - sparse_categorical_accuracy: 0.9472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:70-val_loss:0.207/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MobileNet/MobileNet epoch:70-val_loss:0.207/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 15s 90ms/step - loss: 0.1619 - sparse_categorical_accuracy: 0.9472 - val_loss: 0.2065 - val_sparse_categorical_accuracy: 0.9374\n",
      "Epoch 71/100\n",
      "147/169 [=========================>....] - ETA: 1s - loss: 0.1634 - sparse_categorical_accuracy: 0.9470"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=100,\n",
    "    validation_data=ds_validation,\n",
    "    callbacks = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"MobileNet/MobileNet epoch:{epoch:02d}-val_loss:{val_loss:.3f}\",\n",
    "        save_best_only = True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19141bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(ds_test, verbose=0)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "\n",
    "ds_test_predict = model.predict(ds_test, verbose=0)\n",
    "\n",
    "labels_iterator = ds_test.unbatch().map(lambda x, y: y).as_numpy_iterator()\n",
    "labels = np.array(list(labels_iterator))\n",
    "\n",
    "y_pred = np.argmax(ds_test_predict, axis=1)\n",
    "y_test = labels\n",
    "plt.figure(figsize=(10,6))\n",
    "fx=sns.heatmap(confusion_matrix(y_pred, y_test, normalize=\"pred\"), annot=True, fmt=\".2%\",cmap=\"GnBu\")\n",
    "fx.set_title('Confusion Matrix \\n');\n",
    "fx.set_xlabel('\\n Predicted Values\\n')\n",
    "fx.set_ylabel('Actual Values\\n');\n",
    "fx.xaxis.set_ticklabels(['AnnualCrop','Forest','HerbaceousVegetation',\n",
    "                         'Highway','Industrial','Pasture','PermanentCrop',\n",
    "                         'Residential','River','SeaLake'], rotation=20, ha=\"right\")\n",
    "fx.yaxis.set_ticklabels(['AnnualCrop','Forest','HerbaceousVegetation',\n",
    "                         'Highway','Industrial','Pasture','PermanentCrop',\n",
    "                         'Residential','River','SeaLake'], rotation=20, ha=\"right\")\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "plt.savefig(fname=\"MobileNet/MobileNet confusion matrix\"+current_time,dpi=300)\n",
    "render_training_history(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
